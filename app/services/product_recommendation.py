import logging
import json
from typing import List, Dict, Tuple
from app.models import DiseaseDetectionResult, ProductRecommendation
from app.services.services import supabase_client, openai_client
from app.services.cache import get_from_cache, set_to_cache
from app.utils.text_processing import extract_keywords_from_question
from app.services.reranker import rerank_products_with_llm, simple_relevance_boost

logger = logging.getLogger(__name__)

# Configuration for re-ranking
ENABLE_RERANKING = True  # Set to False to disable re-ranking for faster response

# =============================================================================
# ‡πÇ‡∏£‡∏Ñ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÅ‡∏°‡∏•‡∏á‡∏û‡∏≤‡∏´‡∏∞ ‚Üí ‡∏Ñ‡∏ß‡∏£‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á‡πÅ‡∏ó‡∏ô‡∏¢‡∏≤‡∏Å‡∏≥‡∏à‡∏±‡∏î‡πÄ‡∏ä‡∏∑‡πâ‡∏≠
# =============================================================================
VECTOR_DISEASES = {
    # =========================================================================
    # üåæ ‡∏Ç‡πâ‡∏≤‡∏ß (RICE) - ‡πÇ‡∏£‡∏Ñ‡πÑ‡∏ß‡∏£‡∏±‡∏™‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏≤‡∏´‡∏∞
    # =========================================================================
    "‡πÇ‡∏£‡∏Ñ‡∏à‡∏π‡πã": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏•", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏• ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á BPH", "disease_query": "‡πÇ‡∏£‡∏Ñ‡∏à‡∏π‡πã ‡∏Ç‡πâ‡∏≤‡∏ß ‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡∏ï‡πâ‡∏ô ‡∏ü‡∏∑‡πâ‡∏ô‡∏ü‡∏π"},
    "rice ragged stunt": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏•", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏• ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á BPH", "disease_query": "‡πÇ‡∏£‡∏Ñ‡∏à‡∏π‡πã ‡∏Ç‡πâ‡∏≤‡∏ß ‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡∏ï‡πâ‡∏ô"},
    "ragged stunt": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏•", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏• ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á BPH", "disease_query": "‡πÇ‡∏£‡∏Ñ‡∏à‡∏π‡πã ‡∏Ç‡πâ‡∏≤‡∏ß ‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡∏ï‡πâ‡∏ô"},
    "‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡∏´‡∏á‡∏¥‡∏Å": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏•", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏• ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á BPH", "disease_query": "‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡∏´‡∏á‡∏¥‡∏Å ‡∏Ç‡πâ‡∏≤‡∏ß ‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡∏ï‡πâ‡∏ô ‡∏Æ‡∏≠‡∏£‡πå‡πÇ‡∏°‡∏ô"},
    "rice grassy stunt": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏•", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏• ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á BPH", "disease_query": "‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡∏´‡∏á‡∏¥‡∏Å ‡∏Ç‡πâ‡∏≤‡∏ß ‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡∏ï‡πâ‡∏ô"},
    "grassy stunt": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏•", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏• ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á BPH", "disease_query": "‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡∏´‡∏á‡∏¥‡∏Å ‡∏Ç‡πâ‡∏≤‡∏ß ‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡∏ï‡πâ‡∏ô"},
    "‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡∏™‡∏µ‡∏™‡πâ‡∏°": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á GLH", "disease_query": "‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡∏™‡∏µ‡∏™‡πâ‡∏° ‡∏Ç‡πâ‡∏≤‡∏ß ‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡∏ï‡πâ‡∏ô"},
    "rice orange leaf": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á GLH", "disease_query": "‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡∏™‡∏µ‡∏™‡πâ‡∏° ‡∏Ç‡πâ‡∏≤‡∏ß ‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡∏ï‡πâ‡∏ô"},
    "orange leaf": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á GLH", "disease_query": "‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡∏™‡∏µ‡∏™‡πâ‡∏° ‡∏Ç‡πâ‡∏≤‡∏ß ‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡∏ï‡πâ‡∏ô"},
    "‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡∏Ç‡∏≤‡∏ß‡∏Ç‡πâ‡∏≤‡∏ß": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á GLH", "disease_query": "‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡∏Ç‡∏≤‡∏ß ‡∏Ç‡πâ‡∏≤‡∏ß ‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡∏ï‡πâ‡∏ô"},
    "rice tungro": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á GLH", "disease_query": "‡πÇ‡∏£‡∏Ñ‡∏ó‡∏±‡∏á‡πÇ‡∏£ ‡∏Ç‡πâ‡∏≤‡∏ß ‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡∏ï‡πâ‡∏ô"},
    "tungro": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á GLH", "disease_query": "‡πÇ‡∏£‡∏Ñ‡∏ó‡∏±‡∏á‡πÇ‡∏£ ‡∏Ç‡πâ‡∏≤‡∏ß ‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡∏ï‡πâ‡∏ô"},
    "‡πÇ‡∏£‡∏Ñ‡∏ó‡∏±‡∏á‡πÇ‡∏£": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á GLH", "disease_query": "‡πÇ‡∏£‡∏Ñ‡∏ó‡∏±‡∏á‡πÇ‡∏£ ‡∏Ç‡πâ‡∏≤‡∏ß ‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡∏ï‡πâ‡∏ô"},

    # =========================================================================
    # üç¨ ‡∏≠‡πâ‡∏≠‡∏¢ (SUGARCANE) - ‡πÇ‡∏£‡∏Ñ‡πÑ‡∏ß‡∏£‡∏±‡∏™‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡πÇ‡∏ï‡∏û‡∏•‡∏≤‡∏™‡∏°‡∏≤
    # =========================================================================
    "‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡∏Ç‡∏≤‡∏ß‡∏≠‡πâ‡∏≠‡∏¢": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏≠‡πâ‡∏≠‡∏¢"},
    "sugarcane white leaf": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏≠‡πâ‡∏≠‡∏¢"},
    "white leaf": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á"},
    "‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡∏î‡πà‡∏≤‡∏á‡∏≠‡πâ‡∏≠‡∏¢": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏≠‡πâ‡∏≠‡∏¢"},
    "sugarcane mosaic": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á"},
    "‡πÇ‡∏£‡∏Ñ‡∏Å‡∏≠‡∏ï‡∏∞‡πÑ‡∏Ñ‡∏£‡πâ": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏≠‡πâ‡∏≠‡∏¢"},
    "sugarcane grassy shoot": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á"},

    # =========================================================================
    # ü•≠ ‡∏°‡∏∞‡∏°‡πà‡∏ß‡∏á (MANGO) - ‡πÇ‡∏£‡∏Ñ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÅ‡∏°‡∏•‡∏á‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
    # =========================================================================
    "‡πÇ‡∏£‡∏Ñ‡∏ä‡πà‡∏≠‡∏î‡∏≥‡∏°‡∏∞‡∏°‡πà‡∏ß‡∏á": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô‡∏°‡∏∞‡∏°‡πà‡∏ß‡∏á ‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏ü", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô‡∏°‡∏∞‡∏°‡πà‡∏ß‡∏á ‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏ü ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á"},
    "mango malformation": {"pest": "‡πÑ‡∏£‡∏™‡∏µ‡πà‡∏Ç‡∏≤", "search_query": "‡πÑ‡∏£‡∏™‡∏µ‡πà‡∏Ç‡∏≤ ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÑ‡∏£ ‡∏°‡∏∞‡∏°‡πà‡∏ß‡∏á"},
    "‡πÇ‡∏£‡∏Ñ‡∏¢‡∏≠‡∏î‡πÑ‡∏´‡∏°‡πâ‡∏°‡∏∞‡∏°‡πà‡∏ß‡∏á": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô‡∏°‡∏∞‡∏°‡πà‡∏ß‡∏á", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô‡∏°‡∏∞‡∏°‡πà‡∏ß‡∏á ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á"},
    "mango hopper burn": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô‡∏°‡∏∞‡∏°‡πà‡∏ß‡∏á", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô‡∏°‡∏∞‡∏°‡πà‡∏ß‡∏á ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á"},

    # =========================================================================
    # üå≥ ‡∏•‡∏≥‡πÑ‡∏¢ (LONGAN) - ‡πÇ‡∏£‡∏Ñ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÅ‡∏°‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏≤‡∏´‡∏∞
    # =========================================================================
    "‡πÇ‡∏£‡∏Ñ‡∏û‡∏∏‡πà‡∏°‡πÑ‡∏°‡πâ‡∏Å‡∏ß‡∏≤‡∏î": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡πÑ‡∏£‡∏™‡∏µ‡πà‡∏Ç‡∏≤", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡πÑ‡∏£‡∏™‡∏µ‡πà‡∏Ç‡∏≤ ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏•‡∏≥‡πÑ‡∏¢"},
    "witches' broom": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡πÑ‡∏£‡∏™‡∏µ‡πà‡∏Ç‡∏≤", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡πÑ‡∏£‡∏™‡∏µ‡πà‡∏Ç‡∏≤ ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏•‡∏≥‡πÑ‡∏¢"},
    "longan witches broom": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡πÑ‡∏£‡∏™‡∏µ‡πà‡∏Ç‡∏≤", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡πÑ‡∏£‡∏™‡∏µ‡πà‡∏Ç‡∏≤ ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á"},
    "‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡πÑ‡∏´‡∏°‡πâ‡∏•‡∏≥‡πÑ‡∏¢": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏ü ‡πÑ‡∏£‡πÅ‡∏î‡∏á", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏ü ‡πÑ‡∏£‡πÅ‡∏î‡∏á ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏•‡∏≥‡πÑ‡∏¢"},

    # =========================================================================
    # üçà ‡∏ó‡∏∏‡πÄ‡∏£‡∏µ‡∏¢‡∏ô (DURIAN) - ‡πÅ‡∏°‡∏•‡∏á‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
    # =========================================================================
    "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏Å‡πà‡πÅ‡∏à‡πâ‡∏ó‡∏∏‡πÄ‡∏£‡∏µ‡∏¢‡∏ô": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏Å‡πà‡πÅ‡∏à‡πâ", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏Å‡πà‡πÅ‡∏à‡πâ ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏ó‡∏∏‡πÄ‡∏£‡∏µ‡∏¢‡∏ô"},
    "‡∏´‡∏ô‡∏≠‡∏ô‡πÄ‡∏à‡∏≤‡∏∞‡∏ú‡∏•‡∏ó‡∏∏‡πÄ‡∏£‡∏µ‡∏¢‡∏ô": {"pest": "‡∏´‡∏ô‡∏≠‡∏ô‡πÄ‡∏à‡∏≤‡∏∞‡∏ú‡∏•", "search_query": "‡∏´‡∏ô‡∏≠‡∏ô‡πÄ‡∏à‡∏≤‡∏∞‡∏ú‡∏• ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏ó‡∏∏‡πÄ‡∏£‡∏µ‡∏¢‡∏ô"},
    "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÅ‡∏õ‡πâ‡∏á‡∏ó‡∏∏‡πÄ‡∏£‡∏µ‡∏¢‡∏ô": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÅ‡∏õ‡πâ‡∏á", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÅ‡∏õ‡πâ‡∏á ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏ó‡∏∏‡πÄ‡∏£‡∏µ‡∏¢‡∏ô"},
    "‡πÑ‡∏£‡πÅ‡∏î‡∏á‡∏ó‡∏∏‡πÄ‡∏£‡∏µ‡∏¢‡∏ô": {"pest": "‡πÑ‡∏£‡πÅ‡∏î‡∏á", "search_query": "‡πÑ‡∏£‡πÅ‡∏î‡∏á ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÑ‡∏£ ‡∏ó‡∏∏‡πÄ‡∏£‡∏µ‡∏¢‡∏ô"},
    "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏ü‡∏ó‡∏∏‡πÄ‡∏£‡∏µ‡∏¢‡∏ô": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏ü", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏ü ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏ó‡∏∏‡πÄ‡∏£‡∏µ‡∏¢‡∏ô"},

    # =========================================================================
    # üçä ‡∏™‡πâ‡∏°/‡∏°‡∏∞‡∏ô‡∏≤‡∏ß (CITRUS) - ‡πÇ‡∏£‡∏Ñ‡πÑ‡∏ß‡∏£‡∏±‡∏™‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏û‡∏≤‡∏´‡∏∞
    # =========================================================================
    "‡πÇ‡∏£‡∏Ñ‡∏Å‡∏£‡∏µ‡∏ô‡∏ô‡∏¥‡πà‡∏á": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏Å‡πà‡πÅ‡∏à‡πâ", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏Å‡πà‡πÅ‡∏à‡πâ ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏™‡πâ‡∏°"},
    "greening": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏Å‡πà‡πÅ‡∏à‡πâ", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏Å‡πà‡πÅ‡∏à‡πâ ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏™‡πâ‡∏°"},
    "hlb": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏Å‡πà‡πÅ‡∏à‡πâ", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏Å‡πà‡πÅ‡∏à‡πâ ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏™‡πâ‡∏°"},
    "huanglongbing": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏Å‡πà‡πÅ‡∏à‡πâ", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏Å‡πà‡πÅ‡∏à‡πâ ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏™‡πâ‡∏°"},
    "‡πÇ‡∏£‡∏Ñ‡∏ó‡∏£‡∏¥‡∏™‡πÄ‡∏ï‡∏ã‡πà‡∏≤": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏™‡πâ‡∏°"},
    "tristeza": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏™‡πâ‡∏°"},
    "citrus tristeza": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏™‡πâ‡∏°"},

    # =========================================================================
    # ü•î ‡∏°‡∏±‡∏ô‡∏™‡∏≥‡∏õ‡∏∞‡∏´‡∏•‡∏±‡∏á (CASSAVA) - ‡πÇ‡∏£‡∏Ñ‡πÑ‡∏ß‡∏£‡∏±‡∏™‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏û‡∏≤‡∏´‡∏∞
    # =========================================================================
    "‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡∏î‡πà‡∏≤‡∏á‡∏°‡∏±‡∏ô‡∏™‡∏≥‡∏õ‡∏∞‡∏´‡∏•‡∏±‡∏á": {"pest": "‡πÅ‡∏°‡∏•‡∏á‡∏´‡∏ß‡∏µ‡πà‡∏Ç‡∏≤‡∏ß", "search_query": "‡πÅ‡∏°‡∏•‡∏á‡∏´‡∏ß‡∏µ‡πà‡∏Ç‡∏≤‡∏ß ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏°‡∏±‡∏ô‡∏™‡∏≥‡∏õ‡∏∞‡∏´‡∏•‡∏±‡∏á"},
    "cassava mosaic": {"pest": "‡πÅ‡∏°‡∏•‡∏á‡∏´‡∏ß‡∏µ‡πà‡∏Ç‡∏≤‡∏ß", "search_query": "‡πÅ‡∏°‡∏•‡∏á‡∏´‡∏ß‡∏µ‡πà‡∏Ç‡∏≤‡∏ß ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏°‡∏±‡∏ô‡∏™‡∏≥‡∏õ‡∏∞‡∏´‡∏•‡∏±‡∏á"},
    "cmd": {"pest": "‡πÅ‡∏°‡∏•‡∏á‡∏´‡∏ß‡∏µ‡πà‡∏Ç‡∏≤‡∏ß", "search_query": "‡πÅ‡∏°‡∏•‡∏á‡∏´‡∏ß‡∏µ‡πà‡∏Ç‡∏≤‡∏ß ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏°‡∏±‡∏ô‡∏™‡∏≥‡∏õ‡∏∞‡∏´‡∏•‡∏±‡∏á"},
    "slcmv": {"pest": "‡πÅ‡∏°‡∏•‡∏á‡∏´‡∏ß‡∏µ‡πà‡∏Ç‡∏≤‡∏ß", "search_query": "‡πÅ‡∏°‡∏•‡∏á‡∏´‡∏ß‡∏µ‡πà‡∏Ç‡∏≤‡∏ß ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á"},
    "‡πÇ‡∏£‡∏Ñ‡∏û‡∏∏‡πà‡∏°‡πÅ‡∏à‡πâ‡∏°‡∏±‡∏ô‡∏™‡∏≥‡∏õ‡∏∞‡∏´‡∏•‡∏±‡∏á": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏°‡∏±‡∏ô‡∏™‡∏≥‡∏õ‡∏∞‡∏´‡∏•‡∏±‡∏á"},
    "cassava witches' broom": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á"},

    # =========================================================================
    # üåΩ ‡∏Ç‡πâ‡∏≤‡∏ß‡πÇ‡∏û‡∏î (CORN/MAIZE) - ‡πÇ‡∏£‡∏Ñ‡πÑ‡∏ß‡∏£‡∏±‡∏™‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏û‡∏≤‡∏´‡∏∞
    # =========================================================================
    "‡πÇ‡∏£‡∏Ñ‡∏Ç‡πâ‡∏≤‡∏ß‡πÇ‡∏û‡∏î‡πÅ‡∏Ñ‡∏£‡∏∞": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô‡∏Ç‡πâ‡∏≤‡∏ß‡πÇ‡∏û‡∏î", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏Ç‡πâ‡∏≤‡∏ß‡πÇ‡∏û‡∏î"},
    "corn stunt": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô‡∏Ç‡πâ‡∏≤‡∏ß‡πÇ‡∏û‡∏î", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏Ç‡πâ‡∏≤‡∏ß‡πÇ‡∏û‡∏î"},
    "‡πÇ‡∏£‡∏Ñ‡∏Ç‡πâ‡∏≤‡∏ß‡πÇ‡∏û‡∏î‡∏á‡∏≠‡∏¢": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô‡∏Ç‡πâ‡∏≤‡∏ß‡πÇ‡∏û‡∏î", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏Ç‡πâ‡∏≤‡∏ß‡πÇ‡∏û‡∏î"},
    "‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡∏•‡∏≤‡∏¢‡∏Ç‡πâ‡∏≤‡∏ß‡πÇ‡∏û‡∏î": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î‡∏Ç‡πâ‡∏≤‡∏ß‡πÇ‡∏û‡∏î", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏Ç‡πâ‡∏≤‡∏ß‡πÇ‡∏û‡∏î"},
    "maize stripe": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î‡∏Ç‡πâ‡∏≤‡∏ß‡πÇ‡∏û‡∏î", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏Ç‡πâ‡∏≤‡∏ß‡πÇ‡∏û‡∏î"},
    "‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡∏î‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≤‡∏ß‡πÇ‡∏û‡∏î": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏Ç‡πâ‡∏≤‡∏ß‡πÇ‡∏û‡∏î"},
    "maize mosaic": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô ‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô ‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á"},

    # =========================================================================
    # üåø ‡πÇ‡∏£‡∏Ñ‡πÑ‡∏ß‡∏£‡∏±‡∏™‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
    # =========================================================================
    "‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡∏î‡πà‡∏≤‡∏á": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô ‡πÅ‡∏°‡∏•‡∏á‡∏´‡∏ß‡∏µ‡πà‡∏Ç‡∏≤‡∏ß", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô ‡πÅ‡∏°‡∏•‡∏á‡∏´‡∏ß‡∏µ‡πà‡∏Ç‡∏≤‡∏ß ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á"},
    "mosaic": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á"},
    "‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡∏´‡∏î": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô ‡πÑ‡∏£‡∏Ç‡∏≤‡∏ß", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô ‡πÑ‡∏£‡∏Ç‡∏≤‡∏ß ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á"},
    "leaf curl": {"pest": "‡πÅ‡∏°‡∏•‡∏á‡∏´‡∏ß‡∏µ‡πà‡∏Ç‡∏≤‡∏ß", "search_query": "‡πÅ‡∏°‡∏•‡∏á‡∏´‡∏ß‡∏µ‡πà‡∏Ç‡∏≤‡∏ß ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á"},
    "‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡∏´‡∏á‡∏¥‡∏Å‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á": {"pest": "‡πÅ‡∏°‡∏•‡∏á‡∏´‡∏ß‡∏µ‡πà‡∏Ç‡∏≤‡∏ß", "search_query": "‡πÅ‡∏°‡∏•‡∏á‡∏´‡∏ß‡∏µ‡πà‡∏Ç‡∏≤‡∏ß ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á"},
}

def get_search_query_for_disease(disease_name: str, pest_type: str = "") -> tuple:
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÇ‡∏£‡∏Ñ‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡πÅ‡∏°‡∏•‡∏á‡∏û‡∏≤‡∏´‡∏∞‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ ‚Üí return (search_query ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á, pest_name, disease_search_query)
    ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ ‚Üí return (disease_name, None, None)

    Returns: (vector_search_query, pest_name, disease_search_query)
    """
    disease_lower = disease_name.lower()

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏£‡∏Ñ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏û‡∏≤‡∏´‡∏∞‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    for key, info in VECTOR_DISEASES.items():
        if key in disease_lower:
            logger.info(f"üêõ ‡πÇ‡∏£‡∏Ñ‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡πÅ‡∏°‡∏•‡∏á‡∏û‡∏≤‡∏´‡∏∞: {info['pest']} ‚Üí ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á‡πÅ‡∏•‡∏∞‡∏¢‡∏≤‡∏£‡∏±‡∏Å‡∏©‡∏≤‡πÇ‡∏£‡∏Ñ")
            # Return both: vector search + disease treatment search
            disease_treatment_query = info.get("disease_query", f"{disease_name} ‡∏¢‡∏≤‡∏£‡∏±‡∏Å‡∏©‡∏≤ ‡πÇ‡∏£‡∏Ñ‡∏û‡∏∑‡∏ä")
            return (info["search_query"], info["pest"], disease_treatment_query)

    # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ß‡∏£‡∏±‡∏™ ‚Üí ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏´‡∏≤‡∏û‡∏≤‡∏´‡∏∞
    if pest_type and "‡πÑ‡∏ß‡∏£‡∏±‡∏™" in pest_type.lower():
        logger.info("ü¶† ‡πÇ‡∏£‡∏Ñ‡πÑ‡∏ß‡∏£‡∏±‡∏™ ‚Üí ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏û‡∏≤‡∏´‡∏∞")
        return (f"{disease_name} ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏û‡∏≤‡∏´‡∏∞", None, None)

    return (disease_name, None, None)


# =============================================================================
# Hybrid Search Functions (Vector + BM25/Keyword)
# =============================================================================

async def hybrid_search_products(query: str, match_count: int = 15,
                                  vector_weight: float = 0.6,
                                  keyword_weight: float = 0.4) -> List[Dict]:
    """
    Perform Hybrid Search combining Vector Search + Keyword/BM25 Search
    Uses Reciprocal Rank Fusion (RRF) for combining results
    """
    try:
        if not supabase_client or not openai_client:
            logger.warning("Supabase or OpenAI client not available for hybrid search")
            return []

        logger.info(f"üîç Hybrid Search: '{query}' (vector={vector_weight}, keyword={keyword_weight})")

        # Generate embedding for vector search
        response = await openai_client.embeddings.create(
            model="text-embedding-3-small",
            input=query,
            encoding_format="float"
        )
        query_embedding = response.data[0].embedding

        # Try hybrid_search_products RPC first (if SQL function exists)
        try:
            result = supabase_client.rpc(
                'hybrid_search_products',
                {
                    'query_embedding': query_embedding,
                    'search_query': query,
                    'vector_weight': vector_weight,
                    'keyword_weight': keyword_weight,
                    'match_threshold': 0.15,
                    'match_count': match_count
                }
            ).execute()

            if result.data:
                logger.info(f"‚úì Hybrid search returned {len(result.data)} products")
                for p in result.data[:3]:
                    logger.info(f"   ‚Üí {p.get('product_name')}: hybrid={p.get('hybrid_score', 0):.3f} "
                               f"(vec={p.get('vector_score', 0):.3f}, kw={p.get('keyword_score', 0):.3f})")
                return result.data

        except Exception as e:
            logger.warning(f"hybrid_search_products RPC failed: {e}, falling back to manual hybrid search")

        # Fallback: Manual hybrid search (Vector + Keyword separately)
        return await manual_hybrid_search(query, query_embedding, match_count, vector_weight, keyword_weight)

    except Exception as e:
        logger.error(f"Hybrid search failed: {e}", exc_info=True)
        return []


async def manual_hybrid_search(query: str, query_embedding: List[float],
                                match_count: int = 15,
                                vector_weight: float = 0.6,
                                keyword_weight: float = 0.4) -> List[Dict]:
    """
    Manual Hybrid Search fallback - runs vector and keyword search separately
    then combines with Reciprocal Rank Fusion (RRF)
    """
    try:
        # 1. Vector Search
        vector_results = []
        try:
            result = supabase_client.rpc(
                'match_products',
                {
                    'query_embedding': query_embedding,
                    'match_threshold': 0.15,
                    'match_count': match_count * 2
                }
            ).execute()
            if result.data:
                vector_results = result.data
                logger.info(f"   Vector search: {len(vector_results)} results")
        except Exception as e:
            logger.warning(f"Vector search failed: {e}")

        # 2. Keyword Search (ILIKE fallback)
        keyword_results = []
        try:
            # Try keyword_search_products RPC
            result = supabase_client.rpc(
                'keyword_search_products',
                {
                    'search_query': query,
                    'match_count': match_count * 2
                }
            ).execute()
            if result.data:
                keyword_results = result.data
                logger.info(f"   Keyword search (RPC): {len(keyword_results)} results")
        except Exception as e:
            logger.warning(f"keyword_search_products RPC failed: {e}, trying ILIKE")
            # Fallback: ILIKE search
            try:
                result = supabase_client.table('products')\
                    .select('*')\
                    .or_(f"product_name.ilike.%{query}%,"
                         f"target_pest.ilike.%{query}%,"
                         f"applicable_crops.ilike.%{query}%,"
                         f"active_ingredient.ilike.%{query}%")\
                    .limit(match_count * 2)\
                    .execute()
                if result.data:
                    # Add rank score for ILIKE results
                    for i, p in enumerate(result.data):
                        p['rank'] = 1.0 / (i + 1)  # Simple rank score
                    keyword_results = result.data
                    logger.info(f"   Keyword search (ILIKE): {len(keyword_results)} results")
            except Exception as e2:
                logger.warning(f"ILIKE search failed: {e2}")

        # 3. Combine with RRF (Reciprocal Rank Fusion)
        combined = reciprocal_rank_fusion(
            vector_results, keyword_results,
            vector_weight, keyword_weight
        )

        logger.info(f"‚úì Manual hybrid search combined: {len(combined)} products")
        return combined[:match_count]

    except Exception as e:
        logger.error(f"Manual hybrid search failed: {e}", exc_info=True)
        return []


def reciprocal_rank_fusion(vector_results: List[Dict], keyword_results: List[Dict],
                           vector_weight: float = 0.6, keyword_weight: float = 0.4,
                           k: int = 60) -> List[Dict]:
    """
    Combine vector and keyword search results using Reciprocal Rank Fusion (RRF)
    RRF score = sum(1 / (k + rank)) across all result sets

    Parameters:
    - k: constant to prevent high scores for top results (default 60)
    """
    try:
        # Build product lookup and RRF scores
        products_by_id = {}
        rrf_scores = {}

        # Process vector results
        for rank, product in enumerate(vector_results, 1):
            pid = product.get('id') or product.get('product_name')
            if pid:
                products_by_id[pid] = product
                rrf_scores[pid] = rrf_scores.get(pid, 0) + vector_weight * (1 / (k + rank))
                product['vector_rank'] = rank
                product['vector_score'] = product.get('similarity', 0)

        # Process keyword results
        for rank, product in enumerate(keyword_results, 1):
            pid = product.get('id') or product.get('product_name')
            if pid:
                if pid not in products_by_id:
                    products_by_id[pid] = product
                rrf_scores[pid] = rrf_scores.get(pid, 0) + keyword_weight * (1 / (k + rank))
                products_by_id[pid]['keyword_rank'] = rank
                products_by_id[pid]['keyword_score'] = product.get('rank', 0)

        # Add bonus for products appearing in both
        for pid in rrf_scores:
            product = products_by_id[pid]
            if product.get('vector_rank') and product.get('keyword_rank'):
                rrf_scores[pid] += 0.02  # Small bonus for appearing in both

        # Sort by RRF score
        sorted_ids = sorted(rrf_scores.keys(), key=lambda x: rrf_scores[x], reverse=True)

        # Build final results
        combined_results = []
        for pid in sorted_ids:
            product = products_by_id[pid].copy()
            product['hybrid_score'] = rrf_scores[pid]
            product['similarity'] = rrf_scores[pid]  # Use hybrid score as similarity
            combined_results.append(product)

        return combined_results

    except Exception as e:
        logger.error(f"RRF fusion failed: {e}", exc_info=True)
        # Fallback: return vector results
        return vector_results

async def retrieve_product_recommendation(disease_info: DiseaseDetectionResult) -> List[ProductRecommendation]:
    """
    Query products using Hybrid Search (Vector + Keyword/BM25)
    Returns top 3-6 most relevant products

    ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏£‡∏Ñ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÅ‡∏°‡∏•‡∏á‡∏û‡∏≤‡∏´‡∏∞ (‡πÄ‡∏ä‡πà‡∏ô ‡πÇ‡∏£‡∏Ñ‡∏à‡∏π‡πã‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≤‡∏ß) ‡∏à‡∏∞‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á‡πÅ‡∏ó‡∏ô
    """
    try:
        logger.info("üîç Retrieving products with Hybrid Search (Vector + Keyword)")

        if not supabase_client:
            logger.warning("Supabase not configured")
            return []

        disease_name = disease_info.disease_name

        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÇ‡∏£‡∏Ñ‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡πÅ‡∏°‡∏•‡∏á‡∏û‡∏≤‡∏´‡∏∞‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà ‚Üí ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á‡πÅ‡∏•‡∏∞‡∏¢‡∏≤‡∏£‡∏±‡∏Å‡∏©‡∏≤‡πÇ‡∏£‡∏Ñ
        pest_type = ""
        if hasattr(disease_info, 'raw_analysis') and disease_info.raw_analysis:
            # ‡∏î‡∏∂‡∏á pest_type ‡∏à‡∏≤‡∏Å raw_analysis ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
            if "‡πÑ‡∏ß‡∏£‡∏±‡∏™" in disease_info.raw_analysis:
                pest_type = "‡πÑ‡∏ß‡∏£‡∏±‡∏™"

        vector_search_query, pest_name, disease_treatment_query = get_search_query_for_disease(disease_name, pest_type)

        if pest_name:
            logger.info(f"üêõ ‡πÇ‡∏£‡∏Ñ‡∏°‡∏µ‡∏û‡∏≤‡∏´‡∏∞: {pest_name}")
            logger.info(f"   ‚Üí ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á: {vector_search_query}")
            logger.info(f"   ‚Üí ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏¢‡∏≤‡∏£‡∏±‡∏Å‡∏©‡∏≤‡πÇ‡∏£‡∏Ñ: {disease_treatment_query}")
            search_query = vector_search_query  # Primary search is for vector
        else:
            search_query = vector_search_query
            logger.info(f"üìù Searching products for: {disease_name}")

        # Check cache first (‡πÉ‡∏ä‡πâ search_query ‡πÄ‡∏õ‡πá‡∏ô key)
        cache_key = f"products:{search_query}"
        cached_products = await get_from_cache("products", cache_key)
        if cached_products:
            logger.info("‚úì Using cached product recommendations")
            return [ProductRecommendation(**p) for p in cached_products]

        # Strategy 1: Hybrid Search (Vector + Keyword combined)
        try:
            all_results = []

            # 1. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏¢‡∏≤‡∏Å‡∏≥‡∏à‡∏±‡∏î‡∏û‡∏≤‡∏´‡∏∞ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
            hybrid_results = await hybrid_search_products(
                query=search_query,  # ‡πÉ‡∏ä‡πâ search_query ‡πÅ‡∏ó‡∏ô disease_name
                match_count=15,
                vector_weight=0.6,
                keyword_weight=0.4
            )
            if hybrid_results:
                # Mark these as vector control products
                for p in hybrid_results:
                    p['recommendation_type'] = 'vector_control' if pest_name else 'disease_treatment'
                all_results.extend(hybrid_results)
                logger.info(f"‚úì Primary search found {len(hybrid_results)} products")

            # 2. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏¢‡∏≤‡∏£‡∏±‡∏Å‡∏©‡∏≤‡πÇ‡∏£‡∏Ñ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° (‡∏ñ‡πâ‡∏≤‡πÇ‡∏£‡∏Ñ‡∏°‡∏µ‡∏û‡∏≤‡∏´‡∏∞)
            if pest_name and disease_treatment_query:
                disease_results = await hybrid_search_products(
                    query=disease_treatment_query,
                    match_count=10,
                    vector_weight=0.5,
                    keyword_weight=0.5
                )
                if disease_results:
                    # Mark these as disease treatment products
                    for p in disease_results:
                        p['recommendation_type'] = 'disease_treatment'
                    all_results.extend(disease_results)
                    logger.info(f"‚úì Disease treatment search found {len(disease_results)} products")

            # Combine and deduplicate
            hybrid_results = all_results

            if hybrid_results:
                logger.info(f"‚úì Total hybrid search found {len(hybrid_results)} candidates")

                # Apply simple relevance boost first
                for p in hybrid_results:
                    boost = simple_relevance_boost(disease_name, p)
                    p['hybrid_score'] = p.get('hybrid_score', p.get('similarity', 0)) + boost

                # Sort by boosted score
                hybrid_results.sort(key=lambda x: x.get('hybrid_score', 0), reverse=True)

                # Re-rank top candidates with LLM Cross-Encoder (if enabled)
                if ENABLE_RERANKING and len(hybrid_results) > 6:
                    logger.info("üîÑ Applying LLM re-ranking for higher accuracy...")
                    hybrid_results = await rerank_products_with_llm(
                        query=disease_name,
                        products=hybrid_results[:15],  # Top 15 candidates
                        top_k=6,
                        openai_client=openai_client
                    )

                # Filter by hybrid score threshold
                filtered_data = [
                    p for p in hybrid_results
                    if p.get('hybrid_score', p.get('similarity', 0)) > 0.005
                ][:6]

                if filtered_data:
                    logger.info(f"‚úì Final {len(filtered_data)} products after re-ranking")
                    filtered_products = build_recommendations_from_data(filtered_data, pest_name=pest_name)

                    # Cache the results
                    if filtered_products:
                        await set_to_cache("products", cache_key, [r.dict() for r in filtered_products])

                    return filtered_products
                else:
                    # No products passed threshold - return empty instead of forcing results
                    logger.warning("‚ö†Ô∏è No products passed relevance threshold - no recommendations")
                    return []

        except Exception as e:
            logger.warning(f"Hybrid search failed: {e}, trying fallback")

        # Strategy 2: Keyword search fallback
        matches_data = []

        # Search in target_pest field
        try:
            result = supabase_client.table('products')\
                .select('*')\
                .ilike('target_pest', f'%{disease_name}%')\
                .limit(10)\
                .execute()

            if result.data:
                matches_data.extend(result.data)
                logger.info(f"Found {len(result.data)} products in target_pest")
        except Exception as e:
            logger.warning(f"target_pest search failed: {e}")

        # If no results, search by pest type
        if not matches_data:
            try:
                pest_keywords = []
                if "‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡∏£‡∏≤" in disease_info.raw_analysis:
                    pest_keywords = ["‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡∏£‡∏≤", "‡πÇ‡∏£‡∏Ñ‡∏û‡∏∑‡∏ä"]
                elif "‡πÑ‡∏ß‡∏£‡∏±‡∏™" in disease_info.raw_analysis:
                    pest_keywords = ["‡πÑ‡∏ß‡∏£‡∏±‡∏™"]
                elif "‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä" in disease_info.raw_analysis or "‡πÅ‡∏°‡∏•‡∏á" in disease_info.raw_analysis:
                    pest_keywords = ["‡πÅ‡∏°‡∏•‡∏á", "‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä", "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢"]
                elif "‡∏ß‡∏±‡∏ä‡∏û‡∏∑‡∏ä" in disease_info.raw_analysis:
                    pest_keywords = ["‡∏ß‡∏±‡∏ä‡∏û‡∏∑‡∏ä", "‡∏´‡∏ç‡πâ‡∏≤"]

                for keyword in pest_keywords:
                    result = supabase_client.table('products')\
                        .select('*')\
                        .ilike('target_pest', f'%{keyword}%')\
                        .limit(5)\
                        .execute()

                    if result.data:
                        matches_data.extend(result.data)
                        logger.info(f"Found {len(result.data)} products for keyword: {keyword}")
                        break

            except Exception as e:
                logger.warning(f"Keyword search failed: {e}")

        if not matches_data:
            logger.warning("No products found with any search strategy")
            return []

        logger.info(f"Total products found: {len(matches_data)}")
        recommendations = build_recommendations_from_data(matches_data[:6], pest_name=pest_name)

        # Cache the results
        if recommendations:
            await set_to_cache("products", cache_key, [r.dict() for r in recommendations])

        return recommendations

    except Exception as e:
        logger.error(f"Product search failed: {e}", exc_info=True)
        return []


def build_recommendations_from_data(products_data: List[Dict], pest_name: str = None) -> List[ProductRecommendation]:
    """Build ProductRecommendation list from raw data

    Args:
        products_data: List of product dictionaries
        pest_name: Name of pest vector (if disease has one) - used to add context to recommendations
    """
    recommendations = []
    seen_products = set()

    # Sort to prioritize vector control products first if pest_name is provided
    if pest_name:
        # Put vector_control products first
        products_data = sorted(
            products_data,
            key=lambda x: (0 if x.get('recommendation_type') == 'vector_control' else 1, -x.get('hybrid_score', x.get('similarity', 0)))
        )

    for product in products_data:
        pname = product.get("product_name", "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠")

        if pname in seen_products:
            continue
        seen_products.add(pname)

        pest = product.get("target_pest", "")
        if not pest or pest.strip() == "":
            continue

        # ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏° prefix ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• product ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß

        rec = ProductRecommendation(
            product_name=pname,
            active_ingredient=product.get("active_ingredient", ""),
            target_pest=pest,
            applicable_crops=product.get("applicable_crops", ""),
            how_to_use=product.get("how_to_use", ""),
            usage_period=product.get("usage_period", ""),
            usage_rate=product.get("usage_rate", ""),
            link_product=product.get("link_product", ""),
            score=product.get("similarity", 0.7)
        )
        recommendations.append(rec)

    return recommendations

async def recommend_products_by_intent(question: str, keywords: dict) -> str:
    """‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ï‡∏≤‡∏° intent ‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ (‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ú‡∏•‡∏ú‡∏•‡∏¥‡∏ï, ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤, ‡∏Ø‡∏•‡∏Ø)"""
    try:
        intent = keywords.get('intent')
        logger.info(f"üéØ Intent-based recommendation: {intent}")
        logger.info(f"üìù Keywords: crops={keywords.get('crops')}, pests={keywords.get('pests')}")
        
        if not supabase_client:
            logger.error("‚ùå Supabase client not available")
            return await answer_product_question(question, keywords)
        
        if not openai_client:
            logger.error("‚ùå OpenAI client not available")
            return await answer_product_question(question, keywords)
        
        intent = keywords.get("intent")
        crops = keywords.get("crops", [])
        pests = keywords.get("pests", [])
        
        # Build search query based on intent
        search_queries = []
        
        if intent == "increase_yield":
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ú‡∏•‡∏ú‡∏•‡∏¥‡∏ï - search more broadly
            if crops:
                for crop in crops[:2]:
                    # Primary searches
                    search_queries.append(f"‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ú‡∏•‡∏ú‡∏•‡∏¥‡∏ï {crop}")
                    search_queries.append(f"‡∏ö‡∏≥‡∏£‡∏∏‡∏á {crop}")
                    search_queries.append(f"‡∏õ‡∏∏‡πã‡∏¢ {crop}")
                    search_queries.append(f"‡∏Æ‡∏≠‡∏£‡πå‡πÇ‡∏°‡∏ô {crop}")
                    # Also search by crop name directly
                    search_queries.append(crop)
                    # Problem prevention for yield
                    search_queries.append(f"‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÇ‡∏£‡∏Ñ {crop}")
                    search_queries.append(f"‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡∏ï‡πâ‡∏ô {crop}")
            else:
                search_queries.append("‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ú‡∏•‡∏ú‡∏•‡∏¥‡∏ï ‡∏õ‡∏∏‡πã‡∏¢ ‡∏Æ‡∏≠‡∏£‡πå‡πÇ‡∏°‡∏ô ‡∏ö‡∏≥‡∏£‡∏∏‡∏á")
        
        elif intent == "solve_problem":
            # ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä
            if pests and crops:
                for pest in pests[:2]:
                    for crop in crops[:2]:
                        search_queries.append(f"‡∏Å‡∏≥‡∏à‡∏±‡∏î {pest} {crop}")
                        # English variants
                        if any(c.isalpha() for c in crop) or any(c.isalpha() for c in pest):
                            search_queries.append(f"control {pest} {crop}")
                            search_queries.append(f"manage {pest} on {crop}")
            elif pests:
                for pest in pests[:2]:
                    search_queries.append(f"‡∏Å‡∏≥‡∏à‡∏±‡∏î {pest}")
                    if any(c.isalpha() for c in pest):
                        search_queries.append(f"control {pest}")
            elif crops:
                for crop in crops[:2]:
                    search_queries.append(f"‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÇ‡∏£‡∏Ñ {crop}")
                    if any(c.isalpha() for c in crop):
                        search_queries.append(f"prevent disease {crop}")
        
        elif intent == "general_care":
            # ‡∏î‡∏π‡πÅ‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
            if crops:
                for crop in crops[:2]:
                    search_queries.append(f"‡∏î‡∏π‡πÅ‡∏• {crop}")
                    search_queries.append(f"‡∏ö‡∏≥‡∏£‡∏∏‡∏á {crop}")
        
        else:
            # Default: product inquiry
            if crops:
                search_queries.append(f"‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå {crops[0]}")
            if pests:
                search_queries.append(f"‡∏Å‡∏≥‡∏à‡∏±‡∏î {pests[0]}")
        
        # Hybrid search for each query (Vector + Keyword combined)
        all_products = []
        logger.info(f"üîç Hybrid searching with {len(search_queries)} queries: {search_queries[:5]}")

        for query in search_queries[:5]:  # Top 5 queries
            try:
                logger.info(f"   ‚Üí Query: '{query}'")

                # Use hybrid search (Vector + Keyword)
                results = await hybrid_search_products(
                    query=query,
                    match_count=15,
                    vector_weight=0.5,  # Balanced weights for intent-based search
                    keyword_weight=0.5
                )

                if results:
                    all_products.extend(results)
                    logger.info(f"   ‚úì Found {len(results)} products (hybrid)")
                else:
                    logger.warning(f"   ‚ö†Ô∏è No products found")
            except Exception as e:
                logger.error(f"   ‚ùå Hybrid search failed: {e}", exc_info=True)
        
        # Remove duplicates and apply relevance boost
        seen = set()
        unique_products = []
        for p in all_products:
            pname = p.get('product_name', '')
            if pname and pname not in seen:
                seen.add(pname)
                # Apply relevance boost based on query terms
                boost = 0
                for query in search_queries[:3]:
                    boost += simple_relevance_boost(query, p)
                p['hybrid_score'] = p.get('hybrid_score', p.get('similarity', 0)) + (boost / 3)
                unique_products.append(p)

        # Sort by boosted score
        unique_products.sort(key=lambda x: x.get('hybrid_score', 0), reverse=True)

        # Re-rank with LLM if enabled and enough candidates
        if ENABLE_RERANKING and len(unique_products) > 6:
            logger.info("üîÑ Applying LLM re-ranking for intent-based search...")
            unique_products = await rerank_products_with_llm(
                query=question,
                products=unique_products[:15],
                top_k=10,
                openai_client=openai_client
            )

        logger.info(f"üì¶ Total products: {len(all_products)}, Unique: {len(unique_products)}")

        if not unique_products:
            # Fallback 1: Search by applicable_crops
            logger.warning("‚ö†Ô∏è No products from vector search, trying applicable_crops search")
            if crops:
                for crop in crops[:2]:
                    try:
                        result = supabase_client.table('products')\
                            .select('*')\
                            .ilike('applicable_crops', f'%{crop}%')\
                            .limit(10)\
                            .execute()

                        if result.data:
                            unique_products.extend(result.data)
                            logger.info(f"‚úì Found {len(result.data)} products for crop: {crop}")
                    except Exception as e:
                        logger.warning(f"applicable_crops search failed: {e}")

            # Fallback 2: Search by target_pest for common issues
            if not unique_products and pests:
                for pest in pests[:2]:
                    try:
                        result = supabase_client.table('products')\
                            .select('*')\
                            .ilike('target_pest', f'%{pest}%')\
                            .limit(10)\
                            .execute()

                        if result.data:
                            unique_products.extend(result.data)
                            logger.info(f"‚úì Found {len(result.data)} products for pest: {pest}")
                    except Exception as e:
                        logger.warning(f"target_pest search failed: {e}")

            # If still no products, fallback to keyword search
            if not unique_products:
                logger.warning("‚ö†Ô∏è No products found, trying keyword search")
                return await answer_product_question(question, keywords)
        
        # Log product names
        product_names = [p.get('product_name', 'N/A') for p in unique_products[:5]]
        logger.info(f"üìã Top products: {', '.join(product_names)}")
        
        # Use Gemini to filter and create natural response
        products_text = ""
        for idx, p in enumerate(unique_products[:15], 1):  # Top 15 for Gemini
            products_text += f"\n[{idx}] {p.get('product_name', 'N/A')}"
            products_text += f"\n    ‚Ä¢ ‡∏™‡∏≤‡∏£‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: {p.get('active_ingredient', 'N/A')}"
            products_text += f"\n    ‚Ä¢ ‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏à‡∏±‡∏î‡πÑ‡∏î‡πâ: {p.get('target_pest', 'N/A')[:150]}"
            products_text += f"\n    ‚Ä¢ ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ: {p.get('how_to_use', 'N/A')[:200]}"
            products_text += f"\n    ‚Ä¢ ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ: {p.get('usage_rate', 'N/A')}"
            if p.get('usage_period'):
                products_text += f"\n    ‚Ä¢ ‡∏ä‡πà‡∏ß‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ: {p.get('usage_period')}"
            products_text += f"\n    ‚Ä¢ ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏û‡∏∑‡∏ä: {p.get('applicable_crops', 'N/A')[:100]}"
            products_text += f"\n    ‚Ä¢ Similarity: {p.get('similarity', 0):.0%}\n"
        
        # Create intent-specific prompt
        if intent == "increase_yield":
            prompt = f"""‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏à‡∏≤‡∏Å ICP Ladda

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏Å‡∏©‡∏ï‡∏£‡∏Å‡∏£: {question}

‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö (‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ):
{products_text}

üö® **‡∏Å‡∏é‡∏ó‡∏µ‡πà‡∏´‡πâ‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏°‡∏¥‡∏î**:
1. ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
2.  ‡∏´‡πâ‡∏≤‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡πÉ‡∏´‡∏°‡πà
3. ‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£
4. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° ‡πÉ‡∏´‡πâ‡∏ö‡∏≠‡∏Å‡∏ï‡∏£‡∏á‡πÜ‡∏ß‡πà‡∏≤ "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö"

üìã **‡∏ß‡∏¥‡∏ò‡∏µ‡∏ï‡∏≠‡∏ö**:
1. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 3-5 ‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô
2. ‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
3. ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á ‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ï‡πà‡∏á‡πÄ‡∏ï‡∏¥‡∏°
4. ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô‡∏ï‡∏≤‡∏°‡∏ô‡∏µ‡πâ:
   - ‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)
   - ‡∏™‡∏≤‡∏£‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)
   - ‡∏ä‡πà‡∏ß‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)
   - ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏û‡∏∑‡∏ä (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)
   - ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)
   - ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)

5. ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡∏û‡∏£‡πâ‡∏≠‡∏° emoji
6. ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ markdown

‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:"""
        
        elif intent == "solve_problem":
            prompt = f"""‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏à‡∏≤‡∏Å ICP Ladda

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏Å‡∏©‡∏ï‡∏£‡∏Å‡∏£: {question}

‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö (‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ):
{products_text}

‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä‡∏ó‡∏µ‡πà‡∏û‡∏ö: {', '.join(pests) if pests else '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'}
‡∏û‡∏∑‡∏ä‡∏ó‡∏µ‡πà‡∏õ‡∏•‡∏π‡∏Å: {', '.join(crops) if crops else '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'}

üö® **‡∏Å‡∏é‡∏ó‡∏µ‡πà‡∏´‡πâ‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏°‡∏¥‡∏î**:
1. ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
2. ‡∏´‡πâ‡∏≤‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡πÉ‡∏´‡∏°‡πà
3. ‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£
4. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏à‡∏±‡∏î‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏î‡πâ

üìã **‡∏ß‡∏¥‡∏ò‡∏µ‡∏ï‡∏≠‡∏ö**:
1. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 3-5 ‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô
2. ‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
3. ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á ‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ï‡πà‡∏á‡πÄ‡∏ï‡∏¥‡∏°
4. ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô‡∏ï‡∏≤‡∏°‡∏ô‡∏µ‡πâ:
   - ‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)
   - ‡∏™‡∏≤‡∏£‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)
   - ‡∏ä‡πà‡∏ß‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)
   - ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏û‡∏∑‡∏ä (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)
   - ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)
   - ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)

5. ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡∏û‡∏£‡πâ‡∏≠‡∏° emoji
6. ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ markdown

‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:"""
        
        else:
            # General product inquiry
            prompt = f"""‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏à‡∏≤‡∏Å ICP Ladda

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏Å‡∏©‡∏ï‡∏£‡∏Å‡∏£: {question}

‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö (‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ):
{products_text}

üö® **‡∏Å‡∏é‡∏ó‡∏µ‡πà‡∏´‡πâ‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏°‡∏¥‡∏î**:
1. ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
2. ‡∏´‡πâ‡∏≤‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡πÉ‡∏´‡∏°‡πà
3. ‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£

üìã **‡∏ß‡∏¥‡∏ò‡∏µ‡∏ï‡∏≠‡∏ö**:
1. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 3-5 ‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô  
2. ‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠ exact ‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
3. ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£
4. ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡∏û‡∏£‡πâ‡∏≠‡∏° emoji
5. ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ markdown

‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:"""
        
        # Check if AI is available
        if not openai_client:
            logger.warning("OpenAI not available, using simple format")
            return await format_product_list_simple(unique_products[:5], question, intent)
        
        try:
            response = await openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "You are a strict product assistant. ONLY recommend products from the provided list. Never create or suggest products not in the list."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,  # ‡∏•‡∏î‡∏•‡∏á‡∏à‡∏≤‡∏Å 0.7 ‚Üí 0.1 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå
                max_tokens=800
            )
            answer = response.choices[0].message.content.strip()
            answer = answer.replace("```", "").replace("**", "").replace("##", "")
            
            # Add footer
            answer += "\n\n" + "="*40
            answer += "\nüìö ‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î:"
            answer += "\nüîó https://www.icpladda.com/about/"
            answer += "\n\nüí° ‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡πà‡∏∞ üòä"
            
            logger.info(f"‚úì Intent-based answer generated ({intent})")
            return answer
            
        except Exception as e:
            logger.error(f"AI generation failed: {e}", exc_info=True)
            # Fallback to simple product list
            return await format_product_list_simple(unique_products[:5], question, intent)
        
    except Exception as e:
        logger.error(f"Error in intent-based recommendation: {e}", exc_info=True)
        return await answer_product_question(question, keywords)

async def format_product_list_simple(products: list, question: str, intent: str) -> str:
    """Format product list as simple fallback"""
    if intent == "increase_yield":
        header = "üå± ‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ú‡∏•‡∏ú‡∏•‡∏¥‡∏ï:\n"
    elif intent == "solve_problem":
        header = "üíä ‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä:\n"
    else:
        header = "üì¶ ‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:\n"
    
    response = header
    for idx, p in enumerate(products, 1):
        response += f"\n{idx}. {p.get('product_name', 'N/A')}"
        
        # ‡∏™‡∏≤‡∏£‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
        if p.get('active_ingredient'):
            response += f"\n   - ‡∏™‡∏≤‡∏£‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: {p.get('active_ingredient')}"
        
        # ‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏à‡∏±‡∏î‡πÑ‡∏î‡πâ
        if p.get('target_pest'):
            pest = p.get('target_pest')[:150] + "..." if len(p.get('target_pest', '')) > 150 else p.get('target_pest', '')
            response += f"\n   - ‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏à‡∏±‡∏î‡πÑ‡∏î‡πâ: {pest}"
        
        # ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ
        if p.get('how_to_use'):
            how_to = p.get('how_to_use')[:200] + "..." if len(p.get('how_to_use', '')) > 200 else p.get('how_to_use', '')
            response += f"\n   - ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ: {how_to}"
        
        # ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ
        if p.get('usage_rate'):
            response += f"\n   - ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ: {p.get('usage_rate')}"
        
        # ‡∏ä‡πà‡∏ß‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ
        if p.get('usage_period'):
            response += f"\n   - ‡∏ä‡πà‡∏ß‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ: {p.get('usage_period')}"
        
        # ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏û‡∏∑‡∏ä
        if p.get('applicable_crops'):
            crops = p.get('applicable_crops')[:100] + "..." if len(p.get('applicable_crops', '')) > 100 else p.get('applicable_crops', '')
            response += f"\n   - ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏û‡∏∑‡∏ä: {crops}"
        
        response += "\n"
    
    response += "\nüìö ‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°: https://www.icpladda.com/about/"
    return response

# =============================================================================
# Matching Score Product Recommendation
# =============================================================================

def calculate_matching_score(product: Dict, disease_name: str, plant_type: str, growth_stage: str) -> float:
    """
    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Matching Score ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á product ‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• user

    Weights:
    - 40% - ‡πÇ‡∏£‡∏Ñ/‡πÅ‡∏°‡∏•‡∏á ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö target_pest
    - 30% - ‡∏û‡∏∑‡∏ä ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö applicable_crops
    - 30% - ‡∏£‡∏∞‡∏¢‡∏∞ ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö usage_period

    Returns: score 0.0 - 1.0
    """
    score = 0.0

    target_pest = (product.get("target_pest") or "").lower()
    applicable_crops = (product.get("applicable_crops") or "").lower()
    usage_period = (product.get("usage_period") or "").lower()

    disease_lower = disease_name.lower()
    plant_lower = plant_type.lower() if plant_type else ""
    stage_lower = growth_stage.lower() if growth_stage else ""

    # 1. Disease/Pest Match (40%)
    disease_score = 0.0

    # Direct disease name match
    if disease_lower and disease_lower in target_pest:
        disease_score = 1.0
    else:
        # Check partial matches
        disease_keywords = disease_lower.replace("‡πÇ‡∏£‡∏Ñ", "").strip().split()
        for kw in disease_keywords:
            if len(kw) > 2 and kw in target_pest:
                disease_score = max(disease_score, 0.7)
                break

        # Check if product targets related issues
        pest_check_query, pest_name, _ = get_search_query_for_disease(disease_name)
        if pest_name:
            # Disease has vector - check if product targets the vector
            pest_keywords = pest_name.lower().split()
            for kw in pest_keywords:
                if len(kw) > 2 and kw in target_pest:
                    disease_score = max(disease_score, 0.9)
                    break

        # Generic disease type match (‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡∏£‡∏≤, ‡πÑ‡∏ß‡∏£‡∏±‡∏™, etc.)
        disease_types = ["‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡∏£‡∏≤", "‡πÑ‡∏ß‡∏£‡∏±‡∏™", "‡πÅ‡∏ö‡∏Ñ‡∏ó‡∏µ‡πÄ‡∏£‡∏µ‡∏¢", "‡πÅ‡∏°‡∏•‡∏á", "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢", "‡∏´‡∏ô‡∏≠‡∏ô"]
        for dt in disease_types:
            if dt in disease_lower and dt in target_pest:
                disease_score = max(disease_score, 0.5)
                break

    score += disease_score * 0.4

    # 2. Plant/Crop Match (30%)
    plant_score = 0.0

    if plant_lower:
        # Direct plant match
        if plant_lower in applicable_crops:
            plant_score = 1.0
        else:
            # Check plant synonyms/variants
            plant_synonyms = {
                "‡∏Ç‡πâ‡∏≤‡∏ß": ["‡∏Ç‡πâ‡∏≤‡∏ß", "rice", "‡∏ô‡∏≤‡∏Ç‡πâ‡∏≤‡∏ß"],
                "‡∏°‡∏∞‡∏°‡πà‡∏ß‡∏á": ["‡∏°‡∏∞‡∏°‡πà‡∏ß‡∏á", "mango"],
                "‡∏ó‡∏∏‡πÄ‡∏£‡∏µ‡∏¢‡∏ô": ["‡∏ó‡∏∏‡πÄ‡∏£‡∏µ‡∏¢‡∏ô", "durian"],
                "‡∏™‡πâ‡∏°": ["‡∏™‡πâ‡∏°", "‡∏°‡∏∞‡∏ô‡∏≤‡∏ß", "citrus", "‡∏™‡πâ‡∏°‡πÇ‡∏≠"],
                "‡∏ú‡∏±‡∏Å": ["‡∏ú‡∏±‡∏Å", "vegetable", "‡∏ú‡∏±‡∏Å‡∏Å‡∏≤‡∏î", "‡∏Ñ‡∏∞‡∏ô‡πâ‡∏≤", "‡∏Å‡∏∞‡∏´‡∏•‡πà‡∏≥"],
                "‡∏°‡∏±‡∏ô‡∏™‡∏≥‡∏õ‡∏∞‡∏´‡∏•‡∏±‡∏á": ["‡∏°‡∏±‡∏ô", "cassava", "‡∏°‡∏±‡∏ô‡∏™‡∏≥‡∏õ‡∏∞‡∏´‡∏•‡∏±‡∏á"],
                "‡∏Ç‡πâ‡∏≤‡∏ß‡πÇ‡∏û‡∏î": ["‡∏Ç‡πâ‡∏≤‡∏ß‡πÇ‡∏û‡∏î", "corn", "maize"],
                "‡∏≠‡πâ‡∏≠‡∏¢": ["‡∏≠‡πâ‡∏≠‡∏¢", "sugarcane"],
                "‡∏•‡∏≥‡πÑ‡∏¢": ["‡∏•‡∏≥‡πÑ‡∏¢", "longan"],
                "‡∏¢‡∏≤‡∏á‡∏û‡∏≤‡∏£‡∏≤": ["‡∏¢‡∏≤‡∏á", "rubber", "‡∏¢‡∏≤‡∏á‡∏û‡∏≤‡∏£‡∏≤"],
                "‡∏õ‡∏≤‡∏•‡πå‡∏°": ["‡∏õ‡∏≤‡∏•‡πå‡∏°", "palm", "‡∏õ‡∏≤‡∏•‡πå‡∏°‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô"],
                "‡∏û‡∏£‡∏¥‡∏Å": ["‡∏û‡∏£‡∏¥‡∏Å", "chili", "pepper"],
                "‡∏°‡∏∞‡πÄ‡∏Ç‡∏∑‡∏≠": ["‡∏°‡∏∞‡πÄ‡∏Ç‡∏∑‡∏≠", "eggplant", "tomato", "‡∏°‡∏∞‡πÄ‡∏Ç‡∏∑‡∏≠‡πÄ‡∏ó‡∏®"],
            }

            for main_plant, synonyms in plant_synonyms.items():
                if any(s in plant_lower for s in synonyms):
                    if any(s in applicable_crops for s in synonyms):
                        plant_score = 0.9
                        break
                    elif main_plant in applicable_crops:
                        plant_score = 0.8
                        break

            # Generic crop match
            if plant_score == 0 and ("‡∏û‡∏∑‡∏ä" in applicable_crops or "‡∏ó‡∏∏‡∏Å‡∏ä‡∏ô‡∏¥‡∏î" in applicable_crops):
                plant_score = 0.3

    score += plant_score * 0.3

    # 3. Growth Stage Match (30%)
    stage_score = 0.0

    if stage_lower:
        # Extract stage keywords from user input
        stage_keywords_map = {
            "‡∏Å‡∏•‡πâ‡∏≤": ["‡∏Å‡∏•‡πâ‡∏≤", "‡∏õ‡∏±‡∏Å‡∏î‡∏≥", "‡πÄ‡∏û‡∏≤‡∏∞", "‡∏ï‡πâ‡∏ô‡∏≠‡πà‡∏≠‡∏ô", "seedling"],
            "‡πÅ‡∏ï‡∏Å‡∏Å‡∏≠": ["‡πÅ‡∏ï‡∏Å‡∏Å‡∏≠", "tillering", "‡πÅ‡∏ï‡∏Å‡πÉ‡∏ö"],
            "‡∏ï‡∏±‡πâ‡∏á‡∏ó‡πâ‡∏≠‡∏á": ["‡∏ï‡∏±‡πâ‡∏á‡∏ó‡πâ‡∏≠‡∏á", "booting", "‡∏ó‡πâ‡∏≠‡∏á"],
            "‡∏≠‡∏≠‡∏Å‡∏£‡∏ß‡∏á": ["‡∏≠‡∏≠‡∏Å‡∏£‡∏ß‡∏á", "flowering", "‡∏≠‡∏≠‡∏Å‡∏î‡∏≠‡∏Å", "‡∏£‡∏ß‡∏á", "heading"],
            "‡∏≠‡∏≠‡∏Å‡∏î‡∏≠‡∏Å": ["‡∏≠‡∏≠‡∏Å‡∏î‡∏≠‡∏Å", "‡∏î‡∏≠‡∏Å", "flower", "‡∏ö‡∏≤‡∏ô"],
            "‡∏ï‡∏¥‡∏î‡∏ú‡∏•": ["‡∏ï‡∏¥‡∏î‡∏ú‡∏•", "‡∏ú‡∏•‡∏≠‡πà‡∏≠‡∏ô", "fruiting", "‡∏ï‡∏¥‡∏î‡∏•‡∏π‡∏Å"],
            "‡∏ú‡∏•‡πÇ‡∏ï": ["‡∏ú‡∏•‡πÇ‡∏ï", "‡∏Ç‡∏¢‡∏≤‡∏¢‡∏ú‡∏•", "fruit development"],
            "‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß": ["‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß", "harvest", "‡∏™‡∏∏‡∏Å"],
            "‡∏ó‡∏∏‡∏Å‡∏£‡∏∞‡∏¢‡∏∞": ["‡∏ó‡∏∏‡∏Å‡∏£‡∏∞‡∏¢‡∏∞", "‡∏ï‡∏•‡∏≠‡∏î", "all stage"],
        }

        # Check stage match in usage_period
        for stage_name, keywords in stage_keywords_map.items():
            # Check if user's stage matches
            user_stage_match = any(kw in stage_lower for kw in keywords)

            if user_stage_match:
                # Check if product's usage_period covers this stage
                if any(kw in usage_period for kw in keywords):
                    stage_score = 1.0
                    break
                elif "‡∏ó‡∏∏‡∏Å‡∏£‡∏∞‡∏¢‡∏∞" in usage_period or "‡∏ï‡∏•‡∏≠‡∏î" in usage_period:
                    stage_score = 0.7
                    break

        # If no specific match, check for general compatibility
        if stage_score == 0:
            # Extract day ranges if present (e.g., "0-20 ‡∏ß‡∏±‡∏ô")
            import re
            user_days = re.findall(r'(\d+)', stage_lower)
            product_days = re.findall(r'(\d+)', usage_period)

            if user_days and product_days:
                # Check if ranges overlap
                try:
                    user_mid = sum(int(d) for d in user_days[:2]) / len(user_days[:2])
                    prod_mid = sum(int(d) for d in product_days[:2]) / len(product_days[:2])

                    # If within 30 days, partial match
                    if abs(user_mid - prod_mid) < 30:
                        stage_score = 0.5
                except:
                    pass

    score += stage_score * 0.3

    return score


async def retrieve_products_with_matching_score(
    detection_result: DiseaseDetectionResult,
    plant_type: str,
    growth_stage: str
) -> List[ProductRecommendation]:
    """
    ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Matching Score

    Flow:
    1. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏à‡∏≤‡∏Å Hybrid Search ‡∏ï‡∏≤‡∏°‡πÇ‡∏£‡∏Ñ/‡πÅ‡∏°‡∏•‡∏á
    2. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Matching Score ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤
    3. ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ï‡∏≤‡∏° score
    4. Return top products

    Args:
        detection_result: ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢‡πÇ‡∏£‡∏Ñ
        plant_type: ‡∏ä‡∏ô‡∏¥‡∏î‡∏û‡∏∑‡∏ä‡∏ó‡∏µ‡πà‡∏õ‡∏•‡∏π‡∏Å
        growth_stage: ‡∏£‡∏∞‡∏¢‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏à‡∏£‡∏¥‡∏ç‡πÄ‡∏ï‡∏¥‡∏ö‡πÇ‡∏ï

    Returns:
        List[ProductRecommendation] ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏° matching score
    """
    try:
        logger.info("üéØ Retrieving products with Matching Score")
        logger.info(f"   Disease: {detection_result.disease_name}")
        logger.info(f"   Plant: {plant_type}")
        logger.info(f"   Stage: {growth_stage}")

        if not supabase_client:
            logger.warning("Supabase not configured")
            return []

        disease_name = detection_result.disease_name

        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÇ‡∏£‡∏Ñ‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡πÅ‡∏°‡∏•‡∏á‡∏û‡∏≤‡∏´‡∏∞‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        pest_type = ""
        if hasattr(detection_result, 'raw_analysis') and detection_result.raw_analysis:
            if "‡πÑ‡∏ß‡∏£‡∏±‡∏™" in detection_result.raw_analysis:
                pest_type = "‡πÑ‡∏ß‡∏£‡∏±‡∏™"

        vector_search_query, pest_name, disease_treatment_query = get_search_query_for_disease(disease_name, pest_type)

        if pest_name:
            logger.info(f"üêõ ‡πÇ‡∏£‡∏Ñ‡∏°‡∏µ‡∏û‡∏≤‡∏´‡∏∞: {pest_name}")

        # 1. Hybrid Search for products
        all_results = []

        # Primary search (vector control if has pest, or disease treatment)
        search_query = vector_search_query
        if plant_type:
            search_query = f"{search_query} {plant_type}"

        logger.info(f"üîç Primary search: {search_query}")

        hybrid_results = await hybrid_search_products(
            query=search_query,
            match_count=20,
            vector_weight=0.5,
            keyword_weight=0.5
        )

        if hybrid_results:
            all_results.extend(hybrid_results)
            logger.info(f"   ‚Üí Found {len(hybrid_results)} products")

        # Secondary search for disease treatment (if has vector)
        if pest_name and disease_treatment_query:
            if plant_type:
                disease_treatment_query = f"{disease_treatment_query} {plant_type}"

            logger.info(f"üîç Disease treatment search: {disease_treatment_query}")

            disease_results = await hybrid_search_products(
                query=disease_treatment_query,
                match_count=15,
                vector_weight=0.5,
                keyword_weight=0.5
            )

            if disease_results:
                all_results.extend(disease_results)
                logger.info(f"   ‚Üí Found {len(disease_results)} disease treatment products")

        # 2. Calculate Matching Score for each product
        scored_products = []
        seen_products = set()

        for product in all_results:
            pname = product.get("product_name", "")
            if not pname or pname in seen_products:
                continue
            seen_products.add(pname)

            # Skip products without target_pest
            if not product.get("target_pest"):
                continue

            # Calculate matching score
            match_score = calculate_matching_score(
                product=product,
                disease_name=disease_name,
                plant_type=plant_type,
                growth_stage=growth_stage
            )

            # Combine hybrid score with matching score
            hybrid_score = product.get("hybrid_score", product.get("similarity", 0))

            # Final score: 50% matching + 50% hybrid (search relevance)
            final_score = (match_score * 0.5) + (hybrid_score * 0.5)

            product["matching_score"] = match_score
            product["final_score"] = final_score

            scored_products.append(product)

        # 3. Sort by final score
        scored_products.sort(key=lambda x: x.get("final_score", 0), reverse=True)

        # Log top products
        logger.info(f"üìä Top products by Matching Score:")
        for p in scored_products[:5]:
            logger.info(f"   ‚Üí {p.get('product_name')}: "
                       f"match={p.get('matching_score', 0):.2f}, "
                       f"final={p.get('final_score', 0):.2f}")

        # 4. Filter and build recommendations
        # Keep products with reasonable score (>0.15) or top 6
        min_score = 0.15
        filtered_products = [p for p in scored_products if p.get("final_score", 0) >= min_score]

        if len(filtered_products) < 3:
            # If too few pass threshold, take top 6 anyway
            filtered_products = scored_products[:6]
        else:
            filtered_products = filtered_products[:6]

        if not filtered_products:
            logger.warning("‚ö†Ô∏è No products found with matching score")
            return []

        # Build recommendations
        recommendations = []
        for product in filtered_products:
            rec = ProductRecommendation(
                product_name=product.get("product_name", "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠"),
                active_ingredient=product.get("active_ingredient", ""),
                target_pest=product.get("target_pest", ""),
                applicable_crops=product.get("applicable_crops", ""),
                how_to_use=product.get("how_to_use", ""),
                usage_period=product.get("usage_period", ""),
                usage_rate=product.get("usage_rate", ""),
                link_product=product.get("link_product", ""),
                score=product.get("final_score", 0)
            )
            recommendations.append(rec)

        logger.info(f"‚úì Returning {len(recommendations)} products with matching score")
        return recommendations

    except Exception as e:
        logger.error(f"Error in retrieve_products_with_matching_score: {e}", exc_info=True)
        return []


async def answer_product_question(question: str, keywords: dict) -> str:
    """Answer product-specific questions with high accuracy"""
    try:
        logger.info(f"Product-specific query: {question[:50]}...")
        
        if not supabase_client:
            return "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡∏£‡∏∞‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ"
        
        products_data = []
        
        # Search by pest/disease
        if keywords["pests"]:
            for pest in keywords["pests"][:2]:
                result = supabase_client.table('products')\
                    .select('*')\
                    .ilike('target_pest', f'%{pest}%')\
                    .limit(5)\
                    .execute()
                if result.data:
                    products_data.extend(result.data)
        
        # Search by crop
        if keywords["crops"]:
            for crop in keywords["crops"][:2]:
                result = supabase_client.table('products')\
                    .select('*')\
                    .ilike('applicable_crops', f'%{crop}%')\
                    .limit(5)\
                    .execute()
                if result.data:
                    products_data.extend(result.data)
        
        # Search by product name
        if keywords["products"]:
            for prod in keywords["products"]:
                if len(prod) > 3:
                    result = supabase_client.table('products')\
                        .select('*')\
                        .ilike('product_name', f'%{prod}%')\
                        .limit(5)\
                        .execute()
                    if result.data:
                        products_data.extend(result.data)
        
        # If no specific keywords, get general products
        if not products_data:
            result = supabase_client.table('products')\
                .select('*')\
                .limit(10)\
                .execute()
            if result.data:
                products_data = result.data
        
        if not products_data:
            return "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠‡∏û‡∏∑‡∏ä‡∏´‡∏£‡∏∑‡∏≠‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏à‡∏±‡∏î‡∏Ñ‡πà‡∏∞ üå±"
        
        # Remove duplicates
        seen = set()
        unique_products = []
        for p in products_data:
            pname = p.get('product_name', '')
            if pname and pname not in seen:
                seen.add(pname)
                unique_products.append(p)
        
        # Use Gemini to filter and format response
        products_text = ""
        for idx, p in enumerate(unique_products[:10], 1):
            products_text += f"\n[{idx}] {p.get('product_name', 'N/A')}"
            products_text += f"\n    ‡∏™‡∏≤‡∏£‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: {p.get('active_ingredient', 'N/A')}"
            products_text += f"\n    ‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä: {p.get('target_pest', 'N/A')[:100]}"
            products_text += f"\n    ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏û‡∏∑‡∏ä: {p.get('applicable_crops', 'N/A')[:80]}"
            products_text += f"\n    ‡∏ä‡πà‡∏ß‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ: {p.get('usage_period', 'N/A')}"
            products_text += f"\n    ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡πÉ‡∏ä‡πâ: {p.get('usage_rate', 'N/A')}"
            products_text += "\n"
        
        prompt = f"""‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≥‡∏à‡∏±‡∏î‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä‡∏Ç‡∏≠‡∏á ICP Ladda

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏Å‡∏©‡∏ï‡∏£‡∏Å‡∏£: {question}

‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö:
{products_text}

‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö:
1. **‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°** - ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡∏©‡∏ï‡∏£‡∏Å‡∏£‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏∞‡πÑ‡∏£
2. **‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°** - ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 3-5 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
3. **‡∏à‡∏±‡∏î‡∏•‡∏≥‡∏î‡∏±‡∏ö** - ‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏Å‡πà‡∏≠‡∏ô
4. **‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î**:
   - ‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå
   - ‡∏™‡∏≤‡∏£‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
   - ‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏à‡∏±‡∏î‡πÑ‡∏î‡πâ
   - ‡∏û‡∏∑‡∏ä‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ
   - ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ
   - ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡πÇ‡∏î‡∏¢‡∏¢‡πà‡∏≠
5. **‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥**:
   - ‡∏≠‡πà‡∏≤‡∏ô‡∏â‡∏•‡∏≤‡∏Å‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ
   - ‡πÉ‡∏ä‡πâ‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏ï‡∏±‡∏ß
   - ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÉ‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏•‡πá‡∏Å‡∏Å‡πà‡∏≠‡∏ô
6. **‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏á‡πà‡∏≤‡∏¢‡πÜ** 
7. **‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ markdown** - ‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤

**‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å**:
- ‡∏ñ‡πâ‡∏≤‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏û‡∏∑‡∏ä‡πÄ‡∏â‡∏û‡∏≤‡∏∞ ‚Üí ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏û‡∏∑‡∏ä‡∏ô‡∏±‡πâ‡∏ô‡πÑ‡∏î‡πâ
- ‡∏ñ‡πâ‡∏≤‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä ‚Üí ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏à‡∏±‡∏î‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä‡∏ô‡∏±‡πâ‡∏ô‡πÑ‡∏î‡πâ
- ‡∏ñ‡πâ‡∏≤‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‚Üí ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏¢‡∏≠‡∏î‡∏ô‡∏¥‡∏¢‡∏° 3-5 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£

‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:"""

        try:
            response = await openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "You are an agricultural product expert."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=800
            )
            answer = response.choices[0].message.content.strip()
            answer = answer.replace("```", "").replace("**", "").replace("##", "")
            
            # Add footer
            answer += "\n\n" + "="*40
            answer += "\nüìö ‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î:"
            answer += "\nüîó https://www.icpladda.com/about/"
            answer += "\n\nüí° ‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡πà‡∏∞ üòä"
            
            logger.info("‚úì Product answer generated successfully")
            return answer
            
        except Exception as e:
            logger.error(f"Gemini generation failed: {e}")
            # Fallback: return top 3 products directly
            response = "üíä ‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏à‡∏≤‡∏Å ICP Ladda:\n"
            for idx, p in enumerate(unique_products[:3], 1):
                response += f"\n{idx}. {p.get('product_name')}"
                if p.get('active_ingredient'):
                    response += f"\n   ‡∏™‡∏≤‡∏£‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: {p.get('active_ingredient')}"
                if p.get('target_pest'):
                    pest = p.get('target_pest')[:80] + "..." if len(p.get('target_pest', '')) > 80 else p.get('target_pest', '')
                    response += f"\n   ‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä: {pest}"
                if p.get('applicable_crops'):
                    crops = p.get('applicable_crops')[:60] + "..." if len(p.get('applicable_crops', '')) > 60 else p.get('applicable_crops', '')
                    response += f"\n   ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏û‡∏∑‡∏ä: {crops}"
                if p.get('usage_period'):
                    response += f"\n   ‡∏ä‡πà‡∏ß‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ: {p.get('usage_period')}"
                if p.get('usage_rate'):
                    response += f"\n   ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡πÉ‡∏ä‡πâ: {p.get('usage_rate')}"
                response += "\n"
            
            response += "\nüìö ‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°: https://www.icpladda.com/about/"
            return response
        
    except Exception as e:
        logger.error(f"Error in product Q&A: {e}", exc_info=True)
        return "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏∞ üôè"
