import logging
import json
from typing import List, Dict, Tuple
from app.models import DiseaseDetectionResult, ProductRecommendation
from app.services.services import supabase_client, openai_client
from app.services.cache import get_from_cache, set_to_cache
from app.utils.text_processing import extract_keywords_from_question
from app.services.reranker import rerank_products_with_llm, simple_relevance_boost

logger = logging.getLogger(__name__)

# Configuration for re-ranking
ENABLE_RERANKING = True  # Set to False to disable re-ranking for faster response

# =============================================================================
# ‡πÇ‡∏£‡∏Ñ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÅ‡∏°‡∏•‡∏á‡∏û‡∏≤‡∏´‡∏∞ ‚Üí ‡∏Ñ‡∏ß‡∏£‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á‡πÅ‡∏ó‡∏ô‡∏¢‡∏≤‡∏Å‡∏≥‡∏à‡∏±‡∏î‡πÄ‡∏ä‡∏∑‡πâ‡∏≠
# =============================================================================
VECTOR_DISEASES = {
    # =========================================================================
    # üåæ ‡∏Ç‡πâ‡∏≤‡∏ß (RICE) - ‡πÇ‡∏£‡∏Ñ‡πÑ‡∏ß‡∏£‡∏±‡∏™‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏≤‡∏´‡∏∞
    # =========================================================================
    "‡πÇ‡∏£‡∏Ñ‡∏à‡∏π‡πã": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏•", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏• ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á BPH"},
    "rice ragged stunt": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏•", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏• ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á BPH"},
    "ragged stunt": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏•", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏• ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á BPH"},
    "‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡∏´‡∏á‡∏¥‡∏Å": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏•", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏• ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á BPH"},
    "rice grassy stunt": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏•", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏• ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á BPH"},
    "grassy stunt": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏•", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏Å‡∏£‡∏∞‡πÇ‡∏î‡∏î‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡∏ï‡∏≤‡∏• ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á BPH"},
    "‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡∏™‡∏µ‡∏™‡πâ‡∏°": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á GLH"},
    "rice orange leaf": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á GLH"},
    "orange leaf": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á GLH"},
    "‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡∏Ç‡∏≤‡∏ß‡∏Ç‡πâ‡∏≤‡∏ß": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á GLH"},
    "rice tungro": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á GLH"},
    "tungro": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á GLH"},
    "‡πÇ‡∏£‡∏Ñ‡∏ó‡∏±‡∏á‡πÇ‡∏£": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á GLH"},

    # =========================================================================
    # üç¨ ‡∏≠‡πâ‡∏≠‡∏¢ (SUGARCANE) - ‡πÇ‡∏£‡∏Ñ‡πÑ‡∏ß‡∏£‡∏±‡∏™‡πÅ‡∏•‡∏∞‡πÑ‡∏ü‡πÇ‡∏ï‡∏û‡∏•‡∏≤‡∏™‡∏°‡∏≤
    # =========================================================================
    "‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡∏Ç‡∏≤‡∏ß‡∏≠‡πâ‡∏≠‡∏¢": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏≠‡πâ‡∏≠‡∏¢"},
    "sugarcane white leaf": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏≠‡πâ‡∏≠‡∏¢"},
    "white leaf": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á"},
    "‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡∏î‡πà‡∏≤‡∏á‡∏≠‡πâ‡∏≠‡∏¢": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏≠‡πâ‡∏≠‡∏¢"},
    "sugarcane mosaic": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á"},
    "‡πÇ‡∏£‡∏Ñ‡∏Å‡∏≠‡∏ï‡∏∞‡πÑ‡∏Ñ‡∏£‡πâ": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏≠‡πâ‡∏≠‡∏¢"},
    "sugarcane grassy shoot": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á"},

    # =========================================================================
    # ü•≠ ‡∏°‡∏∞‡∏°‡πà‡∏ß‡∏á (MANGO) - ‡πÇ‡∏£‡∏Ñ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÅ‡∏°‡∏•‡∏á‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
    # =========================================================================
    "‡πÇ‡∏£‡∏Ñ‡∏ä‡πà‡∏≠‡∏î‡∏≥‡∏°‡∏∞‡∏°‡πà‡∏ß‡∏á": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô‡∏°‡∏∞‡∏°‡πà‡∏ß‡∏á ‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏ü", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô‡∏°‡∏∞‡∏°‡πà‡∏ß‡∏á ‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏ü ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á"},
    "mango malformation": {"pest": "‡πÑ‡∏£‡∏™‡∏µ‡πà‡∏Ç‡∏≤", "search_query": "‡πÑ‡∏£‡∏™‡∏µ‡πà‡∏Ç‡∏≤ ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÑ‡∏£ ‡∏°‡∏∞‡∏°‡πà‡∏ß‡∏á"},
    "‡πÇ‡∏£‡∏Ñ‡∏¢‡∏≠‡∏î‡πÑ‡∏´‡∏°‡πâ‡∏°‡∏∞‡∏°‡πà‡∏ß‡∏á": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô‡∏°‡∏∞‡∏°‡πà‡∏ß‡∏á", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô‡∏°‡∏∞‡∏°‡πà‡∏ß‡∏á ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á"},
    "mango hopper burn": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô‡∏°‡∏∞‡∏°‡πà‡∏ß‡∏á", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô‡∏°‡∏∞‡∏°‡πà‡∏ß‡∏á ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á"},

    # =========================================================================
    # üå≥ ‡∏•‡∏≥‡πÑ‡∏¢ (LONGAN) - ‡πÇ‡∏£‡∏Ñ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÅ‡∏°‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏≤‡∏´‡∏∞
    # =========================================================================
    "‡πÇ‡∏£‡∏Ñ‡∏û‡∏∏‡πà‡∏°‡πÑ‡∏°‡πâ‡∏Å‡∏ß‡∏≤‡∏î": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡πÑ‡∏£‡∏™‡∏µ‡πà‡∏Ç‡∏≤", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡πÑ‡∏£‡∏™‡∏µ‡πà‡∏Ç‡∏≤ ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏•‡∏≥‡πÑ‡∏¢"},
    "witches' broom": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡πÑ‡∏£‡∏™‡∏µ‡πà‡∏Ç‡∏≤", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡πÑ‡∏£‡∏™‡∏µ‡πà‡∏Ç‡∏≤ ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏•‡∏≥‡πÑ‡∏¢"},
    "longan witches broom": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡πÑ‡∏£‡∏™‡∏µ‡πà‡∏Ç‡∏≤", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô ‡πÑ‡∏£‡∏™‡∏µ‡πà‡∏Ç‡∏≤ ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á"},
    "‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡πÑ‡∏´‡∏°‡πâ‡∏•‡∏≥‡πÑ‡∏¢": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏ü ‡πÑ‡∏£‡πÅ‡∏î‡∏á", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏ü ‡πÑ‡∏£‡πÅ‡∏î‡∏á ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏•‡∏≥‡πÑ‡∏¢"},

    # =========================================================================
    # üçà ‡∏ó‡∏∏‡πÄ‡∏£‡∏µ‡∏¢‡∏ô (DURIAN) - ‡πÅ‡∏°‡∏•‡∏á‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
    # =========================================================================
    "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏Å‡πà‡πÅ‡∏à‡πâ‡∏ó‡∏∏‡πÄ‡∏£‡∏µ‡∏¢‡∏ô": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏Å‡πà‡πÅ‡∏à‡πâ", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏Å‡πà‡πÅ‡∏à‡πâ ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏ó‡∏∏‡πÄ‡∏£‡∏µ‡∏¢‡∏ô"},
    "‡∏´‡∏ô‡∏≠‡∏ô‡πÄ‡∏à‡∏≤‡∏∞‡∏ú‡∏•‡∏ó‡∏∏‡πÄ‡∏£‡∏µ‡∏¢‡∏ô": {"pest": "‡∏´‡∏ô‡∏≠‡∏ô‡πÄ‡∏à‡∏≤‡∏∞‡∏ú‡∏•", "search_query": "‡∏´‡∏ô‡∏≠‡∏ô‡πÄ‡∏à‡∏≤‡∏∞‡∏ú‡∏• ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏ó‡∏∏‡πÄ‡∏£‡∏µ‡∏¢‡∏ô"},
    "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÅ‡∏õ‡πâ‡∏á‡∏ó‡∏∏‡πÄ‡∏£‡∏µ‡∏¢‡∏ô": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÅ‡∏õ‡πâ‡∏á", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÅ‡∏õ‡πâ‡∏á ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏ó‡∏∏‡πÄ‡∏£‡∏µ‡∏¢‡∏ô"},
    "‡πÑ‡∏£‡πÅ‡∏î‡∏á‡∏ó‡∏∏‡πÄ‡∏£‡∏µ‡∏¢‡∏ô": {"pest": "‡πÑ‡∏£‡πÅ‡∏î‡∏á", "search_query": "‡πÑ‡∏£‡πÅ‡∏î‡∏á ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÑ‡∏£ ‡∏ó‡∏∏‡πÄ‡∏£‡∏µ‡∏¢‡∏ô"},
    "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏ü‡∏ó‡∏∏‡πÄ‡∏£‡∏µ‡∏¢‡∏ô": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏ü", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏ü ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏ó‡∏∏‡πÄ‡∏£‡∏µ‡∏¢‡∏ô"},

    # =========================================================================
    # üçä ‡∏™‡πâ‡∏°/‡∏°‡∏∞‡∏ô‡∏≤‡∏ß (CITRUS) - ‡πÇ‡∏£‡∏Ñ‡πÑ‡∏ß‡∏£‡∏±‡∏™‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏û‡∏≤‡∏´‡∏∞
    # =========================================================================
    "‡πÇ‡∏£‡∏Ñ‡∏Å‡∏£‡∏µ‡∏ô‡∏ô‡∏¥‡πà‡∏á": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏Å‡πà‡πÅ‡∏à‡πâ", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏Å‡πà‡πÅ‡∏à‡πâ ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏™‡πâ‡∏°"},
    "greening": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏Å‡πà‡πÅ‡∏à‡πâ", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏Å‡πà‡πÅ‡∏à‡πâ ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏™‡πâ‡∏°"},
    "hlb": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏Å‡πà‡πÅ‡∏à‡πâ", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏Å‡πà‡πÅ‡∏à‡πâ ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏™‡πâ‡∏°"},
    "huanglongbing": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏Å‡πà‡πÅ‡∏à‡πâ", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏Å‡πà‡πÅ‡∏à‡πâ ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏™‡πâ‡∏°"},
    "‡πÇ‡∏£‡∏Ñ‡∏ó‡∏£‡∏¥‡∏™‡πÄ‡∏ï‡∏ã‡πà‡∏≤": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏™‡πâ‡∏°"},
    "tristeza": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏™‡πâ‡∏°"},
    "citrus tristeza": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏™‡πâ‡∏°"},

    # =========================================================================
    # üåø ‡πÇ‡∏£‡∏Ñ‡πÑ‡∏ß‡∏£‡∏±‡∏™‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
    # =========================================================================
    "‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡∏î‡πà‡∏≤‡∏á": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô ‡πÅ‡∏°‡∏•‡∏á‡∏´‡∏ß‡∏µ‡πà‡∏Ç‡∏≤‡∏ß", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô ‡πÅ‡∏°‡∏•‡∏á‡∏´‡∏ß‡∏µ‡πà‡∏Ç‡∏≤‡∏ß ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á"},
    "mosaic": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á"},
    "‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡∏´‡∏î": {"pest": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô ‡πÑ‡∏£‡∏Ç‡∏≤‡∏ß", "search_query": "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô ‡πÑ‡∏£‡∏Ç‡∏≤‡∏ß ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á"},
    "leaf curl": {"pest": "‡πÅ‡∏°‡∏•‡∏á‡∏´‡∏ß‡∏µ‡πà‡∏Ç‡∏≤‡∏ß", "search_query": "‡πÅ‡∏°‡∏•‡∏á‡∏´‡∏ß‡∏µ‡πà‡∏Ç‡∏≤‡∏ß ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á"},
    "‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡∏´‡∏á‡∏¥‡∏Å‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á": {"pest": "‡πÅ‡∏°‡∏•‡∏á‡∏´‡∏ß‡∏µ‡πà‡∏Ç‡∏≤‡∏ß", "search_query": "‡πÅ‡∏°‡∏•‡∏á‡∏´‡∏ß‡∏µ‡πà‡∏Ç‡∏≤‡∏ß ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á"},
}

def get_search_query_for_disease(disease_name: str, pest_type: str = "") -> tuple:
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÇ‡∏£‡∏Ñ‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡πÅ‡∏°‡∏•‡∏á‡∏û‡∏≤‡∏´‡∏∞‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ ‚Üí return (search_query ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á, pest_name)
    ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ ‚Üí return (disease_name, None)
    """
    disease_lower = disease_name.lower()

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏£‡∏Ñ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏û‡∏≤‡∏´‡∏∞‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    for key, info in VECTOR_DISEASES.items():
        if key in disease_lower:
            logger.info(f"üêõ ‡πÇ‡∏£‡∏Ñ‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡πÅ‡∏°‡∏•‡∏á‡∏û‡∏≤‡∏´‡∏∞: {info['pest']} ‚Üí ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á")
            return (info["search_query"], info["pest"])

    # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ß‡∏£‡∏±‡∏™ ‚Üí ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏´‡∏≤‡∏û‡∏≤‡∏´‡∏∞
    if pest_type and "‡πÑ‡∏ß‡∏£‡∏±‡∏™" in pest_type.lower():
        logger.info("ü¶† ‡πÇ‡∏£‡∏Ñ‡πÑ‡∏ß‡∏£‡∏±‡∏™ ‚Üí ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏û‡∏≤‡∏´‡∏∞")
        return (f"{disease_name} ‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á ‡∏û‡∏≤‡∏´‡∏∞", None)

    return (disease_name, None)


# =============================================================================
# Hybrid Search Functions (Vector + BM25/Keyword)
# =============================================================================

async def hybrid_search_products(query: str, match_count: int = 15,
                                  vector_weight: float = 0.6,
                                  keyword_weight: float = 0.4) -> List[Dict]:
    """
    Perform Hybrid Search combining Vector Search + Keyword/BM25 Search
    Uses Reciprocal Rank Fusion (RRF) for combining results
    """
    try:
        if not supabase_client or not openai_client:
            logger.warning("Supabase or OpenAI client not available for hybrid search")
            return []

        logger.info(f"üîç Hybrid Search: '{query}' (vector={vector_weight}, keyword={keyword_weight})")

        # Generate embedding for vector search
        response = await openai_client.embeddings.create(
            model="text-embedding-3-small",
            input=query,
            encoding_format="float"
        )
        query_embedding = response.data[0].embedding

        # Try hybrid_search_products RPC first (if SQL function exists)
        try:
            result = supabase_client.rpc(
                'hybrid_search_products',
                {
                    'query_embedding': query_embedding,
                    'search_query': query,
                    'vector_weight': vector_weight,
                    'keyword_weight': keyword_weight,
                    'match_threshold': 0.15,
                    'match_count': match_count
                }
            ).execute()

            if result.data:
                logger.info(f"‚úì Hybrid search returned {len(result.data)} products")
                for p in result.data[:3]:
                    logger.info(f"   ‚Üí {p.get('product_name')}: hybrid={p.get('hybrid_score', 0):.3f} "
                               f"(vec={p.get('vector_score', 0):.3f}, kw={p.get('keyword_score', 0):.3f})")
                return result.data

        except Exception as e:
            logger.warning(f"hybrid_search_products RPC failed: {e}, falling back to manual hybrid search")

        # Fallback: Manual hybrid search (Vector + Keyword separately)
        return await manual_hybrid_search(query, query_embedding, match_count, vector_weight, keyword_weight)

    except Exception as e:
        logger.error(f"Hybrid search failed: {e}", exc_info=True)
        return []


async def manual_hybrid_search(query: str, query_embedding: List[float],
                                match_count: int = 15,
                                vector_weight: float = 0.6,
                                keyword_weight: float = 0.4) -> List[Dict]:
    """
    Manual Hybrid Search fallback - runs vector and keyword search separately
    then combines with Reciprocal Rank Fusion (RRF)
    """
    try:
        # 1. Vector Search
        vector_results = []
        try:
            result = supabase_client.rpc(
                'match_products',
                {
                    'query_embedding': query_embedding,
                    'match_threshold': 0.15,
                    'match_count': match_count * 2
                }
            ).execute()
            if result.data:
                vector_results = result.data
                logger.info(f"   Vector search: {len(vector_results)} results")
        except Exception as e:
            logger.warning(f"Vector search failed: {e}")

        # 2. Keyword Search (ILIKE fallback)
        keyword_results = []
        try:
            # Try keyword_search_products RPC
            result = supabase_client.rpc(
                'keyword_search_products',
                {
                    'search_query': query,
                    'match_count': match_count * 2
                }
            ).execute()
            if result.data:
                keyword_results = result.data
                logger.info(f"   Keyword search (RPC): {len(keyword_results)} results")
        except Exception as e:
            logger.warning(f"keyword_search_products RPC failed: {e}, trying ILIKE")
            # Fallback: ILIKE search
            try:
                result = supabase_client.table('products')\
                    .select('*')\
                    .or_(f"product_name.ilike.%{query}%,"
                         f"target_pest.ilike.%{query}%,"
                         f"applicable_crops.ilike.%{query}%,"
                         f"active_ingredient.ilike.%{query}%")\
                    .limit(match_count * 2)\
                    .execute()
                if result.data:
                    # Add rank score for ILIKE results
                    for i, p in enumerate(result.data):
                        p['rank'] = 1.0 / (i + 1)  # Simple rank score
                    keyword_results = result.data
                    logger.info(f"   Keyword search (ILIKE): {len(keyword_results)} results")
            except Exception as e2:
                logger.warning(f"ILIKE search failed: {e2}")

        # 3. Combine with RRF (Reciprocal Rank Fusion)
        combined = reciprocal_rank_fusion(
            vector_results, keyword_results,
            vector_weight, keyword_weight
        )

        logger.info(f"‚úì Manual hybrid search combined: {len(combined)} products")
        return combined[:match_count]

    except Exception as e:
        logger.error(f"Manual hybrid search failed: {e}", exc_info=True)
        return []


def reciprocal_rank_fusion(vector_results: List[Dict], keyword_results: List[Dict],
                           vector_weight: float = 0.6, keyword_weight: float = 0.4,
                           k: int = 60) -> List[Dict]:
    """
    Combine vector and keyword search results using Reciprocal Rank Fusion (RRF)
    RRF score = sum(1 / (k + rank)) across all result sets

    Parameters:
    - k: constant to prevent high scores for top results (default 60)
    """
    try:
        # Build product lookup and RRF scores
        products_by_id = {}
        rrf_scores = {}

        # Process vector results
        for rank, product in enumerate(vector_results, 1):
            pid = product.get('id') or product.get('product_name')
            if pid:
                products_by_id[pid] = product
                rrf_scores[pid] = rrf_scores.get(pid, 0) + vector_weight * (1 / (k + rank))
                product['vector_rank'] = rank
                product['vector_score'] = product.get('similarity', 0)

        # Process keyword results
        for rank, product in enumerate(keyword_results, 1):
            pid = product.get('id') or product.get('product_name')
            if pid:
                if pid not in products_by_id:
                    products_by_id[pid] = product
                rrf_scores[pid] = rrf_scores.get(pid, 0) + keyword_weight * (1 / (k + rank))
                products_by_id[pid]['keyword_rank'] = rank
                products_by_id[pid]['keyword_score'] = product.get('rank', 0)

        # Add bonus for products appearing in both
        for pid in rrf_scores:
            product = products_by_id[pid]
            if product.get('vector_rank') and product.get('keyword_rank'):
                rrf_scores[pid] += 0.02  # Small bonus for appearing in both

        # Sort by RRF score
        sorted_ids = sorted(rrf_scores.keys(), key=lambda x: rrf_scores[x], reverse=True)

        # Build final results
        combined_results = []
        for pid in sorted_ids:
            product = products_by_id[pid].copy()
            product['hybrid_score'] = rrf_scores[pid]
            product['similarity'] = rrf_scores[pid]  # Use hybrid score as similarity
            combined_results.append(product)

        return combined_results

    except Exception as e:
        logger.error(f"RRF fusion failed: {e}", exc_info=True)
        # Fallback: return vector results
        return vector_results

async def retrieve_product_recommendation(disease_info: DiseaseDetectionResult) -> List[ProductRecommendation]:
    """
    Query products using Hybrid Search (Vector + Keyword/BM25)
    Returns top 3-6 most relevant products

    ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏£‡∏Ñ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÅ‡∏°‡∏•‡∏á‡∏û‡∏≤‡∏´‡∏∞ (‡πÄ‡∏ä‡πà‡∏ô ‡πÇ‡∏£‡∏Ñ‡∏à‡∏π‡πã‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≤‡∏ß) ‡∏à‡∏∞‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á‡πÅ‡∏ó‡∏ô
    """
    try:
        logger.info("üîç Retrieving products with Hybrid Search (Vector + Keyword)")

        if not supabase_client:
            logger.warning("Supabase not configured")
            return []

        disease_name = disease_info.disease_name

        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÇ‡∏£‡∏Ñ‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡πÅ‡∏°‡∏•‡∏á‡∏û‡∏≤‡∏´‡∏∞‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà ‚Üí ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á‡πÅ‡∏ó‡∏ô
        pest_type = ""
        if hasattr(disease_info, 'raw_analysis') and disease_info.raw_analysis:
            # ‡∏î‡∏∂‡∏á pest_type ‡∏à‡∏≤‡∏Å raw_analysis ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
            if "‡πÑ‡∏ß‡∏£‡∏±‡∏™" in disease_info.raw_analysis:
                pest_type = "‡πÑ‡∏ß‡∏£‡∏±‡∏™"

        search_query, pest_name = get_search_query_for_disease(disease_name, pest_type)

        if pest_name:
            logger.info(f"üêõ ‡πÇ‡∏£‡∏Ñ‡∏°‡∏µ‡∏û‡∏≤‡∏´‡∏∞: {pest_name} ‚Üí ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: {search_query}")
        else:
            logger.info(f"üìù Searching products for: {disease_name}")

        # Check cache first (‡πÉ‡∏ä‡πâ search_query ‡πÄ‡∏õ‡πá‡∏ô key)
        cache_key = f"products:{search_query}"
        cached_products = await get_from_cache("products", cache_key)
        if cached_products:
            logger.info("‚úì Using cached product recommendations")
            return [ProductRecommendation(**p) for p in cached_products]

        # Strategy 1: Hybrid Search (Vector + Keyword combined)
        try:
            hybrid_results = await hybrid_search_products(
                query=search_query,  # ‡πÉ‡∏ä‡πâ search_query ‡πÅ‡∏ó‡∏ô disease_name
                match_count=15,
                vector_weight=0.6,
                keyword_weight=0.4
            )

            if hybrid_results:
                logger.info(f"‚úì Hybrid search found {len(hybrid_results)} candidates")

                # Apply simple relevance boost first
                for p in hybrid_results:
                    boost = simple_relevance_boost(disease_name, p)
                    p['hybrid_score'] = p.get('hybrid_score', p.get('similarity', 0)) + boost

                # Sort by boosted score
                hybrid_results.sort(key=lambda x: x.get('hybrid_score', 0), reverse=True)

                # Re-rank top candidates with LLM Cross-Encoder (if enabled)
                if ENABLE_RERANKING and len(hybrid_results) > 6:
                    logger.info("üîÑ Applying LLM re-ranking for higher accuracy...")
                    hybrid_results = await rerank_products_with_llm(
                        query=disease_name,
                        products=hybrid_results[:15],  # Top 15 candidates
                        top_k=6,
                        openai_client=openai_client
                    )

                # Filter by hybrid score threshold
                filtered_data = [
                    p for p in hybrid_results
                    if p.get('hybrid_score', p.get('similarity', 0)) > 0.005
                ][:6]

                if filtered_data:
                    logger.info(f"‚úì Final {len(filtered_data)} products after re-ranking")
                    filtered_products = build_recommendations_from_data(filtered_data)

                    # Cache the results
                    if filtered_products:
                        await set_to_cache("products", cache_key, [r.dict() for r in filtered_products])

                    return filtered_products
                else:
                    # No products passed threshold - return empty instead of forcing results
                    logger.warning("‚ö†Ô∏è No products passed relevance threshold - no recommendations")
                    return []

        except Exception as e:
            logger.warning(f"Hybrid search failed: {e}, trying fallback")

        # Strategy 2: Keyword search fallback
        matches_data = []

        # Search in target_pest field
        try:
            result = supabase_client.table('products')\
                .select('*')\
                .ilike('target_pest', f'%{disease_name}%')\
                .limit(10)\
                .execute()

            if result.data:
                matches_data.extend(result.data)
                logger.info(f"Found {len(result.data)} products in target_pest")
        except Exception as e:
            logger.warning(f"target_pest search failed: {e}")

        # If no results, search by pest type
        if not matches_data:
            try:
                pest_keywords = []
                if "‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡∏£‡∏≤" in disease_info.raw_analysis:
                    pest_keywords = ["‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡∏£‡∏≤", "‡πÇ‡∏£‡∏Ñ‡∏û‡∏∑‡∏ä"]
                elif "‡πÑ‡∏ß‡∏£‡∏±‡∏™" in disease_info.raw_analysis:
                    pest_keywords = ["‡πÑ‡∏ß‡∏£‡∏±‡∏™"]
                elif "‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä" in disease_info.raw_analysis or "‡πÅ‡∏°‡∏•‡∏á" in disease_info.raw_analysis:
                    pest_keywords = ["‡πÅ‡∏°‡∏•‡∏á", "‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä", "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢"]
                elif "‡∏ß‡∏±‡∏ä‡∏û‡∏∑‡∏ä" in disease_info.raw_analysis:
                    pest_keywords = ["‡∏ß‡∏±‡∏ä‡∏û‡∏∑‡∏ä", "‡∏´‡∏ç‡πâ‡∏≤"]

                for keyword in pest_keywords:
                    result = supabase_client.table('products')\
                        .select('*')\
                        .ilike('target_pest', f'%{keyword}%')\
                        .limit(5)\
                        .execute()

                    if result.data:
                        matches_data.extend(result.data)
                        logger.info(f"Found {len(result.data)} products for keyword: {keyword}")
                        break

            except Exception as e:
                logger.warning(f"Keyword search failed: {e}")

        if not matches_data:
            logger.warning("No products found with any search strategy")
            return []

        logger.info(f"Total products found: {len(matches_data)}")
        recommendations = build_recommendations_from_data(matches_data[:6])

        # Cache the results
        if recommendations:
            await set_to_cache("products", cache_key, [r.dict() for r in recommendations])

        return recommendations

    except Exception as e:
        logger.error(f"Product search failed: {e}", exc_info=True)
        return []


def build_recommendations_from_data(products_data: List[Dict]) -> List[ProductRecommendation]:
    """Build ProductRecommendation list from raw data"""
    recommendations = []
    seen_products = set()
    
    for product in products_data:
        pname = product.get("product_name", "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠")
        
        if pname in seen_products:
            continue
        seen_products.add(pname)
        
        pest = product.get("target_pest", "")
        if not pest or pest.strip() == "":
            continue
        
        rec = ProductRecommendation(
            product_name=pname,
            active_ingredient=product.get("active_ingredient", ""),
            target_pest=pest,
            applicable_crops=product.get("applicable_crops", ""),
            how_to_use=product.get("how_to_use", ""),
            usage_period=product.get("usage_period", ""),
            usage_rate=product.get("usage_rate", ""),
            link_product=product.get("link_product", ""),
            score=product.get("similarity", 0.7)
        )
        recommendations.append(rec)
    
    return recommendations

async def recommend_products_by_intent(question: str, keywords: dict) -> str:
    """‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ï‡∏≤‡∏° intent ‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ (‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ú‡∏•‡∏ú‡∏•‡∏¥‡∏ï, ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤, ‡∏Ø‡∏•‡∏Ø)"""
    try:
        intent = keywords.get('intent')
        logger.info(f"üéØ Intent-based recommendation: {intent}")
        logger.info(f"üìù Keywords: crops={keywords.get('crops')}, pests={keywords.get('pests')}")
        
        if not supabase_client:
            logger.error("‚ùå Supabase client not available")
            return await answer_product_question(question, keywords)
        
        if not openai_client:
            logger.error("‚ùå OpenAI client not available")
            return await answer_product_question(question, keywords)
        
        intent = keywords.get("intent")
        crops = keywords.get("crops", [])
        pests = keywords.get("pests", [])
        
        # Build search query based on intent
        search_queries = []
        
        if intent == "increase_yield":
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ú‡∏•‡∏ú‡∏•‡∏¥‡∏ï - search more broadly
            if crops:
                for crop in crops[:2]:
                    # Primary searches
                    search_queries.append(f"‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ú‡∏•‡∏ú‡∏•‡∏¥‡∏ï {crop}")
                    search_queries.append(f"‡∏ö‡∏≥‡∏£‡∏∏‡∏á {crop}")
                    search_queries.append(f"‡∏õ‡∏∏‡πã‡∏¢ {crop}")
                    search_queries.append(f"‡∏Æ‡∏≠‡∏£‡πå‡πÇ‡∏°‡∏ô {crop}")
                    # Also search by crop name directly
                    search_queries.append(crop)
                    # Problem prevention for yield
                    search_queries.append(f"‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÇ‡∏£‡∏Ñ {crop}")
                    search_queries.append(f"‡∏ö‡∏≥‡∏£‡∏∏‡∏á‡∏ï‡πâ‡∏ô {crop}")
            else:
                search_queries.append("‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ú‡∏•‡∏ú‡∏•‡∏¥‡∏ï ‡∏õ‡∏∏‡πã‡∏¢ ‡∏Æ‡∏≠‡∏£‡πå‡πÇ‡∏°‡∏ô ‡∏ö‡∏≥‡∏£‡∏∏‡∏á")
        
        elif intent == "solve_problem":
            # ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä
            if pests and crops:
                for pest in pests[:2]:
                    for crop in crops[:2]:
                        search_queries.append(f"‡∏Å‡∏≥‡∏à‡∏±‡∏î {pest} {crop}")
                        # English variants
                        if any(c.isalpha() for c in crop) or any(c.isalpha() for c in pest):
                            search_queries.append(f"control {pest} {crop}")
                            search_queries.append(f"manage {pest} on {crop}")
            elif pests:
                for pest in pests[:2]:
                    search_queries.append(f"‡∏Å‡∏≥‡∏à‡∏±‡∏î {pest}")
                    if any(c.isalpha() for c in pest):
                        search_queries.append(f"control {pest}")
            elif crops:
                for crop in crops[:2]:
                    search_queries.append(f"‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÇ‡∏£‡∏Ñ {crop}")
                    if any(c.isalpha() for c in crop):
                        search_queries.append(f"prevent disease {crop}")
        
        elif intent == "general_care":
            # ‡∏î‡∏π‡πÅ‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
            if crops:
                for crop in crops[:2]:
                    search_queries.append(f"‡∏î‡∏π‡πÅ‡∏• {crop}")
                    search_queries.append(f"‡∏ö‡∏≥‡∏£‡∏∏‡∏á {crop}")
        
        else:
            # Default: product inquiry
            if crops:
                search_queries.append(f"‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå {crops[0]}")
            if pests:
                search_queries.append(f"‡∏Å‡∏≥‡∏à‡∏±‡∏î {pests[0]}")
        
        # Hybrid search for each query (Vector + Keyword combined)
        all_products = []
        logger.info(f"üîç Hybrid searching with {len(search_queries)} queries: {search_queries[:5]}")

        for query in search_queries[:5]:  # Top 5 queries
            try:
                logger.info(f"   ‚Üí Query: '{query}'")

                # Use hybrid search (Vector + Keyword)
                results = await hybrid_search_products(
                    query=query,
                    match_count=15,
                    vector_weight=0.5,  # Balanced weights for intent-based search
                    keyword_weight=0.5
                )

                if results:
                    all_products.extend(results)
                    logger.info(f"   ‚úì Found {len(results)} products (hybrid)")
                else:
                    logger.warning(f"   ‚ö†Ô∏è No products found")
            except Exception as e:
                logger.error(f"   ‚ùå Hybrid search failed: {e}", exc_info=True)
        
        # Remove duplicates and apply relevance boost
        seen = set()
        unique_products = []
        for p in all_products:
            pname = p.get('product_name', '')
            if pname and pname not in seen:
                seen.add(pname)
                # Apply relevance boost based on query terms
                boost = 0
                for query in search_queries[:3]:
                    boost += simple_relevance_boost(query, p)
                p['hybrid_score'] = p.get('hybrid_score', p.get('similarity', 0)) + (boost / 3)
                unique_products.append(p)

        # Sort by boosted score
        unique_products.sort(key=lambda x: x.get('hybrid_score', 0), reverse=True)

        # Re-rank with LLM if enabled and enough candidates
        if ENABLE_RERANKING and len(unique_products) > 6:
            logger.info("üîÑ Applying LLM re-ranking for intent-based search...")
            unique_products = await rerank_products_with_llm(
                query=question,
                products=unique_products[:15],
                top_k=10,
                openai_client=openai_client
            )

        logger.info(f"üì¶ Total products: {len(all_products)}, Unique: {len(unique_products)}")

        if not unique_products:
            # Fallback 1: Search by applicable_crops
            logger.warning("‚ö†Ô∏è No products from vector search, trying applicable_crops search")
            if crops:
                for crop in crops[:2]:
                    try:
                        result = supabase_client.table('products')\
                            .select('*')\
                            .ilike('applicable_crops', f'%{crop}%')\
                            .limit(10)\
                            .execute()

                        if result.data:
                            unique_products.extend(result.data)
                            logger.info(f"‚úì Found {len(result.data)} products for crop: {crop}")
                    except Exception as e:
                        logger.warning(f"applicable_crops search failed: {e}")

            # Fallback 2: Search by target_pest for common issues
            if not unique_products and pests:
                for pest in pests[:2]:
                    try:
                        result = supabase_client.table('products')\
                            .select('*')\
                            .ilike('target_pest', f'%{pest}%')\
                            .limit(10)\
                            .execute()

                        if result.data:
                            unique_products.extend(result.data)
                            logger.info(f"‚úì Found {len(result.data)} products for pest: {pest}")
                    except Exception as e:
                        logger.warning(f"target_pest search failed: {e}")

            # If still no products, fallback to keyword search
            if not unique_products:
                logger.warning("‚ö†Ô∏è No products found, trying keyword search")
                return await answer_product_question(question, keywords)
        
        # Log product names
        product_names = [p.get('product_name', 'N/A') for p in unique_products[:5]]
        logger.info(f"üìã Top products: {', '.join(product_names)}")
        
        # Use Gemini to filter and create natural response
        products_text = ""
        for idx, p in enumerate(unique_products[:15], 1):  # Top 15 for Gemini
            products_text += f"\n[{idx}] {p.get('product_name', 'N/A')}"
            products_text += f"\n    ‚Ä¢ ‡∏™‡∏≤‡∏£‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: {p.get('active_ingredient', 'N/A')}"
            products_text += f"\n    ‚Ä¢ ‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏à‡∏±‡∏î‡πÑ‡∏î‡πâ: {p.get('target_pest', 'N/A')[:150]}"
            products_text += f"\n    ‚Ä¢ ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ: {p.get('how_to_use', 'N/A')[:200]}"
            products_text += f"\n    ‚Ä¢ ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ: {p.get('usage_rate', 'N/A')}"
            if p.get('usage_period'):
                products_text += f"\n    ‚Ä¢ ‡∏ä‡πà‡∏ß‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ: {p.get('usage_period')}"
            products_text += f"\n    ‚Ä¢ ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏û‡∏∑‡∏ä: {p.get('applicable_crops', 'N/A')[:100]}"
            products_text += f"\n    ‚Ä¢ Similarity: {p.get('similarity', 0):.0%}\n"
        
        # Create intent-specific prompt
        if intent == "increase_yield":
            prompt = f"""‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏à‡∏≤‡∏Å ICP Ladda

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏Å‡∏©‡∏ï‡∏£‡∏Å‡∏£: {question}

‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö (‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ):
{products_text}

üö® **‡∏Å‡∏é‡∏ó‡∏µ‡πà‡∏´‡πâ‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏°‡∏¥‡∏î**:
1. ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
2.  ‡∏´‡πâ‡∏≤‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡πÉ‡∏´‡∏°‡πà
3. ‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£
4. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° ‡πÉ‡∏´‡πâ‡∏ö‡∏≠‡∏Å‡∏ï‡∏£‡∏á‡πÜ‡∏ß‡πà‡∏≤ "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö"

üìã **‡∏ß‡∏¥‡∏ò‡∏µ‡∏ï‡∏≠‡∏ö**:
1. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 3-5 ‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô
2. ‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
3. ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á ‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ï‡πà‡∏á‡πÄ‡∏ï‡∏¥‡∏°
4. ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô‡∏ï‡∏≤‡∏°‡∏ô‡∏µ‡πâ:
   - ‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)
   - ‡∏™‡∏≤‡∏£‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)
   - ‡∏ä‡πà‡∏ß‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)
   - ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏û‡∏∑‡∏ä (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)
   - ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)
   - ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)

5. ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡∏û‡∏£‡πâ‡∏≠‡∏° emoji
6. ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ markdown

‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:"""
        
        elif intent == "solve_problem":
            prompt = f"""‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏à‡∏≤‡∏Å ICP Ladda

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏Å‡∏©‡∏ï‡∏£‡∏Å‡∏£: {question}

‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö (‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ):
{products_text}

‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä‡∏ó‡∏µ‡πà‡∏û‡∏ö: {', '.join(pests) if pests else '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'}
‡∏û‡∏∑‡∏ä‡∏ó‡∏µ‡πà‡∏õ‡∏•‡∏π‡∏Å: {', '.join(crops) if crops else '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'}

üö® **‡∏Å‡∏é‡∏ó‡∏µ‡πà‡∏´‡πâ‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏°‡∏¥‡∏î**:
1. ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
2. ‡∏´‡πâ‡∏≤‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡πÉ‡∏´‡∏°‡πà
3. ‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£
4. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏à‡∏±‡∏î‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏î‡πâ

üìã **‡∏ß‡∏¥‡∏ò‡∏µ‡∏ï‡∏≠‡∏ö**:
1. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 3-5 ‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô
2. ‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
3. ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á ‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ï‡πà‡∏á‡πÄ‡∏ï‡∏¥‡∏°
4. ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô‡∏ï‡∏≤‡∏°‡∏ô‡∏µ‡πâ:
   - ‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)
   - ‡∏™‡∏≤‡∏£‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)
   - ‡∏ä‡πà‡∏ß‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)
   - ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏û‡∏∑‡∏ä (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)
   - ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)
   - ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)

5. ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡∏û‡∏£‡πâ‡∏≠‡∏° emoji
6. ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ markdown

‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:"""
        
        else:
            # General product inquiry
            prompt = f"""‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏à‡∏≤‡∏Å ICP Ladda

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏Å‡∏©‡∏ï‡∏£‡∏Å‡∏£: {question}

‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö (‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ):
{products_text}

üö® **‡∏Å‡∏é‡∏ó‡∏µ‡πà‡∏´‡πâ‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏°‡∏¥‡∏î**:
1. ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
2. ‡∏´‡πâ‡∏≤‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡πÉ‡∏´‡∏°‡πà
3. ‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£

üìã **‡∏ß‡∏¥‡∏ò‡∏µ‡∏ï‡∏≠‡∏ö**:
1. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 3-5 ‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô  
2. ‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠ exact ‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
3. ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£
4. ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡∏û‡∏£‡πâ‡∏≠‡∏° emoji
5. ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ markdown

‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:"""
        
        # Check if AI is available
        if not openai_client:
            logger.warning("OpenAI not available, using simple format")
            return await format_product_list_simple(unique_products[:5], question, intent)
        
        try:
            response = await openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "You are a strict product assistant. ONLY recommend products from the provided list. Never create or suggest products not in the list."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,  # ‡∏•‡∏î‡∏•‡∏á‡∏à‡∏≤‡∏Å 0.7 ‚Üí 0.1 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå
                max_tokens=800
            )
            answer = response.choices[0].message.content.strip()
            answer = answer.replace("```", "").replace("**", "").replace("##", "")
            
            # Add footer
            answer += "\n\n" + "="*40
            answer += "\nüìö ‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î:"
            answer += "\nüîó https://www.icpladda.com/about/"
            answer += "\n\nüí° ‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡πà‡∏∞ üòä"
            
            logger.info(f"‚úì Intent-based answer generated ({intent})")
            return answer
            
        except Exception as e:
            logger.error(f"AI generation failed: {e}", exc_info=True)
            # Fallback to simple product list
            return await format_product_list_simple(unique_products[:5], question, intent)
        
    except Exception as e:
        logger.error(f"Error in intent-based recommendation: {e}", exc_info=True)
        return await answer_product_question(question, keywords)

async def format_product_list_simple(products: list, question: str, intent: str) -> str:
    """Format product list as simple fallback"""
    if intent == "increase_yield":
        header = "üå± ‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ú‡∏•‡∏ú‡∏•‡∏¥‡∏ï:\n"
    elif intent == "solve_problem":
        header = "üíä ‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä:\n"
    else:
        header = "üì¶ ‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:\n"
    
    response = header
    for idx, p in enumerate(products, 1):
        response += f"\n{idx}. {p.get('product_name', 'N/A')}"
        
        # ‡∏™‡∏≤‡∏£‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
        if p.get('active_ingredient'):
            response += f"\n   - ‡∏™‡∏≤‡∏£‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: {p.get('active_ingredient')}"
        
        # ‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏à‡∏±‡∏î‡πÑ‡∏î‡πâ
        if p.get('target_pest'):
            pest = p.get('target_pest')[:150] + "..." if len(p.get('target_pest', '')) > 150 else p.get('target_pest', '')
            response += f"\n   - ‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏à‡∏±‡∏î‡πÑ‡∏î‡πâ: {pest}"
        
        # ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ
        if p.get('how_to_use'):
            how_to = p.get('how_to_use')[:200] + "..." if len(p.get('how_to_use', '')) > 200 else p.get('how_to_use', '')
            response += f"\n   - ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ: {how_to}"
        
        # ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ
        if p.get('usage_rate'):
            response += f"\n   - ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ: {p.get('usage_rate')}"
        
        # ‡∏ä‡πà‡∏ß‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ
        if p.get('usage_period'):
            response += f"\n   - ‡∏ä‡πà‡∏ß‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ: {p.get('usage_period')}"
        
        # ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏û‡∏∑‡∏ä
        if p.get('applicable_crops'):
            crops = p.get('applicable_crops')[:100] + "..." if len(p.get('applicable_crops', '')) > 100 else p.get('applicable_crops', '')
            response += f"\n   - ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏û‡∏∑‡∏ä: {crops}"
        
        response += "\n"
    
    response += "\nüìö ‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°: https://www.icpladda.com/about/"
    return response

async def answer_product_question(question: str, keywords: dict) -> str:
    """Answer product-specific questions with high accuracy"""
    try:
        logger.info(f"Product-specific query: {question[:50]}...")
        
        if not supabase_client:
            return "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡∏£‡∏∞‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ"
        
        products_data = []
        
        # Search by pest/disease
        if keywords["pests"]:
            for pest in keywords["pests"][:2]:
                result = supabase_client.table('products')\
                    .select('*')\
                    .ilike('target_pest', f'%{pest}%')\
                    .limit(5)\
                    .execute()
                if result.data:
                    products_data.extend(result.data)
        
        # Search by crop
        if keywords["crops"]:
            for crop in keywords["crops"][:2]:
                result = supabase_client.table('products')\
                    .select('*')\
                    .ilike('applicable_crops', f'%{crop}%')\
                    .limit(5)\
                    .execute()
                if result.data:
                    products_data.extend(result.data)
        
        # Search by product name
        if keywords["products"]:
            for prod in keywords["products"]:
                if len(prod) > 3:
                    result = supabase_client.table('products')\
                        .select('*')\
                        .ilike('product_name', f'%{prod}%')\
                        .limit(5)\
                        .execute()
                    if result.data:
                        products_data.extend(result.data)
        
        # If no specific keywords, get general products
        if not products_data:
            result = supabase_client.table('products')\
                .select('*')\
                .limit(10)\
                .execute()
            if result.data:
                products_data = result.data
        
        if not products_data:
            return "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠‡∏û‡∏∑‡∏ä‡∏´‡∏£‡∏∑‡∏≠‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏à‡∏±‡∏î‡∏Ñ‡πà‡∏∞ üå±"
        
        # Remove duplicates
        seen = set()
        unique_products = []
        for p in products_data:
            pname = p.get('product_name', '')
            if pname and pname not in seen:
                seen.add(pname)
                unique_products.append(p)
        
        # Use Gemini to filter and format response
        products_text = ""
        for idx, p in enumerate(unique_products[:10], 1):
            products_text += f"\n[{idx}] {p.get('product_name', 'N/A')}"
            products_text += f"\n    ‡∏™‡∏≤‡∏£‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: {p.get('active_ingredient', 'N/A')}"
            products_text += f"\n    ‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä: {p.get('target_pest', 'N/A')[:100]}"
            products_text += f"\n    ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏û‡∏∑‡∏ä: {p.get('applicable_crops', 'N/A')[:80]}"
            products_text += f"\n    ‡∏ä‡πà‡∏ß‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ: {p.get('usage_period', 'N/A')}"
            products_text += f"\n    ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡πÉ‡∏ä‡πâ: {p.get('usage_rate', 'N/A')}"
            products_text += "\n"
        
        prompt = f"""‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≥‡∏à‡∏±‡∏î‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä‡∏Ç‡∏≠‡∏á ICP Ladda

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏Å‡∏©‡∏ï‡∏£‡∏Å‡∏£: {question}

‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö:
{products_text}

‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö:
1. **‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°** - ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡∏©‡∏ï‡∏£‡∏Å‡∏£‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏∞‡πÑ‡∏£
2. **‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°** - ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 3-5 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
3. **‡∏à‡∏±‡∏î‡∏•‡∏≥‡∏î‡∏±‡∏ö** - ‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏Å‡πà‡∏≠‡∏ô
4. **‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î**:
   - ‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå
   - ‡∏™‡∏≤‡∏£‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
   - ‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏à‡∏±‡∏î‡πÑ‡∏î‡πâ
   - ‡∏û‡∏∑‡∏ä‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ
   - ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ
   - ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡πÇ‡∏î‡∏¢‡∏¢‡πà‡∏≠
5. **‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥**:
   - ‡∏≠‡πà‡∏≤‡∏ô‡∏â‡∏•‡∏≤‡∏Å‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ
   - ‡πÉ‡∏ä‡πâ‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏ï‡∏±‡∏ß
   - ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÉ‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏•‡πá‡∏Å‡∏Å‡πà‡∏≠‡∏ô
6. **‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏á‡πà‡∏≤‡∏¢‡πÜ** 
7. **‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ markdown** - ‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤

**‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å**:
- ‡∏ñ‡πâ‡∏≤‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏û‡∏∑‡∏ä‡πÄ‡∏â‡∏û‡∏≤‡∏∞ ‚Üí ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏û‡∏∑‡∏ä‡∏ô‡∏±‡πâ‡∏ô‡πÑ‡∏î‡πâ
- ‡∏ñ‡πâ‡∏≤‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä ‚Üí ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏à‡∏±‡∏î‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä‡∏ô‡∏±‡πâ‡∏ô‡πÑ‡∏î‡πâ
- ‡∏ñ‡πâ‡∏≤‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‚Üí ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏¢‡∏≠‡∏î‡∏ô‡∏¥‡∏¢‡∏° 3-5 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£

‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:"""

        try:
            response = await openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "You are an agricultural product expert."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=800
            )
            answer = response.choices[0].message.content.strip()
            answer = answer.replace("```", "").replace("**", "").replace("##", "")
            
            # Add footer
            answer += "\n\n" + "="*40
            answer += "\nüìö ‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î:"
            answer += "\nüîó https://www.icpladda.com/about/"
            answer += "\n\nüí° ‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡πà‡∏∞ üòä"
            
            logger.info("‚úì Product answer generated successfully")
            return answer
            
        except Exception as e:
            logger.error(f"Gemini generation failed: {e}")
            # Fallback: return top 3 products directly
            response = "üíä ‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏à‡∏≤‡∏Å ICP Ladda:\n"
            for idx, p in enumerate(unique_products[:3], 1):
                response += f"\n{idx}. {p.get('product_name')}"
                if p.get('active_ingredient'):
                    response += f"\n   ‡∏™‡∏≤‡∏£‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: {p.get('active_ingredient')}"
                if p.get('target_pest'):
                    pest = p.get('target_pest')[:80] + "..." if len(p.get('target_pest', '')) > 80 else p.get('target_pest', '')
                    response += f"\n   ‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä: {pest}"
                if p.get('applicable_crops'):
                    crops = p.get('applicable_crops')[:60] + "..." if len(p.get('applicable_crops', '')) > 60 else p.get('applicable_crops', '')
                    response += f"\n   ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏û‡∏∑‡∏ä: {crops}"
                if p.get('usage_period'):
                    response += f"\n   ‡∏ä‡πà‡∏ß‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ: {p.get('usage_period')}"
                if p.get('usage_rate'):
                    response += f"\n   ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡πÉ‡∏ä‡πâ: {p.get('usage_rate')}"
                response += "\n"
            
            response += "\nüìö ‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°: https://www.icpladda.com/about/"
            return response
        
    except Exception as e:
        logger.error(f"Error in product Q&A: {e}", exc_info=True)
        return "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏∞ üôè"
