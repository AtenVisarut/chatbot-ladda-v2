import logging
import json
from typing import List, Dict
from app.models import DiseaseDetectionResult, ProductRecommendation
from app.services.services import supabase_client, e5_model, openai_client
import logging
import json
from typing import List, Dict
from app.models import DiseaseDetectionResult, ProductRecommendation
from app.services.services import supabase_client, openai_client
from app.services.cache import get_from_cache, set_to_cache
from app.utils.text_processing import extract_keywords_from_question

logger = logging.getLogger(__name__)

async def retrieve_product_recommendation(disease_info: DiseaseDetectionResult) -> List[ProductRecommendation]:
    """
    Query products using Vector Search + Gemini filtering
    Returns top 3-5 most relevant products
    """
    try:
        logger.info("üîç Retrieving products with Vector Search + Gemini Filter")

        if not supabase_client:
            logger.warning("Supabase not configured")
            return []

        disease_name = disease_info.disease_name
        logger.info(f"üìù Searching products for: {disease_name}")
        
        # Check cache first
        cache_key = f"products:{disease_name}"
        # Use "products" as cache type
        cached_products = await get_from_cache("products", cache_key)
        if cached_products:
            logger.info("‚úì Using cached product recommendations")
            return [ProductRecommendation(**p) for p in cached_products]
        
        # Strategy 1: Vector search by disease name (most accurate)
        try:
            if openai_client:
                # Generate embedding for disease name using OpenAI
                response = await openai_client.embeddings.create(
                    model="text-embedding-3-small",
                    input=disease_name,
                    encoding_format="float"
                )
                query_embedding = response.data[0].embedding
                logger.info("‚úì Product query embedding generated (OpenAI)")
                
                # Vector search in products table
                result = supabase_client.rpc(
                    'match_products',
                    {
                        'query_embedding': query_embedding,
                        'match_threshold': 0.3,  # Lower threshold for more candidates
                        'match_count': 15  # Get more candidates
                    }
                ).execute()
                
                if result.data and len(result.data) > 0:
                    logger.info(f"‚úì Found {len(result.data)} product candidates via vector search")
                    
                    # Use similarity scores directly (NO AI filtering - saves ~100 tokens)
                    # Filter by similarity threshold
                    filtered_data = [
                        p for p in result.data 
                        if p.get('similarity', 0) > 0.4
                    ][:6]  # Top 6 candidates
                    
                    if filtered_data:
                        logger.info(f"‚úì Filtered {len(filtered_data)} products by similarity (no AI)")
                        filtered_products = build_recommendations_from_data(filtered_data)
                        
                        # Cache the results
                        if filtered_products:
                            # Use "products" as cache type
                            await set_to_cache("products", cache_key, [r.dict() for r in filtered_products])
                        
                        return filtered_products
                    else:
                        logger.warning("‚ö†Ô∏è No products passed similarity threshold, using top vector results")
                        # Fallback: use top vector search results
                        return build_recommendations_from_data(result.data[:6])
                else:
                    logger.info("No products found via vector search, trying keyword search")
            else:
                logger.warning("OpenAI client not available, using keyword search")
        except Exception as e:
            logger.warning(f"Vector search failed: {e}, trying keyword search")
        
        # Strategy 2: Keyword search fallback
        matches_data = []
        
        # Search in target_pest field
        try:
            result = supabase_client.table('products')\
                .select('*')\
                .ilike('target_pest', f'%{disease_name}%')\
                .limit(10)\
                .execute()
            
            if result.data:
                matches_data.extend(result.data)
                logger.info(f"Found {len(result.data)} products in target_pest")
        except Exception as e:
            logger.warning(f"target_pest search failed: {e}")
        
        # If no results, search by pest type
        if not matches_data:
            try:
                pest_keywords = []
                if "‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡∏£‡∏≤" in disease_info.raw_analysis:
                    pest_keywords = ["‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡∏£‡∏≤", "‡πÇ‡∏£‡∏Ñ‡∏û‡∏∑‡∏ä"]
                elif "‡πÑ‡∏ß‡∏£‡∏±‡∏™" in disease_info.raw_analysis:
                    pest_keywords = ["‡πÑ‡∏ß‡∏£‡∏±‡∏™"]
                elif "‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä" in disease_info.raw_analysis or "‡πÅ‡∏°‡∏•‡∏á" in disease_info.raw_analysis:
                    pest_keywords = ["‡πÅ‡∏°‡∏•‡∏á", "‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä", "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢"]
                elif "‡∏ß‡∏±‡∏ä‡∏û‡∏∑‡∏ä" in disease_info.raw_analysis:
                    pest_keywords = ["‡∏ß‡∏±‡∏ä‡∏û‡∏∑‡∏ä", "‡∏´‡∏ç‡πâ‡∏≤"]
                
                for keyword in pest_keywords:
                    result = supabase_client.table('products')\
                        .select('*')\
                        .ilike('target_pest', f'%{keyword}%')\
                        .limit(5)\
                        .execute()
                    
                    if result.data:
                        matches_data.extend(result.data)
                        logger.info(f"Found {len(result.data)} products for keyword: {keyword}")
                        break
                        
            except Exception as e:
                logger.warning(f"Keyword search failed: {e}")
        
        if not matches_data:
            logger.warning("No products found with any search strategy")
            return []
        
        logger.info(f"Total products found: {len(matches_data)}")
        recommendations = build_recommendations_from_data(matches_data[:6])
        
        # Cache the results
        if recommendations:
            # Use "products" as cache type
            await set_to_cache("products", cache_key, [r.dict() for r in recommendations])
        
        return recommendations

    except Exception as e:
        logger.error(f"Product search failed: {e}", exc_info=True)
        return []


def build_recommendations_from_data(products_data: List[Dict]) -> List[ProductRecommendation]:
    """Build ProductRecommendation list from raw data"""
    recommendations = []
    seen_products = set()
    
    for product in products_data:
        pname = product.get("product_name", "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠")
        
        if pname in seen_products:
            continue
        seen_products.add(pname)
        
        pest = product.get("target_pest", "")
        if not pest or pest.strip() == "":
            continue
        
        rec = ProductRecommendation(
            product_name=pname,
            active_ingredient=product.get("active_ingredient", ""),
            target_pest=pest,
            applicable_crops=product.get("applicable_crops", ""),
            how_to_use=product.get("how_to_use", ""),
            usage_period=product.get("usage_period", ""),
            usage_rate=product.get("usage_rate", ""),
            link_product=product.get("link_product", ""),
            score=product.get("similarity", 0.7)
        )
        recommendations.append(rec)
    
    return recommendations

async def recommend_products_by_intent(question: str, keywords: dict) -> str:
    """‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ï‡∏≤‡∏° intent ‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ (‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ú‡∏•‡∏ú‡∏•‡∏¥‡∏ï, ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤, ‡∏Ø‡∏•‡∏Ø)"""
    try:
        intent = keywords.get('intent')
        logger.info(f"üéØ Intent-based recommendation: {intent}")
        logger.info(f"üìù Keywords: crops={keywords.get('crops')}, pests={keywords.get('pests')}")
        
        if not supabase_client:
            logger.error("‚ùå Supabase client not available")
            return await answer_product_question(question, keywords)
        
        if not openai_client:
            logger.error("‚ùå OpenAI client not available")
            return await answer_product_question(question, keywords)
        
        intent = keywords.get("intent")
        crops = keywords.get("crops", [])
        pests = keywords.get("pests", [])
        
        # Build search query based on intent
        search_queries = []
        
        if intent == "increase_yield":
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ú‡∏•‡∏ú‡∏•‡∏¥‡∏ï
            if crops:
                for crop in crops[:2]:
                    search_queries.append(f"‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ú‡∏•‡∏ú‡∏•‡∏¥‡∏ï {crop}")
                    search_queries.append(f"‡∏õ‡∏∏‡πã‡∏¢‡∏ö‡∏≥‡∏£‡∏∏‡∏á {crop}")
                    search_queries.append(f"‡∏Æ‡∏≠‡∏£‡πå‡πÇ‡∏°‡∏ô {crop}")
                    # English variants for English crop names
                    if any(c.isalpha() for c in crop):
                        search_queries.append(f"increase yield {crop}")
                        search_queries.append(f"fertilizer for {crop}")
                        search_queries.append(f"plant hormone {crop}")
            else:
                search_queries.append("‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ú‡∏•‡∏ú‡∏•‡∏¥‡∏ï ‡∏õ‡∏∏‡πã‡∏¢ ‡∏Æ‡∏≠‡∏£‡πå‡πÇ‡∏°‡∏ô")
        
        elif intent == "solve_problem":
            # ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä
            if pests and crops:
                for pest in pests[:2]:
                    for crop in crops[:2]:
                        search_queries.append(f"‡∏Å‡∏≥‡∏à‡∏±‡∏î {pest} {crop}")
                        # English variants
                        if any(c.isalpha() for c in crop) or any(c.isalpha() for c in pest):
                            search_queries.append(f"control {pest} {crop}")
                            search_queries.append(f"manage {pest} on {crop}")
            elif pests:
                for pest in pests[:2]:
                    search_queries.append(f"‡∏Å‡∏≥‡∏à‡∏±‡∏î {pest}")
                    if any(c.isalpha() for c in pest):
                        search_queries.append(f"control {pest}")
            elif crops:
                for crop in crops[:2]:
                    search_queries.append(f"‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÇ‡∏£‡∏Ñ {crop}")
                    if any(c.isalpha() for c in crop):
                        search_queries.append(f"prevent disease {crop}")
        
        elif intent == "general_care":
            # ‡∏î‡∏π‡πÅ‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
            if crops:
                for crop in crops[:2]:
                    search_queries.append(f"‡∏î‡∏π‡πÅ‡∏• {crop}")
                    search_queries.append(f"‡∏ö‡∏≥‡∏£‡∏∏‡∏á {crop}")
        
        else:
            # Default: product inquiry
            if crops:
                search_queries.append(f"‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå {crops[0]}")
            if pests:
                search_queries.append(f"‡∏Å‡∏≥‡∏à‡∏±‡∏î {pests[0]}")
        
        # Vector search for each query
        all_products = []
        logger.info(f"üîç Searching with {len(search_queries)} queries: {search_queries[:3]}")
        
        for query in search_queries[:3]:  # Top 3 queries
            try:
                logger.info(f"   ‚Üí Query: '{query}'")
                
                # Generate embedding using OpenAI
                response = await openai_client.embeddings.create(
                    model="text-embedding-3-small",
                    input=query,
                    encoding_format="float"
                )
                query_embedding = response.data[0].embedding
                
                result = supabase_client.rpc(
                    'match_products',
                    {
                        'query_embedding': query_embedding,
                        'match_threshold': 0.25,  # Lower threshold for more results
                        'match_count': 10
                    }
                ).execute()
                
                if result.data:
                    all_products.extend(result.data)
                    logger.info(f"   ‚úì Found {len(result.data)} products")
                else:
                    logger.warning(f"   ‚ö†Ô∏è No products found")
            except Exception as e:
                logger.error(f"   ‚ùå Vector search failed: {e}", exc_info=True)
        
        # Remove duplicates
        seen = set()
        unique_products = []
        for p in all_products:
            pname = p.get('product_name', '')
            if pname and pname not in seen:
                seen.add(pname)
                unique_products.append(p)
        
        logger.info(f"üì¶ Total products: {len(all_products)}, Unique: {len(unique_products)}")
        
        if not unique_products:
            # Fallback to keyword search
            logger.warning("‚ö†Ô∏è No products from vector search, trying keyword search")
            return await answer_product_question(question, keywords)
        
        # Log product names
        product_names = [p.get('product_name', 'N/A') for p in unique_products[:5]]
        logger.info(f"üìã Top products: {', '.join(product_names)}")
        
        # Use Gemini to filter and create natural response
        products_text = ""
        for idx, p in enumerate(unique_products[:15], 1):  # Top 15 for Gemini
            products_text += f"\n[{idx}] {p.get('product_name', 'N/A')}"
            products_text += f"\n    ‚Ä¢ ‡∏™‡∏≤‡∏£‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: {p.get('active_ingredient', 'N/A')}"
            products_text += f"\n    ‚Ä¢ ‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏à‡∏±‡∏î‡πÑ‡∏î‡πâ: {p.get('target_pest', 'N/A')[:150]}"
            products_text += f"\n    ‚Ä¢ ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ: {p.get('how_to_use', 'N/A')[:200]}"
            products_text += f"\n    ‚Ä¢ ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ: {p.get('usage_rate', 'N/A')}"
            if p.get('usage_period'):
                products_text += f"\n    ‚Ä¢ ‡∏ä‡πà‡∏ß‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ: {p.get('usage_period')}"
            products_text += f"\n    ‚Ä¢ ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏û‡∏∑‡∏ä: {p.get('applicable_crops', 'N/A')[:100]}"
            products_text += f"\n    ‚Ä¢ Similarity: {p.get('similarity', 0):.0%}\n"
        
        # Create intent-specific prompt
        if intent == "increase_yield":
            prompt = f"""‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏à‡∏≤‡∏Å ICP Ladda

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏Å‡∏©‡∏ï‡∏£‡∏Å‡∏£: {question}

‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö (‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ):
{products_text}

üö® **‡∏Å‡∏é‡∏ó‡∏µ‡πà‡∏´‡πâ‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏°‡∏¥‡∏î**:
1. ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
2.  ‡∏´‡πâ‡∏≤‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡πÉ‡∏´‡∏°‡πà
3. ‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£
4. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° ‡πÉ‡∏´‡πâ‡∏ö‡∏≠‡∏Å‡∏ï‡∏£‡∏á‡πÜ‡∏ß‡πà‡∏≤ "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö"

üìã **‡∏ß‡∏¥‡∏ò‡∏µ‡∏ï‡∏≠‡∏ö**:
1. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 3-5 ‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô
2. ‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
3. ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á ‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ï‡πà‡∏á‡πÄ‡∏ï‡∏¥‡∏°
4. ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô‡∏ï‡∏≤‡∏°‡∏ô‡∏µ‡πâ:
   - ‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)
   - ‡∏™‡∏≤‡∏£‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)
   - ‡∏ä‡πà‡∏ß‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)
   - ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏û‡∏∑‡∏ä (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)
   - ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)
   - ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)

5. ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡∏û‡∏£‡πâ‡∏≠‡∏° emoji
6. ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ markdown

‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:"""
        
        elif intent == "solve_problem":
            prompt = f"""‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏à‡∏≤‡∏Å ICP Ladda

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏Å‡∏©‡∏ï‡∏£‡∏Å‡∏£: {question}

‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö (‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ):
{products_text}

‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä‡∏ó‡∏µ‡πà‡∏û‡∏ö: {', '.join(pests) if pests else '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'}
‡∏û‡∏∑‡∏ä‡∏ó‡∏µ‡πà‡∏õ‡∏•‡∏π‡∏Å: {', '.join(crops) if crops else '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏'}

üö® **‡∏Å‡∏é‡∏ó‡∏µ‡πà‡∏´‡πâ‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏°‡∏¥‡∏î**:
1. ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
2. ‡∏´‡πâ‡∏≤‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡πÉ‡∏´‡∏°‡πà
3. ‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£
4. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏à‡∏±‡∏î‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÑ‡∏î‡πâ

üìã **‡∏ß‡∏¥‡∏ò‡∏µ‡∏ï‡∏≠‡∏ö**:
1. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 3-5 ‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô
2. ‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
3. ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á ‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ï‡πà‡∏á‡πÄ‡∏ï‡∏¥‡∏°
4. ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô‡∏ï‡∏≤‡∏°‡∏ô‡∏µ‡πâ:
   - ‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)
   - ‡∏™‡∏≤‡∏£‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)
   - ‡∏ä‡πà‡∏ß‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)
   - ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏û‡∏∑‡∏ä (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)
   - ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)
   - ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ (‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£)

5. ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡∏û‡∏£‡πâ‡∏≠‡∏° emoji
6. ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ markdown

‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:"""
        
        else:
            # General product inquiry
            prompt = f"""‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏à‡∏≤‡∏Å ICP Ladda

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏Å‡∏©‡∏ï‡∏£‡∏Å‡∏£: {question}

‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö (‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ):
{products_text}

üö® **‡∏Å‡∏é‡∏ó‡∏µ‡πà‡∏´‡πâ‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏°‡∏¥‡∏î**:
1. ‡πÉ‡∏ä‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
2. ‡∏´‡πâ‡∏≤‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡πÉ‡∏´‡∏°‡πà
3. ‡∏´‡πâ‡∏≤‡∏°‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£

üìã **‡∏ß‡∏¥‡∏ò‡∏µ‡∏ï‡∏≠‡∏ö**:
1. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 3-5 ‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô  
2. ‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠ exact ‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
3. ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏à‡∏≤‡∏Å‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£
4. ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡∏û‡∏£‡πâ‡∏≠‡∏° emoji
5. ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ markdown

‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:"""
        
        # Check if AI is available
        if not openai_client:
            logger.warning("OpenAI not available, using simple format")
            return await format_product_list_simple(unique_products[:5], question, intent)
        
        try:
            response = await openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "You are a strict product assistant. ONLY recommend products from the provided list. Never create or suggest products not in the list."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,  # ‡∏•‡∏î‡∏•‡∏á‡∏à‡∏≤‡∏Å 0.7 ‚Üí 0.1 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå
                max_tokens=800
            )
            answer = response.choices[0].message.content.strip()
            answer = answer.replace("```", "").replace("**", "").replace("##", "")
            
            # Add footer
            answer += "\n\n" + "="*40
            answer += "\nüìö ‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î:"
            answer += "\nüîó https://www.icpladda.com/about/"
            answer += "\n\nüí° ‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡πà‡∏∞ üòä"
            
            logger.info(f"‚úì Intent-based answer generated ({intent})")
            return answer
            
        except Exception as e:
            logger.error(f"AI generation failed: {e}", exc_info=True)
            # Fallback to simple product list
            return await format_product_list_simple(unique_products[:5], question, intent)
        
    except Exception as e:
        logger.error(f"Error in intent-based recommendation: {e}", exc_info=True)
        return await answer_product_question(question, keywords)

async def format_product_list_simple(products: list, question: str, intent: str) -> str:
    """Format product list as simple fallback"""
    if intent == "increase_yield":
        header = "üå± ‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ú‡∏•‡∏ú‡∏•‡∏¥‡∏ï:\n"
    elif intent == "solve_problem":
        header = "üíä ‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä:\n"
    else:
        header = "üì¶ ‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥:\n"
    
    response = header
    for idx, p in enumerate(products, 1):
        response += f"\n{idx}. {p.get('product_name', 'N/A')}"
        
        # ‡∏™‡∏≤‡∏£‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
        if p.get('active_ingredient'):
            response += f"\n   - ‡∏™‡∏≤‡∏£‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: {p.get('active_ingredient')}"
        
        # ‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏à‡∏±‡∏î‡πÑ‡∏î‡πâ
        if p.get('target_pest'):
            pest = p.get('target_pest')[:150] + "..." if len(p.get('target_pest', '')) > 150 else p.get('target_pest', '')
            response += f"\n   - ‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏à‡∏±‡∏î‡πÑ‡∏î‡πâ: {pest}"
        
        # ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ
        if p.get('how_to_use'):
            how_to = p.get('how_to_use')[:200] + "..." if len(p.get('how_to_use', '')) > 200 else p.get('how_to_use', '')
            response += f"\n   - ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ: {how_to}"
        
        # ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ
        if p.get('usage_rate'):
            response += f"\n   - ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ: {p.get('usage_rate')}"
        
        # ‡∏ä‡πà‡∏ß‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ
        if p.get('usage_period'):
            response += f"\n   - ‡∏ä‡πà‡∏ß‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ: {p.get('usage_period')}"
        
        # ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏û‡∏∑‡∏ä
        if p.get('applicable_crops'):
            crops = p.get('applicable_crops')[:100] + "..." if len(p.get('applicable_crops', '')) > 100 else p.get('applicable_crops', '')
            response += f"\n   - ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏û‡∏∑‡∏ä: {crops}"
        
        response += "\n"
    
    response += "\nüìö ‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°: https://www.icpladda.com/about/"
    return response

async def answer_product_question(question: str, keywords: dict) -> str:
    """Answer product-specific questions with high accuracy"""
    try:
        logger.info(f"Product-specific query: {question[:50]}...")
        
        if not supabase_client:
            return "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡∏£‡∏∞‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ"
        
        products_data = []
        
        # Search by pest/disease
        if keywords["pests"]:
            for pest in keywords["pests"][:2]:
                result = supabase_client.table('products')\
                    .select('*')\
                    .ilike('target_pest', f'%{pest}%')\
                    .limit(5)\
                    .execute()
                if result.data:
                    products_data.extend(result.data)
        
        # Search by crop
        if keywords["crops"]:
            for crop in keywords["crops"][:2]:
                result = supabase_client.table('products')\
                    .select('*')\
                    .ilike('applicable_crops', f'%{crop}%')\
                    .limit(5)\
                    .execute()
                if result.data:
                    products_data.extend(result.data)
        
        # Search by product name
        if keywords["products"]:
            for prod in keywords["products"]:
                if len(prod) > 3:
                    result = supabase_client.table('products')\
                        .select('*')\
                        .ilike('product_name', f'%{prod}%')\
                        .limit(5)\
                        .execute()
                    if result.data:
                        products_data.extend(result.data)
        
        # If no specific keywords, get general products
        if not products_data:
            result = supabase_client.table('products')\
                .select('*')\
                .limit(10)\
                .execute()
            if result.data:
                products_data = result.data
        
        if not products_data:
            return "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠‡∏û‡∏∑‡∏ä‡∏´‡∏£‡∏∑‡∏≠‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏à‡∏±‡∏î‡∏Ñ‡πà‡∏∞ üå±"
        
        # Remove duplicates
        seen = set()
        unique_products = []
        for p in products_data:
            pname = p.get('product_name', '')
            if pname and pname not in seen:
                seen.add(pname)
                unique_products.append(p)
        
        # Use Gemini to filter and format response
        products_text = ""
        for idx, p in enumerate(unique_products[:10], 1):
            products_text += f"\n[{idx}] {p.get('product_name', 'N/A')}"
            products_text += f"\n    ‡∏™‡∏≤‡∏£‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: {p.get('active_ingredient', 'N/A')}"
            products_text += f"\n    ‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä: {p.get('target_pest', 'N/A')[:100]}"
            products_text += f"\n    ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏û‡∏∑‡∏ä: {p.get('applicable_crops', 'N/A')[:80]}"
            products_text += f"\n    ‡∏ä‡πà‡∏ß‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ: {p.get('usage_period', 'N/A')}"
            products_text += f"\n    ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡πÉ‡∏ä‡πâ: {p.get('usage_rate', 'N/A')}"
            products_text += "\n"
        
        prompt = f"""‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≥‡∏à‡∏±‡∏î‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä‡∏Ç‡∏≠‡∏á ICP Ladda

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡πÄ‡∏Å‡∏©‡∏ï‡∏£‡∏Å‡∏£: {question}

‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö:
{products_text}

‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö:
1. **‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°** - ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡∏©‡∏ï‡∏£‡∏Å‡∏£‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏∞‡πÑ‡∏£
2. **‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°** - ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 3-5 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
3. **‡∏à‡∏±‡∏î‡∏•‡∏≥‡∏î‡∏±‡∏ö** - ‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏Å‡πà‡∏≠‡∏ô
4. **‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î**:
   - ‡∏ä‡∏∑‡πà‡∏≠‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå
   - ‡∏™‡∏≤‡∏£‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
   - ‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏à‡∏±‡∏î‡πÑ‡∏î‡πâ
   - ‡∏û‡∏∑‡∏ä‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ
   - ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ
   - ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡πÇ‡∏î‡∏¢‡∏¢‡πà‡∏≠
5. **‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥**:
   - ‡∏≠‡πà‡∏≤‡∏ô‡∏â‡∏•‡∏≤‡∏Å‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ
   - ‡πÉ‡∏ä‡πâ‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏ï‡∏±‡∏ß
   - ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÉ‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏•‡πá‡∏Å‡∏Å‡πà‡∏≠‡∏ô
6. **‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏©‡∏≤‡∏á‡πà‡∏≤‡∏¢‡πÜ** 
7. **‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ markdown** - ‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤

**‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å**:
- ‡∏ñ‡πâ‡∏≤‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏û‡∏∑‡∏ä‡πÄ‡∏â‡∏û‡∏≤‡∏∞ ‚Üí ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏û‡∏∑‡∏ä‡∏ô‡∏±‡πâ‡∏ô‡πÑ‡∏î‡πâ
- ‡∏ñ‡πâ‡∏≤‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä ‚Üí ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏à‡∏±‡∏î‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä‡∏ô‡∏±‡πâ‡∏ô‡πÑ‡∏î‡πâ
- ‡∏ñ‡πâ‡∏≤‡∏ñ‡∏≤‡∏°‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ ‚Üí ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏¢‡∏≠‡∏î‡∏ô‡∏¥‡∏¢‡∏° 3-5 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£

‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:"""

        try:
            response = await openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "You are an agricultural product expert."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=800
            )
            answer = response.choices[0].message.content.strip()
            answer = answer.replace("```", "").replace("**", "").replace("##", "")
            
            # Add footer
            answer += "\n\n" + "="*40
            answer += "\nüìö ‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î:"
            answer += "\nüîó https://www.icpladda.com/about/"
            answer += "\n\nüí° ‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡πà‡∏∞ üòä"
            
            logger.info("‚úì Product answer generated successfully")
            return answer
            
        except Exception as e:
            logger.error(f"Gemini generation failed: {e}")
            # Fallback: return top 3 products directly
            response = "üíä ‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏à‡∏≤‡∏Å ICP Ladda:\n"
            for idx, p in enumerate(unique_products[:3], 1):
                response += f"\n{idx}. {p.get('product_name')}"
                if p.get('active_ingredient'):
                    response += f"\n   ‡∏™‡∏≤‡∏£‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: {p.get('active_ingredient')}"
                if p.get('target_pest'):
                    pest = p.get('target_pest')[:80] + "..." if len(p.get('target_pest', '')) > 80 else p.get('target_pest', '')
                    response += f"\n   ‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä: {pest}"
                if p.get('applicable_crops'):
                    crops = p.get('applicable_crops')[:60] + "..." if len(p.get('applicable_crops', '')) > 60 else p.get('applicable_crops', '')
                    response += f"\n   ‡πÉ‡∏ä‡πâ‡∏Å‡∏±‡∏ö‡∏û‡∏∑‡∏ä: {crops}"
                if p.get('usage_period'):
                    response += f"\n   ‡∏ä‡πà‡∏ß‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ: {p.get('usage_period')}"
                if p.get('usage_rate'):
                    response += f"\n   ‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡πÉ‡∏ä‡πâ: {p.get('usage_rate')}"
                response += "\n"
            
            response += "\nüìö ‡∏î‡∏π‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°: https://www.icpladda.com/about/"
            return response
        
    except Exception as e:
        logger.error(f"Error in product Q&A: {e}", exc_info=True)
        return "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏∞ üôè"
