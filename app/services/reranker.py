"""
Re-ranking module using Cross-Encoder for higher accuracy
Uses GPT-4o-mini for Thai language support (better than sentence-transformers for Thai)
"""
import logging
from typing import List, Dict, Optional, Tuple
import asyncio

logger = logging.getLogger(__name__)


async def rerank_products_with_llm(
    query: str,
    products: List[Dict],
    top_k: int = 6,
    openai_client=None,
    required_category: str = None,
    required_category_th: str = None
) -> List[Dict]:
    """
    Re-rank products using GPT-4o-mini as cross-encoder
    This provides better Thai language understanding than traditional cross-encoders

    Parameters:
    - query: The search query
    - products: List of candidate products from hybrid search
    - top_k: Number of top results to return
    - openai_client: OpenAI async client
    - required_category: Required product category (fungicide/insecticide/herbicide)
    - required_category_th: Thai name of required category

    Returns:
    - Re-ranked list of products
    """
    try:
        if not openai_client:
            logger.warning("OpenAI client not available for re-ranking, returning original order")
            return products[:top_k]

        if len(products) <= top_k:
            logger.info(f"Only {len(products)} products, skipping re-ranking")
            return products

        logger.info(f"üîÑ Re-ranking {len(products)} products for query: '{query}'")

        # Prepare product summaries for re-ranking (limit to top 15 candidates)
        candidates = products[:15]
        product_texts = []
        for i, p in enumerate(candidates, 1):
            text = f"[{i}] {p.get('product_name', 'N/A')}"
            if p.get('target_pest'):
                text += f" | ‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä: {p.get('target_pest', '')[:100]}"
            if p.get('applicable_crops'):
                text += f" | ‡∏û‡∏∑‡∏ä: {p.get('applicable_crops', '')[:80]}"
            if p.get('active_ingredient'):
                text += f" | ‡∏™‡∏≤‡∏£: {p.get('active_ingredient', '')[:50]}"
            product_texts.append(text)

        products_str = "\n".join(product_texts)

        # Build category constraint text
        category_constraint = ""
        if required_category and required_category_th:
            category_map = {
                "fungicide": "‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡∏£‡∏≤ (‡πÄ‡∏ä‡πà‡∏ô propiconazole, difenoconazole, azoxystrobin)",
                "insecticide": "‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á (‡πÄ‡∏ä‡πà‡∏ô cartap, cypermethrin, imidacloprid)",
                "herbicide": "‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡∏ß‡∏±‡∏ä‡∏û‡∏∑‡∏ä (‡πÄ‡∏ä‡πà‡∏ô bispyribac, glyphosate, pretilachlor)"
            }
            category_constraint = f"""

‚ö†Ô∏è ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å: ‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ô‡∏µ‡πâ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ **{required_category_th}** ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô!
- ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏£‡∏Ñ‡∏û‡∏∑‡∏ä/‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡∏£‡∏≤ ‚Üí ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞ {category_map.get('fungicide')}
- ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏°‡∏•‡∏á/‡∏´‡∏ô‡∏≠‡∏ô/‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢ ‚Üí ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞ {category_map.get('insecticide')}
- ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ß‡∏±‡∏ä‡∏û‡∏∑‡∏ä/‡∏´‡∏ç‡πâ‡∏≤ ‚Üí ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞ {category_map.get('herbicide')}

‚ùå ‡∏´‡πâ‡∏≤‡∏°‡∏à‡∏±‡∏î‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà {required_category_th} ‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ï‡πâ‡∏ô‡πÜ"""

        # Cross-encoder prompt for relevance scoring
        prompt = f"""‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏à‡∏±‡∏î‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á

‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: "{query}"
{category_constraint}

‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå:
{products_str}

‡∏à‡∏±‡∏î‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ ‡πÇ‡∏î‡∏¢‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤:
1. ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏õ‡∏±‡∏ç‡∏´‡∏≤ (‡πÇ‡∏£‡∏Ñ‚Üí‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡∏£‡∏≤, ‡πÅ‡∏°‡∏•‡∏á‚Üí‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á, ‡∏ß‡∏±‡∏ä‡∏û‡∏∑‡∏ä‚Üí‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡∏ß‡∏±‡∏ä‡∏û‡∏∑‡∏ä)
2. ‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä/‡πÇ‡∏£‡∏Ñ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏à‡∏±‡∏î‡πÑ‡∏î‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
3. ‡∏û‡∏∑‡∏ä‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
4. ‡∏™‡∏≤‡∏£‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏à‡∏±‡∏î‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà

‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏à‡∏≤‡∏Å‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏°‡∏≤‡∏Å‡∏™‡∏∏‡∏î‡πÑ‡∏õ‡∏ô‡πâ‡∏≠‡∏¢‡∏™‡∏∏‡∏î (‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç ‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢ comma)
‡πÄ‡∏ä‡πà‡∏ô: 3,1,5,2,4

‡∏ï‡∏≠‡∏ö:"""

        response = await openai_client.chat.completions.create(
            model="gpt-4o-mini",  # Use mini for speed
            messages=[
                {"role": "system", "content": "‡∏ï‡∏≠‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö ‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢ comma ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô"},
                {"role": "user", "content": prompt}
            ],
            temperature=0,
            max_tokens=100
        )

        ranking_text = response.choices[0].message.content.strip()
        logger.info(f"   Re-ranking response: {ranking_text}")

        # Parse ranking
        try:
            # Extract numbers from response
            import re
            numbers = re.findall(r'\d+', ranking_text)
            ranking_indices = [int(n) - 1 for n in numbers if 0 < int(n) <= len(candidates)]

            # Build re-ranked list
            reranked = []
            seen_indices = set()
            for idx in ranking_indices:
                if idx not in seen_indices and idx < len(candidates):
                    reranked.append(candidates[idx])
                    seen_indices.add(idx)

            # Add any remaining products not in ranking
            for i, p in enumerate(candidates):
                if i not in seen_indices:
                    reranked.append(p)

            logger.info(f"‚úì Re-ranked: {[p.get('product_name', '')[:20] for p in reranked[:top_k]]}")
            return reranked[:top_k]

        except Exception as e:
            logger.warning(f"Failed to parse re-ranking: {e}, returning original order")
            return products[:top_k]

    except Exception as e:
        logger.error(f"Re-ranking failed: {e}", exc_info=True)
        return products[:top_k]


async def rerank_with_scores(
    query: str,
    products: List[Dict],
    openai_client=None
) -> List[Tuple[Dict, float]]:
    """
    Re-rank products and return with relevance scores

    Returns list of (product, score) tuples
    """
    try:
        if not openai_client or len(products) == 0:
            return [(p, p.get('similarity', 0.5)) for p in products]

        logger.info(f"üîÑ Scoring {len(products)} products for: '{query}'")

        # Limit candidates for efficiency
        candidates = products[:10]

        # Batch scoring prompt
        product_texts = []
        for i, p in enumerate(candidates, 1):
            text = f"[{i}] {p.get('product_name', 'N/A')}"
            if p.get('target_pest'):
                text += f" - {p.get('target_pest', '')[:80]}"
            product_texts.append(text)

        products_str = "\n".join(product_texts)

        prompt = f"""‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á 1-10 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå

‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: "{query}"

‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå:
{products_str}

‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏±‡∏ß (1-10) ‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢ comma
‡πÄ‡∏ä‡πà‡∏ô: 8,6,9,3,7

‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô:"""

        response = await openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "‡∏ï‡∏≠‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô ‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢ comma"},
                {"role": "user", "content": prompt}
            ],
            temperature=0,
            max_tokens=50
        )

        scores_text = response.choices[0].message.content.strip()

        # Parse scores
        import re
        scores = [float(s) / 10.0 for s in re.findall(r'\d+', scores_text)]

        # Pair products with scores
        scored_products = []
        for i, p in enumerate(candidates):
            score = scores[i] if i < len(scores) else 0.5
            scored_products.append((p, score))

        # Sort by score descending
        scored_products.sort(key=lambda x: x[1], reverse=True)

        logger.info(f"‚úì Scored products: {[(p.get('product_name', '')[:15], s) for p, s in scored_products[:5]]}")
        return scored_products

    except Exception as e:
        logger.error(f"Scoring failed: {e}", exc_info=True)
        return [(p, p.get('similarity', 0.5)) for p in products]


# Simple relevance check (lightweight, no LLM)
def simple_relevance_boost(query: str, product: Dict) -> float:
    """
    Quick relevance boost based on exact/partial matches
    Returns bonus score (0.0 to 0.3)
    """
    try:
        bonus = 0.0
        query_lower = query.lower()

        # Check product name match
        product_name = (product.get('product_name') or '').lower()
        if query_lower in product_name:
            bonus += 0.15
        elif any(term in product_name for term in query_lower.split()):
            bonus += 0.05

        # Check target pest match
        target_pest = (product.get('target_pest') or '').lower()
        if query_lower in target_pest:
            bonus += 0.1
        elif any(term in target_pest for term in query_lower.split() if len(term) > 2):
            bonus += 0.03

        # Check applicable crops match
        crops = (product.get('applicable_crops') or '').lower()
        if any(term in crops for term in query_lower.split() if len(term) > 2):
            bonus += 0.05

        return min(bonus, 0.3)  # Cap at 0.3

    except Exception:
        return 0.0
