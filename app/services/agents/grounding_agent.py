"""
Grounding Agent

Responsibilities:
- Verify that answer is grounded in retrieved documents
- Extract citations from documents
- Detect hallucinated/ungrounded claims
- Generate grounded answer when needed
"""

import logging
import json
import re
from typing import List, Dict

from app.services.agents import (
    RetrievedDocument,
    RetrievalResult,
    Citation,
    GroundingResult,
    QueryAnalysis,
    IntentType
)

logger = logging.getLogger(__name__)

# Configuration
MIN_GROUNDING_CONFIDENCE = 0.5
MAX_CITATIONS = 3


class GroundingAgent:
    """
    Agent 3: Grounding
    Ensures answers are grounded in retrieved knowledge
    """

    def __init__(self, openai_client=None):
        self.openai_client = openai_client

    async def ground(
        self,
        query_analysis: QueryAnalysis,
        retrieval_result: RetrievalResult,
        draft_answer: str = None
    ) -> GroundingResult:
        """
        Ground the answer in retrieved documents

        If draft_answer is provided, verify it against documents.
        Otherwise, generate a grounded answer from documents.

        Returns:
            GroundingResult with citations and grounding status
        """
        try:
            logger.info(f"GroundingAgent: Processing {len(retrieval_result.documents)} documents")

            # If no documents, cannot ground
            if not retrieval_result.documents:
                return GroundingResult(
                    is_grounded=False,
                    confidence=0.0,
                    citations=[],
                    ungrounded_claims=["à¹„à¸¡à¹ˆà¸žà¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™à¸à¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥"],
                    suggested_answer="à¸‚à¸­à¸­à¸ à¸±à¸¢à¸„à¹ˆà¸° à¹„à¸¡à¹ˆà¸žà¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡à¹ƒà¸™à¸à¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸„à¹ˆà¸°",
                    grounding_notes="No documents retrieved"
                )

            # Extract key information from documents
            doc_summaries = self._extract_document_info(retrieval_result.documents)

            # Generate grounded answer using LLM
            if self.openai_client:
                result = await self._llm_ground(
                    query_analysis,
                    retrieval_result.documents,
                    doc_summaries,
                    draft_answer
                )
                return result
            else:
                # Fallback: use documents directly
                return self._fallback_ground(retrieval_result.documents, query_analysis)

        except Exception as e:
            logger.error(f"GroundingAgent error: {e}", exc_info=True)
            return GroundingResult(
                is_grounded=False,
                confidence=0.0,
                citations=[],
                ungrounded_claims=[str(e)],
                suggested_answer="à¸‚à¸­à¸­à¸ à¸±à¸¢à¸„à¹ˆà¸° à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸žà¸¥à¸²à¸”à¹ƒà¸™à¸à¸²à¸£à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥",
                grounding_notes=f"Error: {str(e)}"
            )

    def _extract_document_info(self, docs: List[RetrievedDocument]) -> List[Dict]:
        """Extract key information from documents for grounding"""
        summaries = []
        for doc in docs[:10]:  # Limit to top 10
            summary = {
                'id': doc.id,
                'title': doc.title,
                'source': doc.source,
                'content': doc.content[:300],
                'product_name': doc.metadata.get('product_name'),
                'chemical_name': doc.metadata.get('chemical_name'),
                'usage_rate': doc.metadata.get('usage_rate'),
                'target_pest': doc.metadata.get('target_pest'),
                'category': doc.metadata.get('category'),
            }
            summaries.append(summary)
        return summaries

    async def _llm_ground(
        self,
        query_analysis: QueryAnalysis,
        docs: List[RetrievedDocument],
        doc_summaries: List[Dict],
        draft_answer: str = None
    ) -> GroundingResult:
        """Use LLM to verify/generate grounded answer"""

        # Build context from documents
        context_parts = []
        for i, summary in enumerate(doc_summaries, 1):
            part = f"[à¹€à¸­à¸à¸ªà¸²à¸£ {i}]\n"
            part += f"à¸«à¸±à¸§à¸‚à¹‰à¸­: {summary['title']}\n"
            if summary.get('product_name'):
                part += f"à¸ªà¸´à¸™à¸„à¹‰à¸²: {summary['product_name']}"
                if summary.get('chemical_name'):
                    part += f" (à¸ªà¸²à¸£à¸ªà¸³à¸„à¸±à¸: {summary['chemical_name']})"
                part += "\n"
            if summary.get('usage_rate'):
                part += f"à¸­à¸±à¸•à¸£à¸²à¹ƒà¸Šà¹‰: {summary['usage_rate']}\n"
            if summary.get('target_pest'):
                target = str(summary['target_pest'])[:150]
                part += f"à¹ƒà¸Šà¹‰à¸à¸³à¸ˆà¸±à¸”: {target}\n"
            if summary.get('content'):
                part += f"à¹€à¸™à¸·à¹‰à¸­à¸«à¸²: {summary['content']}\n"
            context_parts.append(part)

        context = "\n".join(context_parts)

        # Build allowed products list
        allowed_products = []
        for summary in doc_summaries:
            if summary.get('product_name'):
                allowed_products.append(summary['product_name'])
        allowed_products_str = ", ".join(set(allowed_products)) if allowed_products else "(à¹„à¸¡à¹ˆà¸¡à¸µ)"

        prompt = f"""à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¹à¸¥à¸°à¸ªà¸£à¹‰à¸²à¸‡à¸„à¸³à¸•à¸­à¸šà¸—à¸µà¹ˆ grounded à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™à¸à¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™

à¸„à¸³à¸–à¸²à¸¡: "{query_analysis.original_query}"
Intent: {query_analysis.intent.value}
Entities: {json.dumps(query_analysis.entities, ensure_ascii=False)}

à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸à¸à¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥:
{context}

à¸ªà¸´à¸™à¸„à¹‰à¸²à¸—à¸µà¹ˆà¸­à¸™à¸¸à¸à¸²à¸•à¹ƒà¸«à¹‰à¹à¸™à¸°à¸™à¸³: [{allowed_products_str}]

à¸•à¸­à¸šà¹€à¸›à¹‡à¸™ JSON (à¹„à¸¡à¹ˆà¸¡à¸µ markdown):
{{
    "is_grounded": true/false,
    "confidence": 0.0-1.0,
    "citations": [
        {{"doc_id": "X", "title": "...", "quoted_text": "à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸—à¸µà¹ˆà¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡"}}
    ],
    "ungrounded_claims": ["claim à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸¡à¸µà¹ƒà¸™à¸à¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥"],
    "answer": "à¸„à¸³à¸•à¸­à¸šà¸—à¸µà¹ˆ grounded à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™"
}}

à¸à¸Žà¹€à¸«à¸¥à¹‡à¸:
1. à¸«à¹‰à¸²à¸¡à¹à¸•à¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸”à¹‡à¸”à¸‚à¸²à¸” - à¹ƒà¸Šà¹‰à¹€à¸‰à¸žà¸²à¸°à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸à¸à¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¹ƒà¸«à¹‰à¸¡à¸²
2. à¹à¸™à¸°à¸™à¸³à¹„à¸”à¹‰à¹€à¸‰à¸žà¸²à¸°à¸ªà¸´à¸™à¸„à¹‰à¸²à¹ƒà¸™à¸£à¸²à¸¢à¸à¸²à¸£ [{allowed_products_str}] à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™
3. à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸žà¸µà¸¢à¸‡à¸žà¸­ â†’ is_grounded=false à¹à¸¥à¸° answer="à¹„à¸¡à¹ˆà¸žà¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥..."
4. à¸•à¹‰à¸­à¸‡à¸¡à¸µ citations à¸­à¸¢à¹ˆà¸²à¸‡à¸™à¹‰à¸­à¸¢ 1 à¸£à¸²à¸¢à¸à¸²à¸£à¸–à¹‰à¸² is_grounded=true
5. à¸­à¸±à¸•à¸£à¸²à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸•à¹‰à¸­à¸‡à¸¡à¸²à¸ˆà¸²à¸à¸à¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹‚à¸”à¸¢à¸•à¸£à¸‡ à¸«à¹‰à¸²à¸¡à¸„à¸³à¸™à¸§à¸“à¹€à¸­à¸‡
6. à¸Šà¸·à¹ˆà¸­à¸ªà¸´à¸™à¸„à¹‰à¸²à¸•à¹‰à¸­à¸‡à¹à¸ªà¸”à¸‡à¹ƒà¸™à¸£à¸¹à¸›à¹à¸šà¸š "à¸Šà¸·à¹ˆà¸­à¸ªà¸´à¸™à¸„à¹‰à¸² (à¸ªà¸²à¸£à¸ªà¸³à¸„à¸±à¸)" à¹€à¸Šà¹ˆà¸™ "à¹‚à¸¡à¹€à¸”à¸´à¸™ 50 (à¹‚à¸›à¸£à¸Ÿà¸µà¹‚à¸™à¸Ÿà¸­à¸ª)"

à¸£à¸¹à¸›à¹à¸šà¸šà¸„à¸³à¸•à¸­à¸š:
- à¹€à¸£à¸´à¹ˆà¸¡à¸”à¹‰à¸§à¸¢ "à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸´à¸™à¸„à¹‰à¸²" à¸«à¸£à¸·à¸­ "à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™à¸à¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥"
- à¸«à¹‰à¸²à¸¡à¹ƒà¸Šà¹‰ ** à¸«à¸£à¸·à¸­ ##
- à¹ƒà¸Šà¹‰ emoji à¸™à¸³à¸«à¸™à¹‰à¸²à¸«à¸±à¸§à¸‚à¹‰à¸­ à¹€à¸Šà¹ˆà¸™ ðŸ¦  ðŸŒ¿ ðŸ’Š ðŸ“‹ âš–ï¸ ðŸ“… âš ï¸ ðŸ’¡
- à¹ƒà¸Šà¹‰ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” à¸„à¸±à¹ˆà¸™à¸£à¸°à¸«à¸§à¹ˆà¸²à¸‡à¸ªà¹ˆà¸§à¸™à¸«à¸¥à¸±à¸à¹†
- à¸›à¸´à¸”à¸—à¹‰à¸²à¸¢à¸”à¹‰à¸§à¸¢ "à¸–à¹‰à¸²à¸šà¸­à¸à¸‚à¸™à¸²à¸”à¸–à¸±à¸‡à¸žà¹ˆà¸™ à¸™à¹‰à¸­à¸‡à¸¥à¸±à¸”à¸”à¸²à¸Šà¹ˆà¸§à¸¢à¸„à¸³à¸™à¸§à¸“à¸­à¸±à¸•à¸£à¸²à¹ƒà¸«à¹‰à¹„à¸”à¹‰à¸„à¹ˆà¸°" (à¸–à¹‰à¸²à¹€à¸›à¹‡à¸™à¸„à¸³à¸–à¸²à¸¡à¹€à¸£à¸·à¹ˆà¸­à¸‡à¸ªà¸´à¸™à¸„à¹‰à¸²)"""

        response = await self.openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": "à¸„à¸¸à¸“à¸„à¸·à¸­à¸£à¸°à¸šà¸šà¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸„à¸§à¸²à¸¡à¸–à¸¹à¸à¸•à¹‰à¸­à¸‡à¸‚à¸­à¸‡à¸„à¸³à¸•à¸­à¸š à¸•à¸­à¸šà¹€à¸›à¹‡à¸™ JSON à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™ à¸«à¹‰à¸²à¸¡à¹à¸•à¹ˆà¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥"
                },
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,
            max_tokens=800
        )

        response_text = response.choices[0].message.content.strip()

        try:
            # Remove markdown if present
            if response_text.startswith("```"):
                response_text = re.sub(r'^```(?:json)?\n?', '', response_text)
                response_text = re.sub(r'\n?```$', '', response_text)

            data = json.loads(response_text)

            # Build citations
            citations = []
            for cit in data.get("citations", [])[:MAX_CITATIONS]:
                citations.append(Citation(
                    doc_id=str(cit.get("doc_id", "")),
                    doc_title=cit.get("title", ""),
                    source="products",
                    quoted_text=cit.get("quoted_text", ""),
                    confidence=data.get("confidence", 0.5)
                ))

            return GroundingResult(
                is_grounded=data.get("is_grounded", False),
                confidence=float(data.get("confidence", 0.5)),
                citations=citations,
                ungrounded_claims=data.get("ungrounded_claims", []),
                suggested_answer=data.get("answer", ""),
                grounding_notes=f"LLM grounding with {len(doc_summaries)} docs"
            )

        except json.JSONDecodeError as e:
            logger.warning(f"Failed to parse grounding response: {e}")
            return self._fallback_ground(docs, query_analysis)

    def _fallback_ground(
        self,
        docs: List[RetrievedDocument],
        query_analysis: QueryAnalysis
    ) -> GroundingResult:
        """Fallback grounding without LLM"""
        if not docs:
            return GroundingResult(
                is_grounded=False,
                confidence=0.0,
                citations=[],
                ungrounded_claims=["à¹„à¸¡à¹ˆà¸žà¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥"],
                suggested_answer="à¸‚à¸­à¸­à¸ à¸±à¸¢à¸„à¹ˆà¸° à¹„à¸¡à¹ˆà¸žà¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™à¸à¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥",
                grounding_notes="Fallback: no documents"
            )

        # Build answer from top documents
        top_doc = docs[0]
        answer_parts = ["à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸™à¸à¸²à¸™à¸‚à¹‰à¸­à¸¡à¸¹à¸¥:\n"]

        for i, doc in enumerate(docs[:3], 1):
            product_name = doc.metadata.get('product_name') or doc.title
            chemical = doc.metadata.get('chemical_name')
            if chemical:
                product_name = f"{product_name} ({chemical})"

            answer_parts.append(f"{i}. {product_name}")

            if doc.metadata.get('target_pest'):
                answer_parts.append(f"   - à¹ƒà¸Šà¹‰à¸à¸³à¸ˆà¸±à¸”: {str(doc.metadata['target_pest'])[:100]}")
            if doc.metadata.get('usage_rate'):
                answer_parts.append(f"   - à¸­à¸±à¸•à¸£à¸²à¹ƒà¸Šà¹‰: {doc.metadata['usage_rate']}")
            answer_parts.append("")

        answer_parts.append("\nà¸–à¹‰à¸²à¸šà¸­à¸à¸‚à¸™à¸²à¸”à¸–à¸±à¸‡à¸žà¹ˆà¸™ à¸™à¹‰à¸­à¸‡à¸¥à¸±à¸”à¸”à¸²à¸Šà¹ˆà¸§à¸¢à¸„à¸³à¸™à¸§à¸“à¸­à¸±à¸•à¸£à¸²à¹ƒà¸«à¹‰à¹„à¸”à¹‰à¸„à¹ˆà¸°")

        # Build citations
        citations = []
        for doc in docs[:MAX_CITATIONS]:
            citations.append(Citation(
                doc_id=doc.id,
                doc_title=doc.title,
                source=doc.source,
                quoted_text=doc.content[:100],
                confidence=doc.similarity_score
            ))

        avg_score = sum(d.similarity_score for d in docs[:3]) / min(3, len(docs))

        return GroundingResult(
            is_grounded=avg_score >= MIN_GROUNDING_CONFIDENCE,
            confidence=avg_score,
            citations=citations,
            ungrounded_claims=[],
            suggested_answer="\n".join(answer_parts),
            grounding_notes="Fallback grounding"
        )
