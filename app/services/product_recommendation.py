import logging
import json
from typing import List, Dict, Tuple
from app.models import DiseaseDetectionResult, ProductRecommendation
from app.services.services import supabase_client, openai_client
from app.services.cache import get_from_cache, set_to_cache
from app.utils.text_processing import extract_keywords_from_question
from app.services.reranker import rerank_products_with_llm, simple_relevance_boost

logger = logging.getLogger(__name__)

# Configuration for re-ranking
ENABLE_RERANKING = True  # Set to False to disable re-ranking for faster response

# =============================================================================
# à¹‚à¸£à¸„à¸—à¸µà¹ˆà¸¡à¸µà¹à¸¡à¸¥à¸‡à¸žà¸²à¸«à¸° â†’ à¸„à¸§à¸£à¹à¸™à¸°à¸™à¸³à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡à¹à¸—à¸™à¸¢à¸²à¸à¸³à¸ˆà¸±à¸”à¹€à¸Šà¸·à¹‰à¸­
# =============================================================================
VECTOR_DISEASES = {
    # =========================================================================
    # ðŸŒ¾ à¸‚à¹‰à¸²à¸§ (RICE) - à¹‚à¸£à¸„à¹„à¸§à¸£à¸±à¸ªà¸—à¸µà¹ˆà¸¡à¸µà¹€à¸žà¸¥à¸µà¹‰à¸¢à¹€à¸›à¹‡à¸™à¸žà¸²à¸«à¸°
    # =========================================================================
    "à¹‚à¸£à¸„à¸ˆà¸¹à¹‹": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸à¸£à¸°à¹‚à¸”à¸”à¸ªà¸µà¸™à¹‰à¸³à¸•à¸²à¸¥", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸à¸£à¸°à¹‚à¸”à¸”à¸ªà¸µà¸™à¹‰à¸³à¸•à¸²à¸¥ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ BPH"},
    "rice ragged stunt": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸à¸£à¸°à¹‚à¸”à¸”à¸ªà¸µà¸™à¹‰à¸³à¸•à¸²à¸¥", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸à¸£à¸°à¹‚à¸”à¸”à¸ªà¸µà¸™à¹‰à¸³à¸•à¸²à¸¥ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ BPH"},
    "ragged stunt": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸à¸£à¸°à¹‚à¸”à¸”à¸ªà¸µà¸™à¹‰à¸³à¸•à¸²à¸¥", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸à¸£à¸°à¹‚à¸”à¸”à¸ªà¸µà¸™à¹‰à¸³à¸•à¸²à¸¥ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ BPH"},
    "à¹‚à¸£à¸„à¹ƒà¸šà¸«à¸‡à¸´à¸": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸à¸£à¸°à¹‚à¸”à¸”à¸ªà¸µà¸™à¹‰à¸³à¸•à¸²à¸¥", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸à¸£à¸°à¹‚à¸”à¸”à¸ªà¸µà¸™à¹‰à¸³à¸•à¸²à¸¥ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ BPH"},
    "rice grassy stunt": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸à¸£à¸°à¹‚à¸”à¸”à¸ªà¸µà¸™à¹‰à¸³à¸•à¸²à¸¥", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸à¸£à¸°à¹‚à¸”à¸”à¸ªà¸µà¸™à¹‰à¸³à¸•à¸²à¸¥ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ BPH"},
    "grassy stunt": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸à¸£à¸°à¹‚à¸”à¸”à¸ªà¸µà¸™à¹‰à¸³à¸•à¸²à¸¥", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸à¸£à¸°à¹‚à¸”à¸”à¸ªà¸µà¸™à¹‰à¸³à¸•à¸²à¸¥ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ BPH"},
    "à¹‚à¸£à¸„à¹ƒà¸šà¸ªà¸µà¸ªà¹‰à¸¡": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™à¹€à¸‚à¸µà¸¢à¸§", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ GLH"},
    "rice orange leaf": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™à¹€à¸‚à¸µà¸¢à¸§", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ GLH"},
    "orange leaf": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™à¹€à¸‚à¸µà¸¢à¸§", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ GLH"},
    "à¹‚à¸£à¸„à¹ƒà¸šà¸‚à¸²à¸§à¸‚à¹‰à¸²à¸§": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™à¹€à¸‚à¸µà¸¢à¸§", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ GLH"},
    "rice tungro": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™à¹€à¸‚à¸µà¸¢à¸§", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ GLH"},
    "tungro": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™à¹€à¸‚à¸µà¸¢à¸§", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ GLH"},
    "à¹‚à¸£à¸„à¸—à¸±à¸‡à¹‚à¸£": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™à¹€à¸‚à¸µà¸¢à¸§", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ GLH"},

    # =========================================================================
    # ðŸ¬ à¸­à¹‰à¸­à¸¢ (SUGARCANE) - à¹‚à¸£à¸„à¹„à¸§à¸£à¸±à¸ªà¹à¸¥à¸°à¹„à¸Ÿà¹‚à¸•à¸žà¸¥à¸²à¸ªà¸¡à¸²
    # =========================================================================
    "à¹‚à¸£à¸„à¹ƒà¸šà¸‚à¸²à¸§à¸­à¹‰à¸­à¸¢": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ à¸­à¹‰à¸­à¸¢"},
    "sugarcane white leaf": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ à¸­à¹‰à¸­à¸¢"},
    "white leaf": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡"},
    "à¹‚à¸£à¸„à¹ƒà¸šà¸”à¹ˆà¸²à¸‡à¸­à¹‰à¸­à¸¢": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸­à¹ˆà¸­à¸™", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸­à¹ˆà¸­à¸™ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ à¸­à¹‰à¸­à¸¢"},
    "sugarcane mosaic": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸­à¹ˆà¸­à¸™", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸­à¹ˆà¸­à¸™ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡"},
    "à¹‚à¸£à¸„à¸à¸­à¸•à¸°à¹„à¸„à¸£à¹‰": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ à¸­à¹‰à¸­à¸¢"},
    "sugarcane grassy shoot": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡"},

    # =========================================================================
    # ðŸ¥­ à¸¡à¸°à¸¡à¹ˆà¸§à¸‡ (MANGO) - à¹‚à¸£à¸„à¸—à¸µà¹ˆà¸¡à¸µà¹à¸¡à¸¥à¸‡à¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡
    # =========================================================================
    "à¹‚à¸£à¸„à¸Šà¹ˆà¸­à¸”à¸³à¸¡à¸°à¸¡à¹ˆà¸§à¸‡": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™à¸¡à¸°à¸¡à¹ˆà¸§à¸‡ à¹€à¸žà¸¥à¸µà¹‰à¸¢à¹„à¸Ÿ", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™à¸¡à¸°à¸¡à¹ˆà¸§à¸‡ à¹€à¸žà¸¥à¸µà¹‰à¸¢à¹„à¸Ÿ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡"},
    "mango malformation": {"pest": "à¹„à¸£à¸ªà¸µà¹ˆà¸‚à¸²", "search_query": "à¹„à¸£à¸ªà¸µà¹ˆà¸‚à¸² à¸¢à¸²à¸†à¹ˆà¸²à¹„à¸£ à¸¡à¸°à¸¡à¹ˆà¸§à¸‡"},
    "à¹‚à¸£à¸„à¸¢à¸­à¸”à¹„à¸«à¸¡à¹‰à¸¡à¸°à¸¡à¹ˆà¸§à¸‡": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™à¸¡à¸°à¸¡à¹ˆà¸§à¸‡", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™à¸¡à¸°à¸¡à¹ˆà¸§à¸‡ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡"},
    "mango hopper burn": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™à¸¡à¸°à¸¡à¹ˆà¸§à¸‡", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™à¸¡à¸°à¸¡à¹ˆà¸§à¸‡ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡"},

    # =========================================================================
    # ðŸŒ³ à¸¥à¸³à¹„à¸¢ (LONGAN) - à¹‚à¸£à¸„à¸—à¸µà¹ˆà¸¡à¸µà¹à¸¡à¸¥à¸‡à¹€à¸›à¹‡à¸™à¸žà¸²à¸«à¸°
    # =========================================================================
    "à¹‚à¸£à¸„à¸žà¸¸à¹ˆà¸¡à¹„à¸¡à¹‰à¸à¸§à¸²à¸”": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™ à¹„à¸£à¸ªà¸µà¹ˆà¸‚à¸²", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™ à¹„à¸£à¸ªà¸µà¹ˆà¸‚à¸² à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ à¸¥à¸³à¹„à¸¢"},
    "witches' broom": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™ à¹„à¸£à¸ªà¸µà¹ˆà¸‚à¸²", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™ à¹„à¸£à¸ªà¸µà¹ˆà¸‚à¸² à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ à¸¥à¸³à¹„à¸¢"},
    "longan witches broom": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™ à¹„à¸£à¸ªà¸µà¹ˆà¸‚à¸²", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™ à¹„à¸£à¸ªà¸µà¹ˆà¸‚à¸² à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡"},
    "à¹‚à¸£à¸„à¹ƒà¸šà¹„à¸«à¸¡à¹‰à¸¥à¸³à¹„à¸¢": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¹„à¸Ÿ à¹„à¸£à¹à¸”à¸‡", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¹„à¸Ÿ à¹„à¸£à¹à¸”à¸‡ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ à¸¥à¸³à¹„à¸¢"},

    # =========================================================================
    # ðŸˆ à¸—à¸¸à¹€à¸£à¸µà¸¢à¸™ (DURIAN) - à¹à¸¡à¸¥à¸‡à¸¨à¸±à¸•à¸£à¸¹à¸žà¸·à¸Šà¸ªà¸³à¸„à¸±à¸
    # =========================================================================
    "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¹„à¸à¹ˆà¹à¸ˆà¹‰à¸—à¸¸à¹€à¸£à¸µà¸¢à¸™": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¹„à¸à¹ˆà¹à¸ˆà¹‰", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¹„à¸à¹ˆà¹à¸ˆà¹‰ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ à¸—à¸¸à¹€à¸£à¸µà¸¢à¸™"},
    "à¸«à¸™à¸­à¸™à¹€à¸ˆà¸²à¸°à¸œà¸¥à¸—à¸¸à¹€à¸£à¸µà¸¢à¸™": {"pest": "à¸«à¸™à¸­à¸™à¹€à¸ˆà¸²à¸°à¸œà¸¥", "search_query": "à¸«à¸™à¸­à¸™à¹€à¸ˆà¸²à¸°à¸œà¸¥ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ à¸—à¸¸à¹€à¸£à¸µà¸¢à¸™"},
    "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¹à¸›à¹‰à¸‡à¸—à¸¸à¹€à¸£à¸µà¸¢à¸™": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¹à¸›à¹‰à¸‡", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¹à¸›à¹‰à¸‡ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ à¸—à¸¸à¹€à¸£à¸µà¸¢à¸™"},
    "à¹„à¸£à¹à¸”à¸‡à¸—à¸¸à¹€à¸£à¸µà¸¢à¸™": {"pest": "à¹„à¸£à¹à¸”à¸‡", "search_query": "à¹„à¸£à¹à¸”à¸‡ à¸¢à¸²à¸†à¹ˆà¸²à¹„à¸£ à¸—à¸¸à¹€à¸£à¸µà¸¢à¸™"},
    "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¹„à¸Ÿà¸—à¸¸à¹€à¸£à¸µà¸¢à¸™": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¹„à¸Ÿ", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¹„à¸Ÿ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ à¸—à¸¸à¹€à¸£à¸µà¸¢à¸™"},

    # =========================================================================
    # ðŸŠ à¸ªà¹‰à¸¡/à¸¡à¸°à¸™à¸²à¸§ (CITRUS) - à¹‚à¸£à¸„à¹„à¸§à¸£à¸±à¸ªà¸—à¸µà¹ˆà¸¡à¸µà¸žà¸²à¸«à¸°
    # =========================================================================
    "à¹‚à¸£à¸„à¸à¸£à¸µà¸™à¸™à¸´à¹ˆà¸‡": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¹„à¸à¹ˆà¹à¸ˆà¹‰", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¹„à¸à¹ˆà¹à¸ˆà¹‰ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ à¸ªà¹‰à¸¡"},
    "greening": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¹„à¸à¹ˆà¹à¸ˆà¹‰", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¹„à¸à¹ˆà¹à¸ˆà¹‰ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ à¸ªà¹‰à¸¡"},
    "hlb": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¹„à¸à¹ˆà¹à¸ˆà¹‰", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¹„à¸à¹ˆà¹à¸ˆà¹‰ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ à¸ªà¹‰à¸¡"},
    "huanglongbing": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¹„à¸à¹ˆà¹à¸ˆà¹‰", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¹„à¸à¹ˆà¹à¸ˆà¹‰ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ à¸ªà¹‰à¸¡"},
    "à¹‚à¸£à¸„à¸—à¸£à¸´à¸ªà¹€à¸•à¸‹à¹ˆà¸²": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸­à¹ˆà¸­à¸™", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸­à¹ˆà¸­à¸™ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ à¸ªà¹‰à¸¡"},
    "tristeza": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸­à¹ˆà¸­à¸™", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸­à¹ˆà¸­à¸™ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ à¸ªà¹‰à¸¡"},
    "citrus tristeza": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸­à¹ˆà¸­à¸™", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸­à¹ˆà¸­à¸™ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ à¸ªà¹‰à¸¡"},

    # =========================================================================
    # ðŸ¥” à¸¡à¸±à¸™à¸ªà¸³à¸›à¸°à¸«à¸¥à¸±à¸‡ (CASSAVA) - à¹‚à¸£à¸„à¹„à¸§à¸£à¸±à¸ªà¸—à¸µà¹ˆà¸¡à¸µà¸žà¸²à¸«à¸°
    # =========================================================================
    "à¹‚à¸£à¸„à¹ƒà¸šà¸”à¹ˆà¸²à¸‡à¸¡à¸±à¸™à¸ªà¸³à¸›à¸°à¸«à¸¥à¸±à¸‡": {"pest": "à¹à¸¡à¸¥à¸‡à¸«à¸§à¸µà¹ˆà¸‚à¸²à¸§", "search_query": "à¹à¸¡à¸¥à¸‡à¸«à¸§à¸µà¹ˆà¸‚à¸²à¸§ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ à¸¡à¸±à¸™à¸ªà¸³à¸›à¸°à¸«à¸¥à¸±à¸‡"},
    "cassava mosaic": {"pest": "à¹à¸¡à¸¥à¸‡à¸«à¸§à¸µà¹ˆà¸‚à¸²à¸§", "search_query": "à¹à¸¡à¸¥à¸‡à¸«à¸§à¸µà¹ˆà¸‚à¸²à¸§ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ à¸¡à¸±à¸™à¸ªà¸³à¸›à¸°à¸«à¸¥à¸±à¸‡"},
    "cmd": {"pest": "à¹à¸¡à¸¥à¸‡à¸«à¸§à¸µà¹ˆà¸‚à¸²à¸§", "search_query": "à¹à¸¡à¸¥à¸‡à¸«à¸§à¸µà¹ˆà¸‚à¸²à¸§ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ à¸¡à¸±à¸™à¸ªà¸³à¸›à¸°à¸«à¸¥à¸±à¸‡"},
    "slcmv": {"pest": "à¹à¸¡à¸¥à¸‡à¸«à¸§à¸µà¹ˆà¸‚à¸²à¸§", "search_query": "à¹à¸¡à¸¥à¸‡à¸«à¸§à¸µà¹ˆà¸‚à¸²à¸§ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡"},
    "à¹‚à¸£à¸„à¸žà¸¸à¹ˆà¸¡à¹à¸ˆà¹‰à¸¡à¸±à¸™à¸ªà¸³à¸›à¸°à¸«à¸¥à¸±à¸‡": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ à¸¡à¸±à¸™à¸ªà¸³à¸›à¸°à¸«à¸¥à¸±à¸‡"},
    "cassava witches' broom": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡"},

    # =========================================================================
    # ðŸŒ½ à¸‚à¹‰à¸²à¸§à¹‚à¸žà¸” (CORN/MAIZE) - à¹‚à¸£à¸„à¹„à¸§à¸£à¸±à¸ªà¸—à¸µà¹ˆà¸¡à¸µà¸žà¸²à¸«à¸°
    # =========================================================================
    "à¹‚à¸£à¸„à¸‚à¹‰à¸²à¸§à¹‚à¸žà¸”à¹à¸„à¸£à¸°": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™à¸‚à¹‰à¸²à¸§à¹‚à¸žà¸”", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ à¸‚à¹‰à¸²à¸§à¹‚à¸žà¸”"},
    "corn stunt": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™à¸‚à¹‰à¸²à¸§à¹‚à¸žà¸”", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ à¸‚à¹‰à¸²à¸§à¹‚à¸žà¸”"},
    "à¹‚à¸£à¸„à¸‚à¹‰à¸²à¸§à¹‚à¸žà¸”à¸‡à¸­à¸¢": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™à¸‚à¹‰à¸²à¸§à¹‚à¸žà¸”", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸ˆà¸±à¸à¸ˆà¸±à¹ˆà¸™ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ à¸‚à¹‰à¸²à¸§à¹‚à¸žà¸”"},
    "à¹‚à¸£à¸„à¹ƒà¸šà¸¥à¸²à¸¢à¸‚à¹‰à¸²à¸§à¹‚à¸žà¸”": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸à¸£à¸°à¹‚à¸”à¸”à¸‚à¹‰à¸²à¸§à¹‚à¸žà¸”", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸à¸£à¸°à¹‚à¸”à¸” à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ à¸‚à¹‰à¸²à¸§à¹‚à¸žà¸”"},
    "maize stripe": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸à¸£à¸°à¹‚à¸”à¸”à¸‚à¹‰à¸²à¸§à¹‚à¸žà¸”", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸à¸£à¸°à¹‚à¸”à¸” à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ à¸‚à¹‰à¸²à¸§à¹‚à¸žà¸”"},
    "à¹‚à¸£à¸„à¹ƒà¸šà¸”à¹ˆà¸²à¸‡à¸‚à¹‰à¸²à¸§à¹‚à¸žà¸”": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸­à¹ˆà¸­à¸™", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸­à¹ˆà¸­à¸™ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ à¸‚à¹‰à¸²à¸§à¹‚à¸žà¸”"},
    "maize mosaic": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸­à¹ˆà¸­à¸™ à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸à¸£à¸°à¹‚à¸”à¸”", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸­à¹ˆà¸­à¸™ à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸à¸£à¸°à¹‚à¸”à¸” à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡"},

    # =========================================================================
    # ðŸŒ¿ à¹‚à¸£à¸„à¹„à¸§à¸£à¸±à¸ªà¸—à¸±à¹ˆà¸§à¹„à¸›
    # =========================================================================
    "à¹‚à¸£à¸„à¹ƒà¸šà¸”à¹ˆà¸²à¸‡": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸­à¹ˆà¸­à¸™ à¹à¸¡à¸¥à¸‡à¸«à¸§à¸µà¹ˆà¸‚à¸²à¸§", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸­à¹ˆà¸­à¸™ à¹à¸¡à¸¥à¸‡à¸«à¸§à¸µà¹ˆà¸‚à¸²à¸§ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡"},
    "mosaic": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸­à¹ˆà¸­à¸™", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸­à¹ˆà¸­à¸™ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡"},
    "à¹‚à¸£à¸„à¹ƒà¸šà¸«à¸”": {"pest": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸­à¹ˆà¸­à¸™ à¹„à¸£à¸‚à¸²à¸§", "search_query": "à¹€à¸žà¸¥à¸µà¹‰à¸¢à¸­à¹ˆà¸­à¸™ à¹„à¸£à¸‚à¸²à¸§ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡"},
    "leaf curl": {"pest": "à¹à¸¡à¸¥à¸‡à¸«à¸§à¸µà¹ˆà¸‚à¸²à¸§", "search_query": "à¹à¸¡à¸¥à¸‡à¸«à¸§à¸µà¹ˆà¸‚à¸²à¸§ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡"},
    "à¹‚à¸£à¸„à¹ƒà¸šà¸«à¸‡à¸´à¸à¹€à¸«à¸¥à¸·à¸­à¸‡": {"pest": "à¹à¸¡à¸¥à¸‡à¸«à¸§à¸µà¹ˆà¸‚à¸²à¸§", "search_query": "à¹à¸¡à¸¥à¸‡à¸«à¸§à¸µà¹ˆà¸‚à¸²à¸§ à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡"},
}

def get_search_query_for_disease(disease_name: str, pest_type: str = "") -> tuple:
    """
    à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¹‚à¸£à¸„à¸™à¸µà¹‰à¸¡à¸µà¹à¸¡à¸¥à¸‡à¸žà¸²à¸«à¸°à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
    à¸–à¹‰à¸²à¸¡à¸µ â†’ return (search_query à¸ªà¸³à¸«à¸£à¸±à¸šà¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡, pest_name)
    à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µ â†’ return (disease_name, None)
    """
    disease_lower = disease_name.lower()

    # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¹€à¸›à¹‡à¸™à¹‚à¸£à¸„à¸—à¸µà¹ˆà¸¡à¸µà¸žà¸²à¸«à¸°à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
    for key, info in VECTOR_DISEASES.items():
        if key in disease_lower:
            logger.info(f"ðŸ› à¹‚à¸£à¸„à¸™à¸µà¹‰à¸¡à¸µà¹à¸¡à¸¥à¸‡à¸žà¸²à¸«à¸°: {info['pest']} â†’ à¸„à¹‰à¸™à¸«à¸²à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡")
            return (info["search_query"], info["pest"])

    # à¸–à¹‰à¸²à¹€à¸›à¹‡à¸™à¹„à¸§à¸£à¸±à¸ª â†’ à¹à¸™à¸°à¸™à¸³à¹ƒà¸«à¹‰à¸«à¸²à¸žà¸²à¸«à¸°
    if pest_type and "à¹„à¸§à¸£à¸±à¸ª" in pest_type.lower():
        logger.info("ðŸ¦  à¹‚à¸£à¸„à¹„à¸§à¸£à¸±à¸ª â†’ à¸„à¹‰à¸™à¸«à¸²à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡à¸ªà¸³à¸«à¸£à¸±à¸šà¸žà¸²à¸«à¸°")
        return (f"{disease_name} à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡ à¸žà¸²à¸«à¸°", None)

    return (disease_name, None)


# =============================================================================
# Hybrid Search Functions (Vector + BM25/Keyword)
# =============================================================================

async def hybrid_search_products(query: str, match_count: int = 15,
                                  vector_weight: float = 0.6,
                                  keyword_weight: float = 0.4) -> List[Dict]:
    """
    Perform Hybrid Search combining Vector Search + Keyword/BM25 Search
    Uses Reciprocal Rank Fusion (RRF) for combining results
    """
    try:
        if not supabase_client or not openai_client:
            logger.warning("Supabase or OpenAI client not available for hybrid search")
            return []

        logger.info(f"ðŸ” Hybrid Search: '{query}' (vector={vector_weight}, keyword={keyword_weight})")

        # Generate embedding for vector search
        response = await openai_client.embeddings.create(
            model="text-embedding-3-small",
            input=query,
            encoding_format="float"
        )
        query_embedding = response.data[0].embedding

        # Try hybrid_search_products RPC first (if SQL function exists)
        try:
            result = supabase_client.rpc(
                'hybrid_search_products',
                {
                    'query_embedding': query_embedding,
                    'search_query': query,
                    'vector_weight': vector_weight,
                    'keyword_weight': keyword_weight,
                    'match_threshold': 0.15,
                    'match_count': match_count
                }
            ).execute()

            if result.data:
                logger.info(f"âœ“ Hybrid search returned {len(result.data)} products")
                for p in result.data[:3]:
                    logger.info(f"   â†’ {p.get('product_name')}: hybrid={p.get('hybrid_score', 0):.3f} "
                               f"(vec={p.get('vector_score', 0):.3f}, kw={p.get('keyword_score', 0):.3f})")
                return result.data

        except Exception as e:
            logger.warning(f"hybrid_search_products RPC failed: {e}, falling back to manual hybrid search")

        # Fallback: Manual hybrid search (Vector + Keyword separately)
        return await manual_hybrid_search(query, query_embedding, match_count, vector_weight, keyword_weight)

    except Exception as e:
        logger.error(f"Hybrid search failed: {e}", exc_info=True)
        return []


async def manual_hybrid_search(query: str, query_embedding: List[float],
                                match_count: int = 15,
                                vector_weight: float = 0.6,
                                keyword_weight: float = 0.4) -> List[Dict]:
    """
    Manual Hybrid Search fallback - runs vector and keyword search separately
    then combines with Reciprocal Rank Fusion (RRF)
    """
    try:
        # 1. Vector Search
        vector_results = []
        try:
            result = supabase_client.rpc(
                'match_products',
                {
                    'query_embedding': query_embedding,
                    'match_threshold': 0.15,
                    'match_count': match_count * 2
                }
            ).execute()
            if result.data:
                vector_results = result.data
                logger.info(f"   Vector search: {len(vector_results)} results")
        except Exception as e:
            logger.warning(f"Vector search failed: {e}")

        # 2. Keyword Search (ILIKE fallback)
        keyword_results = []
        try:
            # Try keyword_search_products RPC
            result = supabase_client.rpc(
                'keyword_search_products',
                {
                    'search_query': query,
                    'match_count': match_count * 2
                }
            ).execute()
            if result.data:
                keyword_results = result.data
                logger.info(f"   Keyword search (RPC): {len(keyword_results)} results")
        except Exception as e:
            logger.warning(f"keyword_search_products RPC failed: {e}, trying ILIKE")
            # Fallback: ILIKE search
            try:
                result = supabase_client.table('products')\
                    .select('*')\
                    .or_(f"product_name.ilike.%{query}%,"
                         f"target_pest.ilike.%{query}%,"
                         f"applicable_crops.ilike.%{query}%,"
                         f"active_ingredient.ilike.%{query}%")\
                    .limit(match_count * 2)\
                    .execute()
                if result.data:
                    # Add rank score for ILIKE results
                    for i, p in enumerate(result.data):
                        p['rank'] = 1.0 / (i + 1)  # Simple rank score
                    keyword_results = result.data
                    logger.info(f"   Keyword search (ILIKE): {len(keyword_results)} results")
            except Exception as e2:
                logger.warning(f"ILIKE search failed: {e2}")

        # 3. Combine with RRF (Reciprocal Rank Fusion)
        combined = reciprocal_rank_fusion(
            vector_results, keyword_results,
            vector_weight, keyword_weight
        )

        logger.info(f"âœ“ Manual hybrid search combined: {len(combined)} products")
        return combined[:match_count]

    except Exception as e:
        logger.error(f"Manual hybrid search failed: {e}", exc_info=True)
        return []


def reciprocal_rank_fusion(vector_results: List[Dict], keyword_results: List[Dict],
                           vector_weight: float = 0.6, keyword_weight: float = 0.4,
                           k: int = 60) -> List[Dict]:
    """
    Combine vector and keyword search results using Reciprocal Rank Fusion (RRF)
    RRF score = sum(1 / (k + rank)) across all result sets

    Parameters:
    - k: constant to prevent high scores for top results (default 60)
    """
    try:
        # Build product lookup and RRF scores
        products_by_id = {}
        rrf_scores = {}

        # Process vector results
        for rank, product in enumerate(vector_results, 1):
            pid = product.get('id') or product.get('product_name')
            if pid:
                products_by_id[pid] = product
                rrf_scores[pid] = rrf_scores.get(pid, 0) + vector_weight * (1 / (k + rank))
                product['vector_rank'] = rank
                product['vector_score'] = product.get('similarity', 0)

        # Process keyword results
        for rank, product in enumerate(keyword_results, 1):
            pid = product.get('id') or product.get('product_name')
            if pid:
                if pid not in products_by_id:
                    products_by_id[pid] = product
                rrf_scores[pid] = rrf_scores.get(pid, 0) + keyword_weight * (1 / (k + rank))
                products_by_id[pid]['keyword_rank'] = rank
                products_by_id[pid]['keyword_score'] = product.get('rank', 0)

        # Add bonus for products appearing in both
        for pid in rrf_scores:
            product = products_by_id[pid]
            if product.get('vector_rank') and product.get('keyword_rank'):
                rrf_scores[pid] += 0.02  # Small bonus for appearing in both

        # Sort by RRF score
        sorted_ids = sorted(rrf_scores.keys(), key=lambda x: rrf_scores[x], reverse=True)

        # Build final results
        combined_results = []
        for pid in sorted_ids:
            product = products_by_id[pid].copy()
            product['hybrid_score'] = rrf_scores[pid]
            product['similarity'] = rrf_scores[pid]  # Use hybrid score as similarity
            combined_results.append(product)

        return combined_results

    except Exception as e:
        logger.error(f"RRF fusion failed: {e}", exc_info=True)
        # Fallback: return vector results
        return vector_results

async def retrieve_product_recommendation(disease_info: DiseaseDetectionResult) -> List[ProductRecommendation]:
    """
    Query products using Hybrid Search (Vector + Keyword/BM25)
    Returns top 3-6 most relevant products

    à¸ªà¸³à¸«à¸£à¸±à¸šà¹‚à¸£à¸„à¸—à¸µà¹ˆà¸¡à¸µà¹à¸¡à¸¥à¸‡à¸žà¸²à¸«à¸° (à¹€à¸Šà¹ˆà¸™ à¹‚à¸£à¸„à¸ˆà¸¹à¹‹à¸‚à¸­à¸‡à¸‚à¹‰à¸²à¸§) à¸ˆà¸°à¸„à¹‰à¸™à¸«à¸²à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡à¹à¸—à¸™
    """
    try:
        logger.info("ðŸ” Retrieving products with Hybrid Search (Vector + Keyword)")

        if not supabase_client:
            logger.warning("Supabase not configured")
            return []

        disease_name = disease_info.disease_name

        # à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸²à¹‚à¸£à¸„à¸™à¸µà¹‰à¸¡à¸µà¹à¸¡à¸¥à¸‡à¸žà¸²à¸«à¸°à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ â†’ à¸–à¹‰à¸²à¸¡à¸µ à¸„à¹‰à¸™à¸«à¸²à¸¢à¸²à¸†à¹ˆà¸²à¹à¸¡à¸¥à¸‡à¹à¸—à¸™
        pest_type = ""
        if hasattr(disease_info, 'raw_analysis') and disease_info.raw_analysis:
            # à¸”à¸¶à¸‡ pest_type à¸ˆà¸²à¸ raw_analysis à¸–à¹‰à¸²à¸¡à¸µ
            if "à¹„à¸§à¸£à¸±à¸ª" in disease_info.raw_analysis:
                pest_type = "à¹„à¸§à¸£à¸±à¸ª"

        search_query, pest_name = get_search_query_for_disease(disease_name, pest_type)

        if pest_name:
            logger.info(f"ðŸ› à¹‚à¸£à¸„à¸¡à¸µà¸žà¸²à¸«à¸°: {pest_name} â†’ à¸„à¹‰à¸™à¸«à¸²: {search_query}")
        else:
            logger.info(f"ðŸ“ Searching products for: {disease_name}")

        # Check cache first (à¹ƒà¸Šà¹‰ search_query à¹€à¸›à¹‡à¸™ key)
        cache_key = f"products:{search_query}"
        cached_products = await get_from_cache("products", cache_key)
        if cached_products:
            logger.info("âœ“ Using cached product recommendations")
            return [ProductRecommendation(**p) for p in cached_products]

        # Strategy 1: Hybrid Search (Vector + Keyword combined)
        try:
            hybrid_results = await hybrid_search_products(
                query=search_query,  # à¹ƒà¸Šà¹‰ search_query à¹à¸—à¸™ disease_name
                match_count=15,
                vector_weight=0.6,
                keyword_weight=0.4
            )

            if hybrid_results:
                logger.info(f"âœ“ Hybrid search found {len(hybrid_results)} candidates")

                # Apply simple relevance boost first
                for p in hybrid_results:
                    boost = simple_relevance_boost(disease_name, p)
                    p['hybrid_score'] = p.get('hybrid_score', p.get('similarity', 0)) + boost

                # Sort by boosted score
                hybrid_results.sort(key=lambda x: x.get('hybrid_score', 0), reverse=True)

                # Re-rank top candidates with LLM Cross-Encoder (if enabled)
                if ENABLE_RERANKING and len(hybrid_results) > 6:
                    logger.info("ðŸ”„ Applying LLM re-ranking for higher accuracy...")
                    hybrid_results = await rerank_products_with_llm(
                        query=disease_name,
                        products=hybrid_results[:15],  # Top 15 candidates
                        top_k=6,
                        openai_client=openai_client
                    )

                # Filter by hybrid score threshold
                filtered_data = [
                    p for p in hybrid_results
                    if p.get('hybrid_score', p.get('similarity', 0)) > 0.005
                ][:6]

                if filtered_data:
                    logger.info(f"âœ“ Final {len(filtered_data)} products after re-ranking")
                    filtered_products = build_recommendations_from_data(filtered_data)

                    # Cache the results
                    if filtered_products:
                        await set_to_cache("products", cache_key, [r.dict() for r in filtered_products])

                    return filtered_products
                else:
                    # No products passed threshold - return empty instead of forcing results
                    logger.warning("âš ï¸ No products passed relevance threshold - no recommendations")
                    return []

        except Exception as e:
            logger.warning(f"Hybrid search failed: {e}, trying fallback")

        # Strategy 2: Keyword search fallback
        matches_data = []

        # Search in target_pest field
        try:
            result = supabase_client.table('products')\
                .select('*')\
                .ilike('target_pest', f'%{disease_name}%')\
                .limit(10)\
                .execute()

            if result.data:
                matches_data.extend(result.data)
                logger.info(f"Found {len(result.data)} products in target_pest")
        except Exception as e:
            logger.warning(f"target_pest search failed: {e}")

        # If no results, search by pest type
        if not matches_data:
            try:
                pest_keywords = []
                if "à¹€à¸Šà¸·à¹‰à¸­à¸£à¸²" in disease_info.raw_analysis:
                    pest_keywords = ["à¹€à¸Šà¸·à¹‰à¸­à¸£à¸²", "à¹‚à¸£à¸„à¸žà¸·à¸Š"]
                elif "à¹„à¸§à¸£à¸±à¸ª" in disease_info.raw_analysis:
                    pest_keywords = ["à¹„à¸§à¸£à¸±à¸ª"]
                elif "à¸¨à¸±à¸•à¸£à¸¹à¸žà¸·à¸Š" in disease_info.raw_analysis or "à¹à¸¡à¸¥à¸‡" in disease_info.raw_analysis:
                    pest_keywords = ["à¹à¸¡à¸¥à¸‡", "à¸¨à¸±à¸•à¸£à¸¹à¸žà¸·à¸Š", "à¹€à¸žà¸¥à¸µà¹‰à¸¢"]
                elif "à¸§à¸±à¸Šà¸žà¸·à¸Š" in disease_info.raw_analysis:
                    pest_keywords = ["à¸§à¸±à¸Šà¸žà¸·à¸Š", "à¸«à¸à¹‰à¸²"]

                for keyword in pest_keywords:
                    result = supabase_client.table('products')\
                        .select('*')\
                        .ilike('target_pest', f'%{keyword}%')\
                        .limit(5)\
                        .execute()

                    if result.data:
                        matches_data.extend(result.data)
                        logger.info(f"Found {len(result.data)} products for keyword: {keyword}")
                        break

            except Exception as e:
                logger.warning(f"Keyword search failed: {e}")

        if not matches_data:
            logger.warning("No products found with any search strategy")
            return []

        logger.info(f"Total products found: {len(matches_data)}")
        recommendations = build_recommendations_from_data(matches_data[:6])

        # Cache the results
        if recommendations:
            await set_to_cache("products", cache_key, [r.dict() for r in recommendations])

        return recommendations

    except Exception as e:
        logger.error(f"Product search failed: {e}", exc_info=True)
        return []


def build_recommendations_from_data(products_data: List[Dict]) -> List[ProductRecommendation]:
    """Build ProductRecommendation list from raw data"""
    recommendations = []
    seen_products = set()
    
    for product in products_data:
        pname = product.get("product_name", "à¹„à¸¡à¹ˆà¸£à¸°à¸šà¸¸à¸Šà¸·à¹ˆà¸­")
        
        if pname in seen_products:
            continue
        seen_products.add(pname)
        
        pest = product.get("target_pest", "")
        if not pest or pest.strip() == "":
            continue
        
        rec = ProductRecommendation(
            product_name=pname,
            active_ingredient=product.get("active_ingredient", ""),
            target_pest=pest,
            applicable_crops=product.get("applicable_crops", ""),
            how_to_use=product.get("how_to_use", ""),
            usage_period=product.get("usage_period", ""),
            usage_rate=product.get("usage_rate", ""),
            link_product=product.get("link_product", ""),
            score=product.get("similarity", 0.7)
        )
        recommendations.append(rec)
    
    return recommendations

async def recommend_products_by_intent(question: str, keywords: dict) -> str:
    """à¹à¸™à¸°à¸™à¸³à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¸•à¸²à¸¡ intent à¸‚à¸­à¸‡à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰ (à¹€à¸žà¸´à¹ˆà¸¡à¸œà¸¥à¸œà¸¥à¸´à¸•, à¹à¸à¹‰à¸›à¸±à¸à¸«à¸², à¸¯à¸¥à¸¯)"""
    try:
        intent = keywords.get('intent')
        logger.info(f"ðŸŽ¯ Intent-based recommendation: {intent}")
        logger.info(f"ðŸ“ Keywords: crops={keywords.get('crops')}, pests={keywords.get('pests')}")
        
        if not supabase_client:
            logger.error("âŒ Supabase client not available")
            return await answer_product_question(question, keywords)
        
        if not openai_client:
            logger.error("âŒ OpenAI client not available")
            return await answer_product_question(question, keywords)
        
        intent = keywords.get("intent")
        crops = keywords.get("crops", [])
        pests = keywords.get("pests", [])
        
        # Build search query based on intent
        search_queries = []
        
        if intent == "increase_yield":
            # à¹€à¸žà¸´à¹ˆà¸¡à¸œà¸¥à¸œà¸¥à¸´à¸• - search more broadly
            if crops:
                for crop in crops[:2]:
                    # Primary searches
                    search_queries.append(f"à¹€à¸žà¸´à¹ˆà¸¡à¸œà¸¥à¸œà¸¥à¸´à¸• {crop}")
                    search_queries.append(f"à¸šà¸³à¸£à¸¸à¸‡ {crop}")
                    search_queries.append(f"à¸›à¸¸à¹‹à¸¢ {crop}")
                    search_queries.append(f"à¸®à¸­à¸£à¹Œà¹‚à¸¡à¸™ {crop}")
                    # Also search by crop name directly
                    search_queries.append(crop)
                    # Problem prevention for yield
                    search_queries.append(f"à¸›à¹‰à¸­à¸‡à¸à¸±à¸™à¹‚à¸£à¸„ {crop}")
                    search_queries.append(f"à¸šà¸³à¸£à¸¸à¸‡à¸•à¹‰à¸™ {crop}")
            else:
                search_queries.append("à¹€à¸žà¸´à¹ˆà¸¡à¸œà¸¥à¸œà¸¥à¸´à¸• à¸›à¸¸à¹‹à¸¢ à¸®à¸­à¸£à¹Œà¹‚à¸¡à¸™ à¸šà¸³à¸£à¸¸à¸‡")
        
        elif intent == "solve_problem":
            # à¹à¸à¹‰à¸›à¸±à¸à¸«à¸²à¸¨à¸±à¸•à¸£à¸¹à¸žà¸·à¸Š
            if pests and crops:
                for pest in pests[:2]:
                    for crop in crops[:2]:
                        search_queries.append(f"à¸à¸³à¸ˆà¸±à¸” {pest} {crop}")
                        # English variants
                        if any(c.isalpha() for c in crop) or any(c.isalpha() for c in pest):
                            search_queries.append(f"control {pest} {crop}")
                            search_queries.append(f"manage {pest} on {crop}")
            elif pests:
                for pest in pests[:2]:
                    search_queries.append(f"à¸à¸³à¸ˆà¸±à¸” {pest}")
                    if any(c.isalpha() for c in pest):
                        search_queries.append(f"control {pest}")
            elif crops:
                for crop in crops[:2]:
                    search_queries.append(f"à¸›à¹‰à¸­à¸‡à¸à¸±à¸™à¹‚à¸£à¸„ {crop}")
                    if any(c.isalpha() for c in crop):
                        search_queries.append(f"prevent disease {crop}")
        
        elif intent == "general_care":
            # à¸”à¸¹à¹à¸¥à¸—à¸±à¹ˆà¸§à¹„à¸›
            if crops:
                for crop in crops[:2]:
                    search_queries.append(f"à¸”à¸¹à¹à¸¥ {crop}")
                    search_queries.append(f"à¸šà¸³à¸£à¸¸à¸‡ {crop}")
        
        else:
            # Default: product inquiry
            if crops:
                search_queries.append(f"à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œ {crops[0]}")
            if pests:
                search_queries.append(f"à¸à¸³à¸ˆà¸±à¸” {pests[0]}")
        
        # Hybrid search for each query (Vector + Keyword combined)
        all_products = []
        logger.info(f"ðŸ” Hybrid searching with {len(search_queries)} queries: {search_queries[:5]}")

        for query in search_queries[:5]:  # Top 5 queries
            try:
                logger.info(f"   â†’ Query: '{query}'")

                # Use hybrid search (Vector + Keyword)
                results = await hybrid_search_products(
                    query=query,
                    match_count=15,
                    vector_weight=0.5,  # Balanced weights for intent-based search
                    keyword_weight=0.5
                )

                if results:
                    all_products.extend(results)
                    logger.info(f"   âœ“ Found {len(results)} products (hybrid)")
                else:
                    logger.warning(f"   âš ï¸ No products found")
            except Exception as e:
                logger.error(f"   âŒ Hybrid search failed: {e}", exc_info=True)
        
        # Remove duplicates and apply relevance boost
        seen = set()
        unique_products = []
        for p in all_products:
            pname = p.get('product_name', '')
            if pname and pname not in seen:
                seen.add(pname)
                # Apply relevance boost based on query terms
                boost = 0
                for query in search_queries[:3]:
                    boost += simple_relevance_boost(query, p)
                p['hybrid_score'] = p.get('hybrid_score', p.get('similarity', 0)) + (boost / 3)
                unique_products.append(p)

        # Sort by boosted score
        unique_products.sort(key=lambda x: x.get('hybrid_score', 0), reverse=True)

        # Re-rank with LLM if enabled and enough candidates
        if ENABLE_RERANKING and len(unique_products) > 6:
            logger.info("ðŸ”„ Applying LLM re-ranking for intent-based search...")
            unique_products = await rerank_products_with_llm(
                query=question,
                products=unique_products[:15],
                top_k=10,
                openai_client=openai_client
            )

        logger.info(f"ðŸ“¦ Total products: {len(all_products)}, Unique: {len(unique_products)}")

        if not unique_products:
            # Fallback 1: Search by applicable_crops
            logger.warning("âš ï¸ No products from vector search, trying applicable_crops search")
            if crops:
                for crop in crops[:2]:
                    try:
                        result = supabase_client.table('products')\
                            .select('*')\
                            .ilike('applicable_crops', f'%{crop}%')\
                            .limit(10)\
                            .execute()

                        if result.data:
                            unique_products.extend(result.data)
                            logger.info(f"âœ“ Found {len(result.data)} products for crop: {crop}")
                    except Exception as e:
                        logger.warning(f"applicable_crops search failed: {e}")

            # Fallback 2: Search by target_pest for common issues
            if not unique_products and pests:
                for pest in pests[:2]:
                    try:
                        result = supabase_client.table('products')\
                            .select('*')\
                            .ilike('target_pest', f'%{pest}%')\
                            .limit(10)\
                            .execute()

                        if result.data:
                            unique_products.extend(result.data)
                            logger.info(f"âœ“ Found {len(result.data)} products for pest: {pest}")
                    except Exception as e:
                        logger.warning(f"target_pest search failed: {e}")

            # If still no products, fallback to keyword search
            if not unique_products:
                logger.warning("âš ï¸ No products found, trying keyword search")
                return await answer_product_question(question, keywords)
        
        # Log product names
        product_names = [p.get('product_name', 'N/A') for p in unique_products[:5]]
        logger.info(f"ðŸ“‹ Top products: {', '.join(product_names)}")
        
        # Use Gemini to filter and create natural response
        products_text = ""
        for idx, p in enumerate(unique_products[:15], 1):  # Top 15 for Gemini
            products_text += f"\n[{idx}] {p.get('product_name', 'N/A')}"
            products_text += f"\n    â€¢ à¸ªà¸²à¸£à¸ªà¸³à¸„à¸±à¸: {p.get('active_ingredient', 'N/A')}"
            products_text += f"\n    â€¢ à¸¨à¸±à¸•à¸£à¸¹à¸žà¸·à¸Šà¸—à¸µà¹ˆà¸à¸³à¸ˆà¸±à¸”à¹„à¸”à¹‰: {p.get('target_pest', 'N/A')[:150]}"
            products_text += f"\n    â€¢ à¸§à¸´à¸˜à¸µà¹ƒà¸Šà¹‰: {p.get('how_to_use', 'N/A')[:200]}"
            products_text += f"\n    â€¢ à¸­à¸±à¸•à¸£à¸²à¸à¸²à¸£à¹ƒà¸Šà¹‰: {p.get('usage_rate', 'N/A')}"
            if p.get('usage_period'):
                products_text += f"\n    â€¢ à¸Šà¹ˆà¸§à¸‡à¸à¸²à¸£à¹ƒà¸Šà¹‰: {p.get('usage_period')}"
            products_text += f"\n    â€¢ à¹ƒà¸Šà¹‰à¸à¸±à¸šà¸žà¸·à¸Š: {p.get('applicable_crops', 'N/A')[:100]}"
            products_text += f"\n    â€¢ Similarity: {p.get('similarity', 0):.0%}\n"
        
        # Create intent-specific prompt
        if intent == "increase_yield":
            prompt = f"""à¸„à¸¸à¸“à¸„à¸·à¸­à¸œà¸¹à¹‰à¸Šà¹ˆà¸§à¸¢à¹à¸™à¸°à¸™à¸³à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¸ˆà¸²à¸ ICP Ladda

à¸„à¸³à¸–à¸²à¸¡à¸ˆà¸²à¸à¹€à¸à¸©à¸•à¸£à¸à¸£: {question}

à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¸—à¸µà¹ˆà¸¡à¸µà¹ƒà¸™à¸£à¸°à¸šà¸š (à¸«à¹‰à¸²à¸¡à¹à¸™à¸°à¸™à¸³à¸™à¸­à¸à¸ˆà¸²à¸à¸™à¸µà¹‰):
{products_text}

ðŸš¨ **à¸à¸Žà¸—à¸µà¹ˆà¸«à¹‰à¸²à¸¡à¸¥à¸°à¹€à¸¡à¸´à¸”**:
1. à¹ƒà¸Šà¹‰à¹€à¸‰à¸žà¸²à¸°à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¸ˆà¸²à¸à¸£à¸²à¸¢à¸à¸²à¸£à¸‚à¹‰à¸²à¸‡à¸•à¹‰à¸™à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™
2.  à¸«à¹‰à¸²à¸¡à¸ªà¸£à¹‰à¸²à¸‡à¸Šà¸·à¹ˆà¸­à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¹ƒà¸«à¸¡à¹ˆ
3. à¸«à¹‰à¸²à¸¡à¹à¸™à¸°à¸™à¸³à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¸£à¸²à¸¢à¸à¸²à¸£
4. à¸–à¹‰à¸²à¹„à¸¡à¹ˆà¸¡à¸µà¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡ à¹ƒà¸«à¹‰à¸šà¸­à¸à¸•à¸£à¸‡à¹†à¸§à¹ˆà¸² "à¹„à¸¡à¹ˆà¸žà¸šà¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡à¹ƒà¸™à¸£à¸°à¸šà¸š"

ðŸ“‹ **à¸§à¸´à¸˜à¸µà¸•à¸­à¸š**:
1. à¹€à¸¥à¸·à¸­à¸ 3-5 à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¸ˆà¸²à¸à¸£à¸²à¸¢à¸à¸²à¸£à¸‚à¹‰à¸²à¸‡à¸•à¹‰à¸™
2. à¹ƒà¸Šà¹‰à¸Šà¸·à¹ˆà¸­à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¸•à¸²à¸¡à¸—à¸µà¹ˆà¸£à¸°à¸šà¸¸à¹ƒà¸™à¸£à¸²à¸¢à¸à¸²à¸£à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™
3. à¸„à¸±à¸”à¸¥à¸­à¸à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¸ˆà¸²à¸à¸£à¸²à¸¢à¸à¸²à¸£à¹‚à¸”à¸¢à¸•à¸£à¸‡ à¸«à¹‰à¸²à¸¡à¹à¸•à¹ˆà¸‡à¹€à¸•à¸´à¸¡
4. à¹à¸ªà¸”à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸„à¸£à¸šà¸–à¹‰à¸§à¸™à¸•à¸²à¸¡à¸™à¸µà¹‰:
   - à¸Šà¸·à¹ˆà¸­à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œ (à¸•à¸²à¸¡à¸£à¸²à¸¢à¸à¸²à¸£)
   - à¸ªà¸²à¸£à¸ªà¸³à¸„à¸±à¸ (à¸•à¸²à¸¡à¸£à¸²à¸¢à¸à¸²à¸£)
   - à¸Šà¹ˆà¸§à¸‡à¸à¸²à¸£à¹ƒà¸Šà¹‰ (à¸•à¸²à¸¡à¸£à¸²à¸¢à¸à¸²à¸£)
   - à¹ƒà¸Šà¹‰à¸à¸±à¸šà¸žà¸·à¸Š (à¸•à¸²à¸¡à¸£à¸²à¸¢à¸à¸²à¸£)
   - à¸§à¸´à¸˜à¸µà¹ƒà¸Šà¹‰ (à¸•à¸²à¸¡à¸£à¸²à¸¢à¸à¸²à¸£)
   - à¸­à¸±à¸•à¸£à¸²à¸à¸²à¸£à¹ƒà¸Šà¹‰ (à¸•à¸²à¸¡à¸£à¸²à¸¢à¸à¸²à¸£)

5. à¹ƒà¸Šà¹‰à¸ à¸²à¸©à¸²à¸‡à¹ˆà¸²à¸¢à¹† à¸žà¸£à¹‰à¸­à¸¡ emoji
6. à¹„à¸¡à¹ˆà¹ƒà¸Šà¹‰ markdown

à¸•à¸­à¸šà¸„à¸³à¸–à¸²à¸¡:"""
        
        elif intent == "solve_problem":
            prompt = f"""à¸„à¸¸à¸“à¸„à¸·à¸­à¸œà¸¹à¹‰à¸Šà¹ˆà¸§à¸¢à¹à¸™à¸°à¸™à¸³à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¸ˆà¸²à¸ ICP Ladda

à¸„à¸³à¸–à¸²à¸¡à¸ˆà¸²à¸à¹€à¸à¸©à¸•à¸£à¸à¸£: {question}

à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¸—à¸µà¹ˆà¸¡à¸µà¹ƒà¸™à¸£à¸°à¸šà¸š (à¸«à¹‰à¸²à¸¡à¹à¸™à¸°à¸™à¸³à¸™à¸­à¸à¸ˆà¸²à¸à¸™à¸µà¹‰):
{products_text}

à¸¨à¸±à¸•à¸£à¸¹à¸žà¸·à¸Šà¸—à¸µà¹ˆà¸žà¸š: {', '.join(pests) if pests else 'à¹„à¸¡à¹ˆà¸£à¸°à¸šà¸¸'}
à¸žà¸·à¸Šà¸—à¸µà¹ˆà¸›à¸¥à¸¹à¸: {', '.join(crops) if crops else 'à¹„à¸¡à¹ˆà¸£à¸°à¸šà¸¸'}

ðŸš¨ **à¸à¸Žà¸—à¸µà¹ˆà¸«à¹‰à¸²à¸¡à¸¥à¸°à¹€à¸¡à¸´à¸”**:
1. à¹ƒà¸Šà¹‰à¹€à¸‰à¸žà¸²à¸°à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¸ˆà¸²à¸à¸£à¸²à¸¢à¸à¸²à¸£à¸‚à¹‰à¸²à¸‡à¸•à¹‰à¸™à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™
2. à¸«à¹‰à¸²à¸¡à¸ªà¸£à¹‰à¸²à¸‡à¸Šà¸·à¹ˆà¸­à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¹ƒà¸«à¸¡à¹ˆ
3. à¸«à¹‰à¸²à¸¡à¹à¸™à¸°à¸™à¸³à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¸£à¸²à¸¢à¸à¸²à¸£
4. à¹€à¸¥à¸·à¸­à¸à¹€à¸‰à¸žà¸²à¸°à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¸—à¸µà¹ˆà¸à¸³à¸ˆà¸±à¸”à¸¨à¸±à¸•à¸£à¸¹à¸žà¸·à¸Šà¸—à¸µà¹ˆà¸£à¸°à¸šà¸¸à¹„à¸”à¹‰

ðŸ“‹ **à¸§à¸´à¸˜à¸µà¸•à¸­à¸š**:
1. à¹€à¸¥à¸·à¸­à¸ 3-5 à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¸ˆà¸²à¸à¸£à¸²à¸¢à¸à¸²à¸£à¸‚à¹‰à¸²à¸‡à¸•à¹‰à¸™
2. à¹ƒà¸Šà¹‰à¸Šà¸·à¹ˆà¸­à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¸•à¸²à¸¡à¸—à¸µà¹ˆà¸£à¸°à¸šà¸¸à¹ƒà¸™à¸£à¸²à¸¢à¸à¸²à¸£à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™
3. à¸„à¸±à¸”à¸¥à¸­à¸à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¸ˆà¸²à¸à¸£à¸²à¸¢à¸à¸²à¸£à¹‚à¸”à¸¢à¸•à¸£à¸‡ à¸«à¹‰à¸²à¸¡à¹à¸•à¹ˆà¸‡à¹€à¸•à¸´à¸¡
4. à¹à¸ªà¸”à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸„à¸£à¸šà¸–à¹‰à¸§à¸™à¸•à¸²à¸¡à¸™à¸µà¹‰:
   - à¸Šà¸·à¹ˆà¸­à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œ (à¸•à¸²à¸¡à¸£à¸²à¸¢à¸à¸²à¸£)
   - à¸ªà¸²à¸£à¸ªà¸³à¸„à¸±à¸ (à¸•à¸²à¸¡à¸£à¸²à¸¢à¸à¸²à¸£)
   - à¸Šà¹ˆà¸§à¸‡à¸à¸²à¸£à¹ƒà¸Šà¹‰ (à¸•à¸²à¸¡à¸£à¸²à¸¢à¸à¸²à¸£)
   - à¹ƒà¸Šà¹‰à¸à¸±à¸šà¸žà¸·à¸Š (à¸•à¸²à¸¡à¸£à¸²à¸¢à¸à¸²à¸£)
   - à¸§à¸´à¸˜à¸µà¹ƒà¸Šà¹‰ (à¸•à¸²à¸¡à¸£à¸²à¸¢à¸à¸²à¸£)
   - à¸­à¸±à¸•à¸£à¸²à¸à¸²à¸£à¹ƒà¸Šà¹‰ (à¸•à¸²à¸¡à¸£à¸²à¸¢à¸à¸²à¸£)

5. à¹ƒà¸Šà¹‰à¸ à¸²à¸©à¸²à¸‡à¹ˆà¸²à¸¢à¹† à¸žà¸£à¹‰à¸­à¸¡ emoji
6. à¹„à¸¡à¹ˆà¹ƒà¸Šà¹‰ markdown

à¸•à¸­à¸šà¸„à¸³à¸–à¸²à¸¡:"""
        
        else:
            # General product inquiry
            prompt = f"""à¸„à¸¸à¸“à¸„à¸·à¸­à¸œà¸¹à¹‰à¸Šà¹ˆà¸§à¸¢à¹à¸™à¸°à¸™à¸³à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¸ˆà¸²à¸ ICP Ladda

à¸„à¸³à¸–à¸²à¸¡à¸ˆà¸²à¸à¹€à¸à¸©à¸•à¸£à¸à¸£: {question}

à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¸—à¸µà¹ˆà¸¡à¸µà¹ƒà¸™à¸£à¸°à¸šà¸š (à¸«à¹‰à¸²à¸¡à¹à¸™à¸°à¸™à¸³à¸™à¸­à¸à¸ˆà¸²à¸à¸™à¸µà¹‰):
{products_text}

ðŸš¨ **à¸à¸Žà¸—à¸µà¹ˆà¸«à¹‰à¸²à¸¡à¸¥à¸°à¹€à¸¡à¸´à¸”**:
1. à¹ƒà¸Šà¹‰à¹€à¸‰à¸žà¸²à¸°à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¸ˆà¸²à¸à¸£à¸²à¸¢à¸à¸²à¸£à¸‚à¹‰à¸²à¸‡à¸•à¹‰à¸™à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™
2. à¸«à¹‰à¸²à¸¡à¸ªà¸£à¹‰à¸²à¸‡à¸Šà¸·à¹ˆà¸­à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¹ƒà¸«à¸¡à¹ˆ
3. à¸«à¹‰à¸²à¸¡à¹à¸™à¸°à¸™à¸³à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¹„à¸”à¹‰à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¸£à¸²à¸¢à¸à¸²à¸£

ðŸ“‹ **à¸§à¸´à¸˜à¸µà¸•à¸­à¸š**:
1. à¹€à¸¥à¸·à¸­à¸ 3-5 à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¸ˆà¸²à¸à¸£à¸²à¸¢à¸à¸²à¸£à¸‚à¹‰à¸²à¸‡à¸•à¹‰à¸™  
2. à¹ƒà¸Šà¹‰à¸Šà¸·à¹ˆà¸­ exact à¸•à¸²à¸¡à¸£à¸²à¸¢à¸à¸²à¸£à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™
3. à¸„à¸±à¸”à¸¥à¸­à¸à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¸ˆà¸²à¸à¸£à¸²à¸¢à¸à¸²à¸£
4. à¹ƒà¸Šà¹‰à¸ à¸²à¸©à¸²à¸‡à¹ˆà¸²à¸¢à¹† à¸žà¸£à¹‰à¸­à¸¡ emoji
5. à¹„à¸¡à¹ˆà¹ƒà¸Šà¹‰ markdown

à¸•à¸­à¸šà¸„à¸³à¸–à¸²à¸¡:"""
        
        # Check if AI is available
        if not openai_client:
            logger.warning("OpenAI not available, using simple format")
            return await format_product_list_simple(unique_products[:5], question, intent)
        
        try:
            response = await openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "You are a strict product assistant. ONLY recommend products from the provided list. Never create or suggest products not in the list."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,  # à¸¥à¸”à¸¥à¸‡à¸ˆà¸²à¸ 0.7 â†’ 0.1 à¹€à¸žà¸·à¹ˆà¸­à¸¥à¸”à¸à¸²à¸£à¸ªà¸£à¹‰à¸²à¸‡à¸ªà¸£à¸£à¸„à¹Œ
                max_tokens=800
            )
            answer = response.choices[0].message.content.strip()
            answer = answer.replace("```", "").replace("**", "").replace("##", "")
            
            # Add footer
            answer += "\n\n" + "="*40
            answer += "\nðŸ“š à¸”à¸¹à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”:"
            answer += "\nðŸ”— https://www.icpladda.com/about/"
            answer += "\n\nðŸ’¡ à¸«à¸²à¸à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸žà¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡ à¸à¸£à¸¸à¸“à¸²à¸–à¸²à¸¡à¹„à¸”à¹‰à¹€à¸¥à¸¢à¸„à¹ˆà¸° ðŸ˜Š"
            
            logger.info(f"âœ“ Intent-based answer generated ({intent})")
            return answer
            
        except Exception as e:
            logger.error(f"AI generation failed: {e}", exc_info=True)
            # Fallback to simple product list
            return await format_product_list_simple(unique_products[:5], question, intent)
        
    except Exception as e:
        logger.error(f"Error in intent-based recommendation: {e}", exc_info=True)
        return await answer_product_question(question, keywords)

async def format_product_list_simple(products: list, question: str, intent: str) -> str:
    """Format product list as simple fallback"""
    if intent == "increase_yield":
        header = "ðŸŒ± à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¹à¸™à¸°à¸™à¸³à¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸žà¸´à¹ˆà¸¡à¸œà¸¥à¸œà¸¥à¸´à¸•:\n"
    elif intent == "solve_problem":
        header = "ðŸ’Š à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¹à¸™à¸°à¸™à¸³à¸ªà¸³à¸«à¸£à¸±à¸šà¹à¸à¹‰à¸›à¸±à¸à¸«à¸²à¸¨à¸±à¸•à¸£à¸¹à¸žà¸·à¸Š:\n"
    else:
        header = "ðŸ“¦ à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¹à¸™à¸°à¸™à¸³:\n"
    
    response = header
    for idx, p in enumerate(products, 1):
        response += f"\n{idx}. {p.get('product_name', 'N/A')}"
        
        # à¸ªà¸²à¸£à¸ªà¸³à¸„à¸±à¸
        if p.get('active_ingredient'):
            response += f"\n   - à¸ªà¸²à¸£à¸ªà¸³à¸„à¸±à¸: {p.get('active_ingredient')}"
        
        # à¸¨à¸±à¸•à¸£à¸¹à¸žà¸·à¸Šà¸—à¸µà¹ˆà¸à¸³à¸ˆà¸±à¸”à¹„à¸”à¹‰
        if p.get('target_pest'):
            pest = p.get('target_pest')[:150] + "..." if len(p.get('target_pest', '')) > 150 else p.get('target_pest', '')
            response += f"\n   - à¸¨à¸±à¸•à¸£à¸¹à¸žà¸·à¸Šà¸—à¸µà¹ˆà¸à¸³à¸ˆà¸±à¸”à¹„à¸”à¹‰: {pest}"
        
        # à¸§à¸´à¸˜à¸µà¹ƒà¸Šà¹‰
        if p.get('how_to_use'):
            how_to = p.get('how_to_use')[:200] + "..." if len(p.get('how_to_use', '')) > 200 else p.get('how_to_use', '')
            response += f"\n   - à¸§à¸´à¸˜à¸µà¹ƒà¸Šà¹‰: {how_to}"
        
        # à¸­à¸±à¸•à¸£à¸²à¸à¸²à¸£à¹ƒà¸Šà¹‰
        if p.get('usage_rate'):
            response += f"\n   - à¸­à¸±à¸•à¸£à¸²à¸à¸²à¸£à¹ƒà¸Šà¹‰: {p.get('usage_rate')}"
        
        # à¸Šà¹ˆà¸§à¸‡à¸à¸²à¸£à¹ƒà¸Šà¹‰
        if p.get('usage_period'):
            response += f"\n   - à¸Šà¹ˆà¸§à¸‡à¸à¸²à¸£à¹ƒà¸Šà¹‰: {p.get('usage_period')}"
        
        # à¹ƒà¸Šà¹‰à¸à¸±à¸šà¸žà¸·à¸Š
        if p.get('applicable_crops'):
            crops = p.get('applicable_crops')[:100] + "..." if len(p.get('applicable_crops', '')) > 100 else p.get('applicable_crops', '')
            response += f"\n   - à¹ƒà¸Šà¹‰à¸à¸±à¸šà¸žà¸·à¸Š: {crops}"
        
        response += "\n"
    
    response += "\nðŸ“š à¸”à¸¹à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¹€à¸žà¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡: https://www.icpladda.com/about/"
    return response

async def answer_product_question(question: str, keywords: dict) -> str:
    """Answer product-specific questions with high accuracy"""
    try:
        logger.info(f"Product-specific query: {question[:50]}...")
        
        if not supabase_client:
            return "à¸‚à¸­à¸­à¸ à¸±à¸¢à¸„à¹ˆà¸° à¸£à¸°à¸šà¸šà¹„à¸¡à¹ˆà¸žà¸£à¹‰à¸­à¸¡à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹ƒà¸™à¸‚à¸“à¸°à¸™à¸µà¹‰"
        
        products_data = []
        
        # Search by pest/disease
        if keywords["pests"]:
            for pest in keywords["pests"][:2]:
                result = supabase_client.table('products')\
                    .select('*')\
                    .ilike('target_pest', f'%{pest}%')\
                    .limit(5)\
                    .execute()
                if result.data:
                    products_data.extend(result.data)
        
        # Search by crop
        if keywords["crops"]:
            for crop in keywords["crops"][:2]:
                result = supabase_client.table('products')\
                    .select('*')\
                    .ilike('applicable_crops', f'%{crop}%')\
                    .limit(5)\
                    .execute()
                if result.data:
                    products_data.extend(result.data)
        
        # Search by product name
        if keywords["products"]:
            for prod in keywords["products"]:
                if len(prod) > 3:
                    result = supabase_client.table('products')\
                        .select('*')\
                        .ilike('product_name', f'%{prod}%')\
                        .limit(5)\
                        .execute()
                    if result.data:
                        products_data.extend(result.data)
        
        # If no specific keywords, get general products
        if not products_data:
            result = supabase_client.table('products')\
                .select('*')\
                .limit(10)\
                .execute()
            if result.data:
                products_data = result.data
        
        if not products_data:
            return "à¸‚à¸­à¸­à¸ à¸±à¸¢à¸„à¹ˆà¸° à¹„à¸¡à¹ˆà¸žà¸šà¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¸—à¸µà¹ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡ à¸à¸£à¸¸à¸“à¸²à¸£à¸°à¸šà¸¸à¸Šà¸·à¹ˆà¸­à¸žà¸·à¸Šà¸«à¸£à¸·à¸­à¸¨à¸±à¸•à¸£à¸¹à¸žà¸·à¸Šà¸—à¸µà¹ˆà¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸à¸³à¸ˆà¸±à¸”à¸„à¹ˆà¸° ðŸŒ±"
        
        # Remove duplicates
        seen = set()
        unique_products = []
        for p in products_data:
            pname = p.get('product_name', '')
            if pname and pname not in seen:
                seen.add(pname)
                unique_products.append(p)
        
        # Use Gemini to filter and format response
        products_text = ""
        for idx, p in enumerate(unique_products[:10], 1):
            products_text += f"\n[{idx}] {p.get('product_name', 'N/A')}"
            products_text += f"\n    à¸ªà¸²à¸£à¸ªà¸³à¸„à¸±à¸: {p.get('active_ingredient', 'N/A')}"
            products_text += f"\n    à¸¨à¸±à¸•à¸£à¸¹à¸žà¸·à¸Š: {p.get('target_pest', 'N/A')[:100]}"
            products_text += f"\n    à¹ƒà¸Šà¹‰à¸à¸±à¸šà¸žà¸·à¸Š: {p.get('applicable_crops', 'N/A')[:80]}"
            products_text += f"\n    à¸Šà¹ˆà¸§à¸‡à¸à¸²à¸£à¹ƒà¸Šà¹‰: {p.get('usage_period', 'N/A')}"
            products_text += f"\n    à¸­à¸±à¸•à¸£à¸²à¹ƒà¸Šà¹‰: {p.get('usage_rate', 'N/A')}"
            products_text += "\n"
        
        prompt = f"""à¸„à¸¸à¸“à¸„à¸·à¸­à¸œà¸¹à¹‰à¹€à¸Šà¸µà¹ˆà¸¢à¸§à¸Šà¸²à¸à¸”à¹‰à¸²à¸™à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¸›à¹‰à¸­à¸‡à¸à¸±à¸™à¸à¸³à¸ˆà¸±à¸”à¸¨à¸±à¸•à¸£à¸¹à¸žà¸·à¸Šà¸‚à¸­à¸‡ ICP Ladda

à¸„à¸³à¸–à¸²à¸¡à¸ˆà¸²à¸à¹€à¸à¸©à¸•à¸£à¸à¸£: {question}

à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¸—à¸µà¹ˆà¸žà¸šà¹ƒà¸™à¸£à¸°à¸šà¸š:
{products_text}

à¸„à¸³à¹à¸™à¸°à¸™à¸³à¹ƒà¸™à¸à¸²à¸£à¸•à¸­à¸š:
1. **à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸„à¸³à¸–à¸²à¸¡** - à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸§à¹ˆà¸²à¹€à¸à¸©à¸•à¸£à¸à¸£à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸­à¸°à¹„à¸£
2. **à¹€à¸¥à¸·à¸­à¸à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡** - à¹€à¸¥à¸·à¸­à¸ 3-5 à¸£à¸²à¸¢à¸à¸²à¸£à¸—à¸µà¹ˆà¸•à¸£à¸‡à¸—à¸µà¹ˆà¸ªà¸¸à¸”
3. **à¸ˆà¸±à¸”à¸¥à¸³à¸”à¸±à¸š** - à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡à¸—à¸µà¹ˆà¸ªà¸¸à¸”à¸à¹ˆà¸­à¸™
4. **à¹à¸ªà¸”à¸‡à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”**:
   - à¸Šà¸·à¹ˆà¸­à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œ
   - à¸ªà¸²à¸£à¸ªà¸³à¸„à¸±à¸
   - à¸¨à¸±à¸•à¸£à¸¹à¸žà¸·à¸Šà¸—à¸µà¹ˆà¸à¸³à¸ˆà¸±à¸”à¹„à¸”à¹‰
   - à¸žà¸·à¸Šà¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¹„à¸”à¹‰
   - à¸­à¸±à¸•à¸£à¸²à¸à¸²à¸£à¹ƒà¸Šà¹‰
   - à¸§à¸´à¸˜à¸µà¹ƒà¸Šà¹‰à¹‚à¸”à¸¢à¸¢à¹ˆà¸­
5. **à¹€à¸žà¸´à¹ˆà¸¡à¸„à¸³à¹à¸™à¸°à¸™à¸³**:
   - à¸­à¹ˆà¸²à¸™à¸‰à¸¥à¸²à¸à¸à¹ˆà¸­à¸™à¹ƒà¸Šà¹‰
   - à¹ƒà¸Šà¹‰à¸­à¸¸à¸›à¸à¸£à¸“à¹Œà¸›à¹‰à¸­à¸‡à¸à¸±à¸™à¸•à¸±à¸§
   - à¸—à¸”à¸ªà¸­à¸šà¹ƒà¸™à¸žà¸·à¹‰à¸™à¸—à¸µà¹ˆà¹€à¸¥à¹‡à¸à¸à¹ˆà¸­à¸™
6. **à¹ƒà¸Šà¹‰à¸ à¸²à¸©à¸²à¸‡à¹ˆà¸²à¸¢à¹†** 
7. **à¹„à¸¡à¹ˆà¹ƒà¸Šà¹‰ markdown** - à¸•à¸­à¸šà¹€à¸›à¹‡à¸™à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸˜à¸£à¸£à¸¡à¸”à¸²

**à¹€à¸à¸“à¸‘à¹Œà¸à¸²à¸£à¹€à¸¥à¸·à¸­à¸**:
- à¸–à¹‰à¸²à¸–à¸²à¸¡à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸šà¸žà¸·à¸Šà¹€à¸‰à¸žà¸²à¸° â†’ à¹€à¸¥à¸·à¸­à¸à¹€à¸‰à¸žà¸²à¸°à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¸à¸±à¸šà¸žà¸·à¸Šà¸™à¸±à¹‰à¸™à¹„à¸”à¹‰
- à¸–à¹‰à¸²à¸–à¸²à¸¡à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸šà¸¨à¸±à¸•à¸£à¸¹à¸žà¸·à¸Š â†’ à¹€à¸¥à¸·à¸­à¸à¸—à¸µà¹ˆà¸à¸³à¸ˆà¸±à¸”à¸¨à¸±à¸•à¸£à¸¹à¸žà¸·à¸Šà¸™à¸±à¹‰à¸™à¹„à¸”à¹‰
- à¸–à¹‰à¸²à¸–à¸²à¸¡à¸—à¸±à¹ˆà¸§à¹„à¸› â†’ à¹à¸™à¸°à¸™à¸³à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¸¢à¸­à¸”à¸™à¸´à¸¢à¸¡ 3-5 à¸£à¸²à¸¢à¸à¸²à¸£

à¸•à¸­à¸šà¸„à¸³à¸–à¸²à¸¡:"""

        try:
            response = await openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "You are an agricultural product expert."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=800
            )
            answer = response.choices[0].message.content.strip()
            answer = answer.replace("```", "").replace("**", "").replace("##", "")
            
            # Add footer
            answer += "\n\n" + "="*40
            answer += "\nðŸ“š à¸”à¸¹à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¸—à¸±à¹‰à¸‡à¸«à¸¡à¸”:"
            answer += "\nðŸ”— https://www.icpladda.com/about/"
            answer += "\n\nðŸ’¡ à¸«à¸²à¸à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸žà¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡ à¸à¸£à¸¸à¸“à¸²à¸–à¸²à¸¡à¹„à¸”à¹‰à¹€à¸¥à¸¢à¸„à¹ˆà¸° ðŸ˜Š"
            
            logger.info("âœ“ Product answer generated successfully")
            return answer
            
        except Exception as e:
            logger.error(f"Gemini generation failed: {e}")
            # Fallback: return top 3 products directly
            response = "ðŸ’Š à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¹à¸™à¸°à¸™à¸³à¸ˆà¸²à¸ ICP Ladda:\n"
            for idx, p in enumerate(unique_products[:3], 1):
                response += f"\n{idx}. {p.get('product_name')}"
                if p.get('active_ingredient'):
                    response += f"\n   à¸ªà¸²à¸£à¸ªà¸³à¸„à¸±à¸: {p.get('active_ingredient')}"
                if p.get('target_pest'):
                    pest = p.get('target_pest')[:80] + "..." if len(p.get('target_pest', '')) > 80 else p.get('target_pest', '')
                    response += f"\n   à¸¨à¸±à¸•à¸£à¸¹à¸žà¸·à¸Š: {pest}"
                if p.get('applicable_crops'):
                    crops = p.get('applicable_crops')[:60] + "..." if len(p.get('applicable_crops', '')) > 60 else p.get('applicable_crops', '')
                    response += f"\n   à¹ƒà¸Šà¹‰à¸à¸±à¸šà¸žà¸·à¸Š: {crops}"
                if p.get('usage_period'):
                    response += f"\n   à¸Šà¹ˆà¸§à¸‡à¸à¸²à¸£à¹ƒà¸Šà¹‰: {p.get('usage_period')}"
                if p.get('usage_rate'):
                    response += f"\n   à¸­à¸±à¸•à¸£à¸²à¹ƒà¸Šà¹‰: {p.get('usage_rate')}"
                response += "\n"
            
            response += "\nðŸ“š à¸”à¸¹à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¹€à¸žà¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡: https://www.icpladda.com/about/"
            return response
        
    except Exception as e:
        logger.error(f"Error in product Q&A: {e}", exc_info=True)
        return "à¸‚à¸­à¸­à¸ à¸±à¸¢à¸„à¹ˆà¸° à¹„à¸¡à¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¸„à¹‰à¸™à¸«à¸²à¸œà¸¥à¸´à¸•à¸ à¸±à¸“à¸‘à¹Œà¹„à¸”à¹‰à¹ƒà¸™à¸‚à¸“à¸°à¸™à¸µà¹‰ à¸à¸£à¸¸à¸“à¸²à¸¥à¸­à¸‡à¹ƒà¸«à¸¡à¹ˆà¸­à¸µà¸à¸„à¸£à¸±à¹‰à¸‡à¸„à¹ˆà¸° ðŸ™"
