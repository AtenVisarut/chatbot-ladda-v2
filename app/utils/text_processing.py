import re
from typing import List, Dict

def post_process_answer(answer: str) -> str:
    """Post-process Gemini answer for better quality"""
    if not answer:
        return ""
    
    # 1. Remove markdown formatting
    answer = answer.replace("```", "")
    answer = answer.replace("**", "")
    answer = answer.replace("##", "")
    answer = answer.replace("###", "")
    answer = re.sub(r'\*\*([^*]+)\*\*', r'\1', answer)  # **text** ‚Üí text
    answer = re.sub(r'\*([^*]+)\*', r'\1', answer)  # *text* ‚Üí text
    
    # 2. Fix Thai encoding issues
    answer = re.sub(r'([‡∏Å-‡∏Æ])ƒû([‡∏≥‡∏¥‡∏µ‡∏∏‡∏π‡πÄ‡πÅ‡πÇ‡πÉ‡πÑ‡πà‡πâ‡πä‡πã])', r'\1\2', answer)
    answer = answer.replace('ƒû', '')
    answer = answer.replace('', '')
    answer = answer.replace('\x00', '')
    
    # 3. Fix spacing issues (preserve newlines!)
    # Only collapse multiple spaces within lines, preserve newlines
    answer = re.sub(r'[ \t]+', ' ', answer)  # Multiple spaces/tabs ‚Üí single space (preserve \n)
    answer = answer.replace(' ,', ',')
    answer = answer.replace(' .', '.')
    answer = answer.replace(' :', ':')
    answer = answer.replace('( ', '(')
    answer = answer.replace(' )', ')')
    
    # 4. Fix bullet points (convert markdown to Thai style)
    answer = re.sub(r'^\s*[-*]\s+', '‚Ä¢ ', answer, flags=re.MULTILINE)
    answer = re.sub(r'\n\s*[-*]\s+', '\n‚Ä¢ ', answer)
    
    # 5. Ensure proper line breaks
    answer = re.sub(r'\n{3,}', '\n\n', answer)  # Max 2 line breaks
    
    # 6. Remove leading/trailing whitespace
    answer = answer.strip()
    
    # 7. Fix common Thai typos
    answer = answer.replace('‡∏ï‡πâ', '‡∏ï‡πâ')
    answer = answer.replace('‡∏ï', '‡∏ï')
    
    # 8. Ensure emoji spacing (include common emojis used in responses)
    answer = re.sub(r'([üå±üêõüçÑüíä‚ö†Ô∏è‚úÖüìöüí°üéØüìãüîçüòäüåæüíöü¶†‚öñÔ∏èüìÖüî¢üìäüè∑Ô∏èüí¨üîó])([‡∏Å-‡πôA-Za-z])', r'\1 \2', answer)

    # 9. Normalize dividers to standard format
    answer = re.sub(r'^[-=‚îÄ]{3,}$', '‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ', answer, flags=re.MULTILINE)

    # 10. Remove old [‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠] bracket format (fallback cleanup)
    answer = re.sub(r'^\[([^\]]+)\]\s*$', r'\1', answer, flags=re.MULTILINE)

    return answer

def clean_knowledge_text(text: str) -> str:
    """Clean and format knowledge text for better readability"""
    if not text:
        return ""
    
    # Fix encoding issues - remove corrupted characters
    # Common patterns: ‡∏àƒû‡∏≥, ‡∏•ƒû‡∏≥, ‡∏óƒû‡∏≥, ‡∏ôƒû‡πâ‡∏≥, ‡∏Åƒû‡∏≥
    text = re.sub(r'([‡∏Å-‡∏Æ])ƒû([‡∏≥])', r'\1\2', text)  # ‡∏àƒû‡∏≥ ‚Üí ‡∏à‡∏≥
    text = re.sub(r'([‡∏Å-‡∏Æ])ƒû([‡πâ])', r'\1\2', text)  # ‡∏ôƒû‡πâ ‚Üí ‡∏ô‡πâ
    text = re.sub(r'([‡∏Å-‡∏Æ])ƒû([‡∏¥])', r'\1\2', text)  # ‡∏Åƒû‡∏¥ ‚Üí ‡∏Å‡∏¥
    text = re.sub(r'([‡∏Å-‡∏Æ])ƒû([‡∏µ])', r'\1\2', text)  # ‡∏Åƒû‡∏µ ‚Üí ‡∏Å‡∏µ
    text = re.sub(r'([‡∏Å-‡∏Æ])ƒû([‡∏∏])', r'\1\2', text)  # ‡∏Åƒû‡∏∏ ‚Üí ‡∏Å‡∏∏
    text = re.sub(r'([‡∏Å-‡∏Æ])ƒû([‡∏π])', r'\1\2', text)  # ‡∏Åƒû‡∏π ‚Üí ‡∏Å‡∏π
    text = re.sub(r'([‡∏Å-‡∏Æ])ƒû([‡πà])', r'\1\2', text)  # ‡∏Åƒû‡πà ‚Üí ‡∏Å‡πà
    text = re.sub(r'([‡∏Å-‡∏Æ])ƒû([‡πâ])', r'\1\2', text)  # ‡∏Åƒû‡πâ ‚Üí ‡∏Å‡πâ
    text = re.sub(r'([‡∏Å-‡∏Æ])ƒû([‡πä])', r'\1\2', text)  # ‡∏Åƒû‡πä ‚Üí ‡∏Å‡πä
    text = re.sub(r'([‡∏Å-‡∏Æ])ƒû([‡πã])', r'\1\2', text)  # ‡∏Åƒû‡πã ‚Üí ‡∏Å‡πã
    text = re.sub(r'ƒû', '', text)  # Remove remaining ƒû
    
    # Fix other corrupted characters
    text = text.replace('‡∏ï‡πâ', '‡∏ï‡πâ')  # Fix tone marks
    text = text.replace('‡∏ï', '‡∏ï')
    text = text.replace('', '')  # Remove replacement character
    text = text.replace('\x00', '')  # Remove null character
    
    # Fix common Thai encoding issues
    text = text.replace('√†¬∏', '')  # Remove Thai encoding prefix
    text = text.replace('√†¬π', '')  # Remove Thai encoding prefix
    
    # Remove excessive whitespace
    text = ' '.join(text.split())
    
    # Fix common issues
    text = text.replace('  ', ' ')  # Double spaces
    text = text.replace(' ,', ',')  # Space before comma
    text = text.replace(' .', '.')  # Space before period
    text = text.replace('( ', '(')  # Space after opening parenthesis
    text = text.replace(' )', ')')  # Space before closing parenthesis
    text = text.replace(' :', ':')  # Space before colon
    
    # Fix Thai-specific issues (keep important marks)
    # text = text.replace('‡∏∫', '')  # Keep Thai character above
    # text = text.replace('‡πå', '')  # Keep Thai character above
    
    # Remove multiple consecutive spaces
    text = re.sub(r'\s+', ' ', text)
    
    # Ensure proper sentence spacing
    text = re.sub(r'([.!?])\s*([A-Za-z‡∏Å-‡πô])', r'\1 \2', text)
    
    # Remove leading/trailing whitespace
    text = text.strip()
    
    # Remove lines with only special characters
    lines = text.split('\n')
    cleaned_lines = [line for line in lines if line.strip() and not re.match(r'^[^\w\s]+$', line.strip())]
    text = '\n'.join(cleaned_lines)
    
    return text

def extract_keywords_from_question(question: str) -> dict:
    """Extract main keywords from question with categories"""
    question_lower = question.lower()
    # Normalize simple punctuation to spaces for better matching
    question_norm = re.sub(r'[\.,\?\!\:\;\(\)\/]',' ', question_lower)
    
    # Pest/Disease keywords (expanded)
    pest_keywords = [
        # Thai - ‡πÅ‡∏°‡∏•‡∏á
        "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÑ‡∏ü", "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏≠‡πà‡∏≠‡∏ô", "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢", "‡∏´‡∏ô‡∏≠‡∏ô", "‡πÅ‡∏°‡∏•‡∏á", "‡∏î‡πâ‡∏ß‡∏á‡∏á‡∏ß‡∏á",
        "‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô", "‡∏´‡∏ô‡∏≠‡∏ô‡πÄ‡∏à‡∏≤‡∏∞", "‡∏´‡∏ô‡∏≠‡∏ô‡∏Å‡∏≠", "‡∏´‡∏ô‡∏≠‡∏ô‡πÉ‡∏¢", "‡∏î‡πâ‡∏ß‡∏á", "‡∏°‡∏î", "‡∏õ‡∏•‡∏ß‡∏Å",
        "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡∏à‡∏±‡∏Å‡∏à‡∏±‡πà‡∏ô", "‡πÅ‡∏°‡∏•‡∏á‡∏ß‡∏±‡∏ô‡∏ú‡∏•", "‡πÅ‡∏°‡∏•‡∏á‡∏´‡∏ß‡∏µ‡πà‡∏Ç‡∏≤‡∏ß", "‡∏ó‡∏£‡∏¥‡∏õ‡∏™‡πå",
        "‡∏®‡∏±‡∏ï‡∏£‡∏π‡∏û‡∏∑‡∏ä", "‡πÑ‡∏£", "‡πÄ‡∏û‡∏•‡∏µ‡πâ‡∏¢‡πÅ‡∏õ‡πâ‡∏á", "‡∏´‡∏ô‡∏≠‡∏ô‡∏Å‡∏£‡∏∞‡∏ó‡∏π‡πâ‡∏Ç‡πâ‡∏≤‡∏ß",
        # Thai - ‡πÇ‡∏£‡∏Ñ‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡∏£‡∏≤
        "‡∏£‡∏≤‡∏ô‡πâ‡∏≥‡∏Ñ‡πâ‡∏≤‡∏á", "‡∏£‡∏≤‡πÅ‡∏õ‡πâ‡∏á", "‡∏£‡∏≤‡∏™‡∏ô‡∏¥‡∏°", "‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡∏£‡∏≤", "‡∏£‡∏≤", "‡πÅ‡∏≠‡∏ô‡πÅ‡∏ó‡∏£‡∏Ñ‡πÇ‡∏ô‡∏™",
        "‡πÇ‡∏£‡∏Ñ‡∏ú‡∏•‡πÄ‡∏ô‡πà‡∏≤", "‡∏ú‡∏•‡πÄ‡∏ô‡πà‡∏≤", "‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡πÑ‡∏´‡∏°‡πâ", "‡πÉ‡∏ö‡πÑ‡∏´‡∏°‡πâ", "‡πÇ‡∏£‡∏Ñ‡∏£‡∏≤‡∏î‡∏≥", "‡∏£‡∏≤‡∏î‡∏≥",
        "‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡∏à‡∏∏‡∏î", "‡πÉ‡∏ö‡∏à‡∏∏‡∏î", "‡πÇ‡∏£‡∏Ñ‡∏Å‡∏¥‡πà‡∏á‡πÅ‡∏´‡πâ‡∏á", "‡∏Å‡∏¥‡πà‡∏á‡πÅ‡∏´‡πâ‡∏á", "‡πÇ‡∏£‡∏Ñ‡∏£‡∏≤‡∏Å‡πÄ‡∏ô‡πà‡∏≤", "‡∏£‡∏≤‡∏Å‡πÄ‡∏ô‡πà‡∏≤",
        "‡πÇ‡∏£‡∏Ñ‡∏•‡∏≥‡∏ï‡πâ‡∏ô‡πÄ‡∏ô‡πà‡∏≤", "‡∏•‡∏≥‡∏ï‡πâ‡∏ô‡πÄ‡∏ô‡πà‡∏≤", "‡πÇ‡∏£‡∏Ñ‡πÇ‡∏Ñ‡∏ô‡πÄ‡∏ô‡πà‡∏≤", "‡πÇ‡∏Ñ‡∏ô‡πÄ‡∏ô‡πà‡∏≤",
        # Thai - ‡πÑ‡∏ß‡∏£‡∏±‡∏™
        "‡πÑ‡∏ß‡∏£‡∏±‡∏™", "‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡∏î‡πà‡∏≤‡∏á", "‡πÇ‡∏£‡∏Ñ‡πÉ‡∏ö‡∏´‡∏á‡∏¥‡∏Å", "‡πÇ‡∏£‡∏Ñ‡∏à‡∏π‡πã", "‡πÇ‡∏£‡∏Ñ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á",
        # Thai - ‡∏ß‡∏±‡∏ä‡∏û‡∏∑‡∏ä
        "‡∏ß‡∏±‡∏ä‡∏û‡∏∑‡∏ä", "‡∏´‡∏ç‡πâ‡∏≤", "‡∏ú‡∏±‡∏Å‡∏ö‡∏∏‡πâ‡∏á", "‡∏´‡∏ç‡πâ‡∏≤‡∏Ñ‡∏≤",
        # Thai - ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
        "‡πÇ‡∏£‡∏Ñ‡∏û‡∏∑‡∏ä", "‡πÇ‡∏£‡∏Ñ",
        # English
        "aphid", "thrips", "whitefly", "moth", "caterpillar", "worm", "beetle",
        "mildew", "powdery mildew", "rust", "fungus", "fungal", "anthracnose",
        "virus", "viral", "disease", "weed", "grass", "mite", "borer", "leaf miner",
        "insect", "pest", "armyworm", "thrips", "fruit rot", "root rot", "stem rot"
    ]
    
    # Crop keywords (expanded)
    crop_keywords = [
        # Thai
        "‡∏ó‡∏∏‡πÄ‡∏£‡∏µ‡∏¢‡∏ô", "‡∏°‡∏∞‡∏°‡πà‡∏ß‡∏á", "‡∏Ç‡πâ‡∏≤‡∏ß", "‡∏û‡∏∑‡∏ä‡∏ú‡∏±‡∏Å", "‡∏ú‡∏±‡∏Å", "‡∏ú‡∏•‡πÑ‡∏°‡πâ",
        "‡∏°‡∏∞‡∏ô‡∏≤‡∏ß", "‡∏™‡πâ‡∏°", "‡∏Å‡∏•‡πâ‡∏ß‡∏¢", "‡∏°‡∏∞‡∏û‡∏£‡πâ‡∏≤‡∏ß", "‡∏¢‡∏≤‡∏á‡∏û‡∏≤‡∏£‡∏≤", "‡∏õ‡∏≤‡∏•‡πå‡∏°",
        "‡∏Ç‡πâ‡∏≤‡∏ß‡πÇ‡∏û‡∏î", "‡∏≠‡πâ‡∏≠‡∏¢", "‡∏°‡∏±‡∏ô‡∏™‡∏≥‡∏õ‡∏∞‡∏´‡∏•‡∏±‡∏á", "‡∏ñ‡∏±‡πà‡∏ß", "‡∏û‡∏£‡∏¥‡∏Å", "‡∏°‡∏∞‡πÄ‡∏Ç‡∏∑‡∏≠‡πÄ‡∏ó‡∏®",
        "‡∏•‡∏≥‡πÑ‡∏¢", "‡∏•‡∏¥‡πâ‡∏ô‡∏à‡∏µ‡πà", "‡πÄ‡∏á‡∏≤‡∏∞", "‡∏°‡∏±‡∏á‡∏Ñ‡∏∏‡∏î", "‡∏ù‡∏£‡∏±‡πà‡∏á", "‡∏ä‡∏°‡∏û‡∏π‡πà",
        # English
        "durian", "mango", "rice", "vegetable", "vegetables", "fruit",
        "lime", "orange", "banana", "coconut", "rubber", "palm",
        "corn", "sugarcane", "cassava", "peanut", "chilli", "tomato",
        "longan", "lychee", "rambutan", "mangosteen", "guava"
    ]
    
    # Product-related keywords
    product_keywords = [
        # Thai
        "‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå", "‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤", "‡∏¢‡∏≤", "‡∏™‡∏≤‡∏£", "‡∏õ‡∏∏‡πã‡∏¢",
        "icp", "ladda", "icpl", "‡πÑ‡∏≠‡∏ã‡∏µ‡∏û‡∏µ", "‡∏•‡∏±‡∏î‡∏î‡∏≤",
        "‡πÇ‡∏°‡πÄ‡∏î‡∏¥‡∏ô", "‡πÑ‡∏î‡∏≠‡∏∞‡∏ã‡∏¥‡∏ô‡∏≠‡∏ô", "‡∏≠‡∏¥‡∏°‡∏¥‡∏î‡∏≤‡πÇ‡∏Ñ‡∏•‡∏û‡∏£‡∏¥‡∏î", "‡πÑ‡∏ã‡πÄ‡∏û‡∏≠‡∏£‡πå‡πÄ‡∏°‡∏ó‡∏£‡∏¥‡∏ô",
        "‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥", "‡πÉ‡∏ä‡πâ", "‡∏û‡πà‡∏ô", "‡∏â‡∏µ‡∏î", "‡∏Å‡∏≥‡∏à‡∏±‡∏î", "‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô",
        # English
        "product", "products", "fertilizer", "pesticide", "insecticide", "fungicide", "recommend"
    ]

    # Fertilizer-specific keywords (NEW)
    fertilizer_keywords = [
        # ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏õ‡∏∏‡πã‡∏¢/‡∏™‡∏≤‡∏£‡∏ö‡∏≥‡∏£‡∏∏‡∏á
        "‡∏õ‡∏∏‡πã‡∏¢", "‡∏™‡∏≤‡∏£‡∏ö‡∏≥‡∏£‡∏∏‡∏á", "‡∏ò‡∏≤‡∏ï‡∏∏‡∏≠‡∏≤‡∏´‡∏≤‡∏£", "‡∏Æ‡∏≠‡∏£‡πå‡πÇ‡∏°‡∏ô", "‡∏™‡∏≤‡∏£‡πÄ‡∏£‡πà‡∏á",
        "‡∏õ‡∏∏‡πã‡∏¢‡πÄ‡∏Ñ‡∏°‡∏µ", "‡∏õ‡∏∏‡πã‡∏¢‡∏≠‡∏¥‡∏ô‡∏ó‡∏£‡∏µ‡∏¢‡πå", "‡∏õ‡∏∏‡πã‡∏¢‡∏ä‡∏µ‡∏ß‡∏†‡∏≤‡∏û",
        # ‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏õ‡∏∏‡πã‡∏¢ ICP (‡∏à‡∏≤‡∏Å CSV)
        "‡∏Å‡∏£‡∏∞‡∏£‡∏±‡∏ï", "‡∏Å‡∏≤‡∏£‡∏π‡∏Å‡πâ‡∏≤", "‡∏Ñ‡∏≠‡∏ô‡∏ó‡∏≤‡∏ü", "‡∏ã‡∏≠‡∏¢‡∏ö‡∏≠‡∏°", "‡∏ã‡∏µ‡πÄ‡∏≠‡πá‡∏°‡∏à‡∏µ",
        "‡∏ó‡πä‡∏≠‡∏õ‡∏Å‡∏±‡∏ô", "‡∏û‡∏≤‡∏ô‡∏≤‡∏™", "‡∏£‡∏≤‡πÄ‡∏ã‡∏≠‡∏£‡πå", "‡πÄ‡∏ß‡∏Ñ‡πÄ‡∏ï‡∏≠‡∏£‡πå", "‡∏£‡∏µ‡πÇ‡∏ô‡πÄ‡∏ß‡∏ó",
        "‡∏≠‡∏¥‡∏°‡∏¥‡∏î‡∏≤‡πÇ‡∏Å‡∏•‡∏î‡πå", "‡πÄ‡∏Å‡∏£‡∏Ñ", "‡πÄ‡∏ó‡∏≠‡∏£‡∏≤‡πÇ‡∏ô", "‡πÄ‡∏°‡∏ó‡∏≤‡∏°‡∏≠‡∏£‡πå‡∏õ", "‡πÅ‡∏°‡∏™‡∏ü‡∏≠‡∏£‡πå‡∏î",
        "‡πÅ‡∏≠‡∏ô‡∏î‡∏≤‡πÅ‡∏°‡πá‡∏Å‡∏ã‡πå", "‡πÅ‡∏≠‡πá‡∏Ñ‡∏ô‡∏≤‡∏ß", "‡πÇ‡∏Æ‡∏õ", "‡πÑ‡∏Å‡∏•‡πÇ‡∏ü‡πÄ‡∏™‡∏ó", "‡∏≠‡∏±‡∏û‡∏î‡∏≤‡∏ß",
        "‡πÑ‡∏î‡∏û‡∏¥‡∏°", "‡πÑ‡∏Æ‡∏ã‡∏µ‡∏™", "‡∏ö‡∏≠‡∏°‡∏™‡πå", "‡∏û‡∏£‡∏µ‡∏î‡∏¥‡∏Ñ‡∏ó‡πå", "‡∏ß‡∏≠‡πÅ‡∏£‡∏ô‡∏î‡πå",
        "‡∏≠‡∏¥‡∏ô‡πÄ‡∏ô‡∏≠‡∏£‡πå", "‡πÄ‡∏ö‡∏ô‡∏ã‡∏≤‡∏ô‡πà‡∏≤", "‡πÅ‡∏à‡πä‡∏™", "‡∏ô‡∏≤‡πÅ‡∏î‡∏ô", "‡∏Ñ‡∏≤‡∏ã‡πà‡∏≤",
        "‡∏ã‡∏¥‡∏°‡πÄ‡∏°‡∏≠‡∏£‡πå", "‡∏≠‡∏≤‡∏ó‡∏£‡∏≤‡∏ã‡∏µ‡∏ô", "‡∏Ñ‡∏≤‡∏£‡∏¥‡∏™‡∏°‡∏≤",
        # ‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏™‡∏≤‡∏£‡πÄ‡∏Ñ‡∏°‡∏µ
        "‡∏™‡∏≤‡∏£‡∏Å‡∏≥‡∏à‡∏±‡∏î‡πÅ‡∏°‡∏•‡∏á", "‡∏™‡∏≤‡∏£‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÇ‡∏£‡∏Ñ", "‡∏™‡∏≤‡∏£‡∏Å‡∏≥‡∏à‡∏±‡∏î‡∏ß‡∏±‡∏ä‡∏û‡∏∑‡∏ä",
        "‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÅ‡∏°‡∏•‡∏á", "‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡∏´‡∏ç‡πâ‡∏≤", "‡∏¢‡∏≤‡∏Ü‡πà‡∏≤‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡∏£‡∏≤",
        # ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏õ‡∏∏‡πã‡∏¢
        "‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡πÉ‡∏ä‡πâ", "‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏ú‡∏™‡∏°", "‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏õ‡∏∏‡πã‡∏¢", "‡πÉ‡∏™‡πà‡∏õ‡∏∏‡πã‡∏¢",
        # English
        "fertilizer", "nutrient", "hormone", "chemical"
    ]
    
    # Intent keywords (NEW)
    intent_keywords = {
        "increase_yield": [
            # Thai
            "‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ú‡∏•‡∏ú‡∏•‡∏¥‡∏ï", "‡∏ú‡∏•‡∏ú‡∏•‡∏¥‡∏ï‡∏™‡∏π‡∏á", "‡∏ú‡∏•‡∏ú‡∏•‡∏¥‡∏ï‡∏°‡∏≤‡∏Å", "‡∏ú‡∏•‡∏ú‡∏•‡∏¥‡∏ï‡∏î‡∏µ", "‡∏ú‡∏•‡∏ú‡∏•‡∏¥‡∏ï‡πÄ‡∏¢‡∏≠‡∏∞", "‡∏ú‡∏•‡∏ú‡∏•‡∏¥‡∏ï‡∏Ç‡∏∂‡πâ‡∏ô", "‡∏ú‡∏•‡∏ú‡∏•‡∏¥‡∏ï‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô", "‡∏ú‡∏•‡∏ú‡∏•‡∏¥‡∏ï‡πÄ‡∏û‡∏¥‡πà‡∏°",
            # English
            "increase yield", "higher yield", "more yield", "increase production", "boost yield", "increase harvest"
        ],
        "solve_problem": [
            # Thai
            "‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤", "‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç", "‡∏£‡∏±‡∏Å‡∏©‡∏≤", "‡∏Å‡∏≥‡∏à‡∏±‡∏î", "‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô", "‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°", "‡πÅ‡∏Å‡πâ‡πÇ‡∏£‡∏Ñ", "‡πÅ‡∏Å‡πâ",
            # English
            "solve problem", "control", "kill", "manage pest", "prevent", "control pest", "treat"
        ],
        "general_care": [
            # Thai
            "‡∏î‡∏π‡πÅ‡∏•", "‡∏ö‡∏≥‡∏£‡∏∏‡∏á", "‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á", "‡∏õ‡∏•‡∏π‡∏Å", "‡πÉ‡∏™‡πà‡∏õ‡∏∏‡πã‡∏¢",
            # English
            "care", "fertilize", "general care", "maintenance", "nurture"
        ],
        "product_inquiry": [
            # Thai - ‡πÄ‡∏û‡∏¥‡πà‡∏° patterns ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ñ‡∏≤‡∏°‡∏´‡∏≤‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤
            "‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á", "‡∏°‡∏µ‡πÑ‡∏´‡∏°", "‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥", "‡∏Ñ‡∏ß‡∏£‡πÉ‡∏ä‡πâ", "‡πÉ‡∏ä‡πâ‡∏≠‡∏∞‡πÑ‡∏£", "‡∏ã‡∏∑‡πâ‡∏≠",
            "‡∏ï‡∏±‡∏ß‡πÑ‡∏´‡∏ô", "‡∏¢‡∏≤‡∏≠‡∏∞‡πÑ‡∏£", "‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡πÑ‡∏´‡∏ô", "‡πÉ‡∏ä‡πâ‡∏¢‡∏≤‡∏≠‡∏∞‡πÑ‡∏£", "‡∏û‡πà‡∏ô‡∏≠‡∏∞‡πÑ‡∏£", "‡∏â‡∏µ‡∏î‡∏≠‡∏∞‡πÑ‡∏£",
            "‡∏™‡∏≤‡∏£‡∏≠‡∏∞‡πÑ‡∏£", "‡πÉ‡∏ä‡πâ‡∏™‡∏≤‡∏£‡∏≠‡∏∞‡πÑ‡∏£", "‡πÉ‡∏ä‡πâ‡∏≠‡∏∞‡πÑ‡∏£‡∏î‡∏µ", "‡∏ï‡∏±‡∏ß‡πÑ‡∏´‡∏ô‡∏î‡∏µ", "‡∏¢‡∏≤‡∏ï‡∏±‡∏ß‡πÑ‡∏´‡∏ô",
            "‡∏°‡∏µ‡∏¢‡∏≤‡∏≠‡∏∞‡πÑ‡∏£", "‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡πÑ‡∏´‡∏ô", "‡πÑ‡∏î‡πâ‡∏ö‡πâ‡∏≤‡∏á", "‡∏ö‡πâ‡∏≤‡∏á",
            # English
            "what products", "what is available", "recommend product", "recommend", "what to use", "is there"
        ]
    }
    
    found = {
        "pests": [],
        "crops": [],
        "products": [],
        "fertilizers": [],  # NEW: fertilizer keywords
        "intent": None,  # NEW: detect user intent
        "is_product_query": False,
        "is_fertilizer_query": False  # NEW: flag for fertilizer questions
    }
    
    # Extract pests
    for keyword in pest_keywords:
        if keyword in question_norm:
            found["pests"].append(keyword)
    
    # Extract crops
    for keyword in crop_keywords:
        if keyword in question_norm:
            found["crops"].append(keyword)
    
    # Extract product-related
    for keyword in product_keywords:
        if keyword in question_norm:
            found["products"].append(keyword)
            found["is_product_query"] = True

    # Extract fertilizer-related (NEW)
    for keyword in fertilizer_keywords:
        if keyword in question_norm:
            found["fertilizers"].append(keyword)
            found["is_fertilizer_query"] = True
            found["is_product_query"] = True

    # Detect intent (NEW)
    # Detect intent (MATCH ON NORMALIZED TEXT)
    for intent, keywords in intent_keywords.items():
        for keyword in keywords:
            if keyword in question_norm:
                found["intent"] = intent
                found["is_product_query"] = True
                break
        if found["intent"]:
            break
    
    return found
